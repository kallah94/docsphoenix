searchNodes=[{"ref":"Mix.Tasks.Compile.Phoenix.html","title":"Mix.Tasks.Compile.Phoenix","type":"task","doc":"Compiles Phoenix source files that support code reloading."},{"ref":"Mix.Tasks.Local.Phx.html","title":"Mix.Tasks.Local.Phx","type":"task","doc":"Updates the Phoenix project generator locally. mix local.phx Accepts the same command line options as archive.install hex phx_new. Note: Older versions of this task (up to and including 1.4.8) do not fetch the latest version from hex. If your phx_new archive is older than 1.4.9, it&#39;s necessary to call mix archive.install hex phx_new manually at least once."},{"ref":"Mix.Tasks.Local.Phx.html#run/1","title":"Mix.Tasks.Local.Phx.run/1","type":"function","doc":"A task needs to implement run which receives a list of command line args. Callback implementation for Mix.Task.run/1."},{"ref":"Mix.Tasks.Phx.html","title":"Mix.Tasks.Phx","type":"task","doc":"Prints Phoenix tasks and their information. mix phx"},{"ref":"Mix.Tasks.Phx.Digest.html","title":"Mix.Tasks.Phx.Digest","type":"task","doc":"Digests and compresses static files. mix phx.digest mix phx.digest priv/static -o /www/public The first argument is the path where the static files are located. The -o option indicates the path that will be used to save the digested and compressed files. If no path is given, it will use priv/static as the input and output path. The output folder will contain: the original file the file compressed with gzip a file containing the original file name and its digest a compressed file containing the file name and its digest a cache manifest file Example of generated files: app.js app.js.gz app-eb0a5b9302e8d32828d8a73f137cc8f0.js app-eb0a5b9302e8d32828d8a73f137cc8f0.js.gz cache_manifest.json"},{"ref":"Mix.Tasks.Phx.Digest.Clean.html","title":"Mix.Tasks.Phx.Digest.Clean","type":"task","doc":"Removes old versions of compiled assets. By default, it will keep the latest version and 2 previous versions as well as any digest created in the last hour. mix phx.digest.clean mix phx.digest.clean -o /www/public mix phx.digest.clean --age 600 --keep 3 Options -o, --output - indicates the path to your compiled assets directory. Defaults to priv/static --age - specifies a maximum age (in seconds) for assets. Files older than age that are not in the last --keep versions will be removed. Defaults to 3600 (1 hour) --keep - specifies how many previous versions of assets to keep. Defaults to 2 previous versions"},{"ref":"Mix.Tasks.Phx.Gen.Cert.html","title":"Mix.Tasks.Phx.Gen.Cert","type":"task","doc":"Generates a self-signed certificate for HTTPS testing. mix phx.gen.cert mix phx.gen.cert my-app my-app.local my-app.internal.example.com Creates a private key and a self-signed certificate in PEM format. These files can be referenced in the certfile and keyfile parameters of an HTTPS Endpoint. WARNING: only use the generated certificate for testing in a closed network environment, such as running a development server on localhost. For production, staging, or testing servers on the public internet, obtain a proper certificate, for example from Let&#39;s Encrypt. NOTE: when using Google Chrome, open chrome://flags/#allow-insecure-localhost to enable the use of self-signed certificates on localhost. Arguments The list of hostnames, if none are specified, defaults to: localhost Other (optional) arguments: --output (-o): the path and base filename for the certificate and key (default: priv/cert/selfsigned) --name (-n): the Common Name value in certificate&#39;s subject (default: &quot;Self-signed test certificate&quot;) Requires OTP 20 or later."},{"ref":"Mix.Tasks.Phx.Gen.Channel.html","title":"Mix.Tasks.Phx.Gen.Channel","type":"task","doc":"Generates a Phoenix channel. mix phx.gen.channel Room Accepts the module name for the channel The generated files will contain: For a regular application: a channel in lib/my_app_web/channels a channel test in test/my_app_web/channels For an umbrella application: a channel in apps/my_app_web/lib/app_name_web/channels a channel test in apps/my_app_web/test/my_app_web/channels"},{"ref":"Mix.Tasks.Phx.Gen.Context.html","title":"Mix.Tasks.Phx.Gen.Context","type":"task","doc":"Generates a context with functions around an Ecto schema. mix phx.gen.context Accounts User users name:string age:integer The first argument is the context module followed by the schema module and its plural name (used as the schema table name). The context is an Elixir module that serves as an API boundary for the given resource. A context often holds many related resources. Therefore, if the context already exists, it will be augmented with functions for the given resource. Note: A resource may also be split over distinct contexts (such as Accounts.User and Payments.User). The schema is responsible for mapping the database fields into an Elixir struct. Overall, this generator will add the following files to lib/your_app: a context module in accounts.ex, serving as the API boundary a schema in accounts/user.ex, with a users table A migration file for the repository and test files for the context will also be generated. Generating without a schema In some cases, you may wish to bootstrap the context module and tests, but leave internal implementation of the context and schema to yourself. Use the --no-schema flags to accomplish this. table By default, the table name for the migration and schema will be the plural name provided for the resource. To customize this value, a --table option may be provided. For example: mix phx.gen.context Accounts User users --table cms_users binary_id Generated migration can use binary_id for schema&#39;s primary key and its references with option --binary-id. Default options This generator uses default options provided in the :generators configuration of your application. These are the defaults: config :your_app, :generators, migration: true, binary_id: false, sample_binary_id: &quot;11111111-1111-1111-1111-111111111111&quot; You can override those options per invocation by providing corresponding switches, e.g. --no-binary-id to use normal ids despite the default configuration or --migration to force generation of the migration. Read the documentation for phx.gen.schema for more information on attributes."},{"ref":"Mix.Tasks.Phx.Gen.Context.html#prompt_for_code_injection/1","title":"Mix.Tasks.Phx.Gen.Context.prompt_for_code_injection/1","type":"function","doc":""},{"ref":"Mix.Tasks.Phx.Gen.Embedded.html","title":"Mix.Tasks.Phx.Gen.Embedded","type":"task","doc":"Generates an embedded Ecto schema for casting/validating data outside the DB. mix phx.gen.embedded Blog.Post title:string views:integer The first argument is the schema module followed by the schema attributes. The generated schema above will contain: an embedded schema file in lib/my_app/blog/post.ex Attributes The resource fields are given using name:type syntax where type are the types supported by Ecto. Omitting the type makes it default to :string: mix phx.gen.embedded Blog.Post title views:integer The following types are supported: :integer :float :decimal :boolean :map :string :array :references :text :date :time :time_usec :naive_datetime :naive_datetime_usec :utc_datetime :utc_datetime_usec :uuid :binary :datetime - An alias for :naive_datetime"},{"ref":"Mix.Tasks.Phx.Gen.Html.html","title":"Mix.Tasks.Phx.Gen.Html","type":"task","doc":"Generates controller, views, and context for an HTML resource. mix phx.gen.html Accounts User users name:string age:integer The first argument is the context module followed by the schema module and its plural name (used as the schema table name). The context is an Elixir module that serves as an API boundary for the given resource. A context often holds many related resources. Therefore, if the context already exists, it will be augmented with functions for the given resource. Note: A resource may also be split over distinct contexts (such as Accounts.User and Payments.User). The schema is responsible for mapping the database fields into an Elixir struct. Overall, this generator will add the following files to lib/: a context module in lib/app/accounts.ex for the accounts API a schema in lib/app/accounts/user.ex, with an users table a view in lib/app_web/views/user_view.ex a controller in lib/app_web/controllers/user_controller.ex default CRUD templates in lib/app_web/templates/user A migration file for the repository and test files for the context and controller features will also be generated. The location of the web files (controllers, views, templates, etc) in an umbrella application will vary based on the :context_app config located in your applications :generators configuration. When set, the Phoenix generators will generate web files directly in your lib and test folders since the application is assumed to be isolated to web specific functionality. If :context_app is not set, the generators will place web related lib and test files in a web/ directory since the application is assumed to be handling both web and domain specific functionality. Example configuration: config :my_app_web, :generators, context_app: :my_app Alternatively, the --context-app option may be supplied to the generator: mix phx.gen.html Sales User users --context-app warehouse Web namespace By default, the controller and view will be namespaced by the schema name. You can customize the web module namespace by passing the --web flag with a module name, for example: mix phx.gen.html Sales User users --web Sales Which would generate a lib/app_web/controllers/sales/user_controller.ex and lib/app_web/views/sales/user_view.ex. Generating without a schema or context file In some cases, you may wish to bootstrap HTML templates, controllers, and controller tests, but leave internal implementation of the context or schema to yourself. You can use the --no-context and --no-schema flags for file generation control. table By default, the table name for the migration and schema will be the plural name provided for the resource. To customize this value, a --table option may be provided. For example: mix phx.gen.html Accounts User users --table cms_users binary_id Generated migration can use binary_id for schema&#39;s primary key and its references with option --binary-id. Default options This generator uses default options provided in the :generators configuration of your application. These are the defaults: config :your_app, :generators, migration: true, binary_id: false, sample_binary_id: &quot;11111111-1111-1111-1111-111111111111&quot; You can override those options per invocation by providing corresponding switches, e.g. --no-binary-id to use normal ids despite the default configuration or --migration to force generation of the migration. Read the documentation for phx.gen.schema for more information on attributes."},{"ref":"Mix.Tasks.Phx.Gen.Json.html","title":"Mix.Tasks.Phx.Gen.Json","type":"task","doc":"Generates controller, views, and context for a JSON resource. mix phx.gen.json Accounts User users name:string age:integer The first argument is the context module followed by the schema module and its plural name (used as the schema table name). The context is an Elixir module that serves as an API boundary for the given resource. A context often holds many related resources. Therefore, if the context already exists, it will be augmented with functions for the given resource. Note: A resource may also be split over distinct contexts (such as Accounts.User and Payments.User). The schema is responsible for mapping the database fields into an Elixir struct. Overall, this generator will add the following files to lib/: a context module in lib/app/accounts.ex for the accounts API a schema in lib/app/accounts/user.ex, with an users table a view in lib/app_web/views/user_view.ex a controller in lib/app_web/controllers/user_controller.ex A migration file for the repository and test files for the context and controller features will also be generated. The location of the web files (controllers, views, templates, etc) in an umbrella application will vary based on the :context_app config located in your applications :generators configuration. When set, the Phoenix generators will generate web files directly in your lib and test folders since the application is assumed to be isolated to web specific functionality. If :context_app is not set, the generators will place web related lib and test files in a web/ directory since the application is assumed to be handling both web and domain specific functionality. Example configuration: config :my_app_web, :generators, context_app: :my_app Alternatively, the --context-app option may be supplied to the generator: mix phx.gen.json Sales User users --context-app warehouse Web namespace By default, the controller and view will be namespaced by the schema name. You can customize the web module namespace by passing the --web flag with a module name, for example: mix phx.gen.json Sales User users --web Sales Which would generate a lib/app_web/controllers/sales/user_controller.ex and lib/app_web/views/sales/user_view.ex. Generating without a schema or context file In some cases, you may wish to bootstrap JSON views, controllers, and controller tests, but leave internal implementation of the context or schema to yourself. You can use the --no-context and --no-schema flags for file generation control. table By default, the table name for the migration and schema will be the plural name provided for the resource. To customize this value, a --table option may be provided. For example: mix phx.gen.json Accounts User users --table cms_users binary_id Generated migration can use binary_id for schema&#39;s primary key and its references with option --binary-id. Default options This generator uses default options provided in the :generators configuration of your application. These are the defaults: config :your_app, :generators, migration: true, binary_id: false, sample_binary_id: &quot;11111111-1111-1111-1111-111111111111&quot; You can override those options per invocation by providing corresponding switches, e.g. --no-binary-id to use normal ids despite the default configuration or --migration to force generation of the migration. Read the documentation for phx.gen.schema for more information on attributes."},{"ref":"Mix.Tasks.Phx.Gen.Presence.html","title":"Mix.Tasks.Phx.Gen.Presence","type":"task","doc":"Generates a Presence tracker for your application. mix phx.gen.presence mix phx.gen.presence MyPresence The only argument is the module name of the Presence tracker, which defaults to Presence. A new file will be generated in lib/my_app_web/channels/presence.ex, where my_app_web is the snake cased version of the module name provided."},{"ref":"Mix.Tasks.Phx.Gen.Schema.html","title":"Mix.Tasks.Phx.Gen.Schema","type":"task","doc":"Generates an Ecto schema and migration. mix phx.gen.schema Blog.Post blog_posts title:string views:integer The first argument is the schema module followed by its plural name (used as the table name). The generated schema above will contain: a schema file in lib/my_app/blog/post.ex, with a blog_posts table a migration file for the repository The generated migration can be skipped with --no-migration. Contexts Your schemas can be generated and added to a separate OTP app. Make sure your configuration is properly setup or manually specify the context app with the --context-app option with the CLI. # Via config config :marketing_web, :generators, context_app: :marketing # Via CLI mix phx.gen.schema Blog.Post blog_posts title:string views:integer --context-app marketing Attributes The resource fields are given using name:type syntax where type are the types supported by Ecto. Omitting the type makes it default to :string: mix phx.gen.schema Blog.Post blog_posts title views:integer The following types are supported: :integer :float :decimal :boolean :map :string :array :references :text :date :time :time_usec :naive_datetime :naive_datetime_usec :utc_datetime :utc_datetime_usec :uuid :binary :datetime - An alias for :naive_datetime The generator also supports references, which we will properly associate the given column to the primary key column of the referenced table: mix phx.gen.schema Blog.Post blog_posts title user_id:references:users This will result in a migration with an :integer column of :user_id and create an index. Furthermore an array type can also be given if it is supported by your database, although it requires the type of the underlying array element to be given too: mix phx.gen.schema Blog.Post blog_posts tags:array:string Unique columns can be automatically generated by using: mix phx.gen.schema Blog.Post blog_posts title:unique unique_int:integer:unique If no data type is given, it defaults to a string. table By default, the table name for the migration and schema will be the plural name provided for the resource. To customize this value, a --table option may be provided. For example: mix phx.gen.schema Blog.Post posts --table cms_posts binary_id Generated migration can use binary_id for schema&#39;s primary key and its references with option --binary-id. Default options This generator uses default options provided in the :generators configuration of your application. These are the defaults: config :your_app, :generators, migration: true, binary_id: false, sample_binary_id: &quot;11111111-1111-1111-1111-111111111111&quot; You can override those options per invocation by providing corresponding switches, e.g. --no-binary-id to use normal ids despite the default configuration or --migration to force generation of the migration."},{"ref":"Mix.Tasks.Phx.Gen.Secret.html","title":"Mix.Tasks.Phx.Gen.Secret","type":"task","doc":"Generates a secret and prints it to the terminal. mix phx.gen.secret [length] By default, mix phx.gen.secret generates a key 64 characters long. The minimum value for length is 32."},{"ref":"Mix.Tasks.Phx.New.html","title":"Mix.Tasks.Phx.New","type":"task","doc":"Creates a new Phoenix project. It expects the path of the project as an argument. mix phx.new PATH [--module MODULE] [--app APP] A project at the given PATH will be created. The application name and module name will be retrieved from the path, unless --module or --app is given. Options --umbrella - generate an umbrella project, with one application for your domain, and a second application for the web interface. --app - the name of the OTP application --module - the name of the base module in the generated skeleton --database - specify the database adapter for Ecto. One of: postgres (https://github.com/elixir-ecto/postgrex) mysql (https://github.com/elixir-ecto/myxql) Please check the driver docs, between parentheses, for more information and requirements. Defaults to &quot;postgres&quot;. --no-webpack - do not generate webpack files for static asset building. When choosing this option, you will need to manually handle JavaScript dependencies if building HTML apps --no-ecto - do not generate Ecto files. --no-html - do not generate HTML views. --no-gettext - do not generate gettext files. --binary-id - use binary_id as primary key type in Ecto schemas --verbose - use verbose output When passing the --no-ecto flag, Phoenix generators such as phx.gen.html, phx.gen.json and phx.gen.context may no longer work as expected as they generate context files that rely on Ecto for the database access. In those cases, you can pass the --no-context flag to generate most of the HTML and JSON files but skip the context, allowing you to fill in the blanks as desired. Similarly, if --no-html is given, the files generated by phx.gen.html will no longer work, as important HTML components will be missing. Examples mix phx.new hello_world Is equivalent to: mix phx.new hello_world --module HelloWorld Or without the HTML and JS bits (useful for APIs): mix phx.new ~/Workspace/hello_world --no-html --no-webpack As an umbrella: mix phx.new hello --umbrella Would generate the following directory structure and modules: hello_umbrella/ Hello.Umbrella apps/ hello/ Hello hello_web/ HelloWeb You can read more about umbrella projects using the official Elixir guide To print the Phoenix installer version, pass -v or --version, for example: mix phx.new -v"},{"ref":"Mix.Tasks.Phx.New.html#generate/4","title":"Mix.Tasks.Phx.New.generate/4","type":"function","doc":""},{"ref":"Mix.Tasks.Phx.New.html#run/1","title":"Mix.Tasks.Phx.New.run/1","type":"function","doc":"A task needs to implement run which receives a list of command line args. Callback implementation for Mix.Task.run/1."},{"ref":"Mix.Tasks.Phx.New.html#run/3","title":"Mix.Tasks.Phx.New.run/3","type":"function","doc":""},{"ref":"Mix.Tasks.Phx.New.Ecto.html","title":"Mix.Tasks.Phx.New.Ecto","type":"task","doc":"Creates a new Ecto project within an umbrella project. This task is intended to create a bare Ecto project without web integration, which serves as a core application of your domain for web applications and your greater umbrella platform to integrate with. It expects the name of the project as an argument. $ cd my_umbrella/apps $ mix phx.new.ecto APP [--module MODULE] [--app APP] A project at the given APP directory will be created. The application name and module name will be retrieved from the application name, unless --module or --app is given. Options --app - the name of the OTP application --module - the name of the base module in the generated skeleton --database - specify the database adapter for Ecto. One of: postgres (https://github.com/elixir-ecto/postgrex) mysql (https://github.com/elixir-ecto/myxql) Please check the driver docs, between parentheses, for more information and requirements. Defaults to &quot;postgres&quot;. --binary-id - use binary_id as primary key type in Ecto schemas Examples mix phx.new.ecto hello_ecto Is equivalent to: mix phx.new.ecto hello_ecto --module HelloEcto"},{"ref":"Mix.Tasks.Phx.New.Ecto.html#run/1","title":"Mix.Tasks.Phx.New.Ecto.run/1","type":"function","doc":"A task needs to implement run which receives a list of command line args. Callback implementation for Mix.Task.run/1."},{"ref":"Mix.Tasks.Phx.New.Web.html","title":"Mix.Tasks.Phx.New.Web","type":"task","doc":"Creates a new Phoenix web project within an umbrella project. It expects the name of the otp app as the first argument and for the command to be run inside your umbrella application&#39;s apps directory: $ cd my_umbrella/apps $ mix phx.new.web APP [--module MODULE] [--app APP] This task is intended to create a bare Phoenix project without database integration, which interfaces with your greater umbrella application(s). Examples mix phx.new.web hello_web Is equivalent to: mix phx.new.web hello_web --module HelloWeb Supports the same options as the phx.new task. See Mix.Tasks.Phx.New for details."},{"ref":"Mix.Tasks.Phx.New.Web.html#run/1","title":"Mix.Tasks.Phx.New.Web.run/1","type":"function","doc":"A task needs to implement run which receives a list of command line args. Callback implementation for Mix.Task.run/1."},{"ref":"Mix.Tasks.Phx.Routes.html","title":"Mix.Tasks.Phx.Routes","type":"task","doc":"Prints all routes for the default or a given router. $ mix phx.routes $ mix phx.routes MyApp.AnotherRouter The default router is inflected from the application name unless a configuration named :namespace is set inside your application configuration. For example, the configuration: config :my_app, namespace: My.App will exhibit the routes for My.App.Router when this task is invoked without arguments. Umbrella projects do not have a default router and therefore always expect a router to be given."},{"ref":"Mix.Tasks.Phx.Server.html","title":"Mix.Tasks.Phx.Server","type":"task","doc":"Starts the application by configuring all endpoints servers to run. Command line options This task accepts the same command-line arguments as run. For additional information, refer to the documentation for Mix.Tasks.Run. For example, to run phx.server without recompiling: mix phx.server --no-compile The --no-halt flag is automatically added. Note that the --no-deps-check flag cannot be used this way, because Mix needs to check dependencies to find phx.server. To run phx.server without checking dependencies, you can run: mix do deps.loadpaths --no-deps-check, phx.server"},{"ref":"Phoenix.html","title":"Phoenix","type":"module","doc":"This is the documentation for the Phoenix project. By default, Phoenix applications depend on the following packages: Ecto - a language integrated query and database wrapper Phoenix - the Phoenix web framework (these docs) Phoenix.js - Phoenix Channels JavaScript client Phoenix PubSub - a distributed pub/sub system with presence support Phoenix HTML - conveniences for working with HTML in Phoenix Plug - a specification and conveniences for composable modules in between web applications Gettext - Internationalization and localization through gettext There are also optional packages depending on your configuration: Phoenix PubSub Redis - use Redis to power the Phoenix PubSub system"},{"ref":"Phoenix.html#json_library/0","title":"Phoenix.json_library/0","type":"function","doc":"Returns the configured JSON encoding library for Phoenix. To customize the JSON library, including the following in your config/config.exs: config :phoenix, :json_library, Jason"},{"ref":"Phoenix.ActionClauseError.html","title":"Phoenix.ActionClauseError","type":"exception","doc":""},{"ref":"Phoenix.ActionClauseError.html#blame/2","title":"Phoenix.ActionClauseError.blame/2","type":"function","doc":"Called from Exception.blame/3 to augment the exception struct. Can be used to collect additional information about the exception or do some additional expensive computation. Callback implementation for Exception.blame/2."},{"ref":"Phoenix.ActionClauseError.html#message/1","title":"Phoenix.ActionClauseError.message/1","type":"function","doc":"Callback implementation for Exception.message/1."},{"ref":"Phoenix.Channel.html","title":"Phoenix.Channel","type":"behaviour","doc":"Defines a Phoenix Channel. Channels provide a means for bidirectional communication from clients that integrate with the Phoenix.PubSub layer for soft-realtime functionality. Topics &amp; Callbacks Every time you join a channel, you need to choose which particular topic you want to listen to. The topic is just an identifier, but by convention it is often made of two parts: &quot;topic:subtopic&quot;. Using the &quot;topic:subtopic&quot; approach pairs nicely with the Phoenix.Socket.channel/3 allowing you to match on all topics starting with a given prefix by using a splat (the * character) as the last character in the topic pattern: channel &quot;room:*&quot;, MyApp.RoomChannel Any topic coming into the router with the &quot;room:&quot; prefix would dispatch to MyApp.RoomChannel in the above example. Topics can also be pattern matched in your channels&#39; join/3 callback to pluck out the scoped pattern: # handles the special `&quot;lobby&quot;` subtopic def join(&quot;room:lobby&quot;, _payload, socket) do {:ok, socket} end # handles any other subtopic as the room ID, for example `&quot;room:12&quot;`, `&quot;room:34&quot;` def join(&quot;room:&quot; &lt;&gt; room_id, _payload, socket) do {:ok, socket} end Authorization Clients must join a channel to send and receive PubSub events on that channel. Your channels must implement a join/3 callback that authorizes the socket for the given topic. For example, you could check if the user is allowed to join that particular room. To authorize a socket in join/3, return {:ok, socket}. To refuse authorization in join/3, return {:error, reply}. Incoming Events After a client has successfully joined a channel, incoming events from the client are routed through the channel&#39;s handle_in/3 callbacks. Within these callbacks, you can perform any action. Typically you&#39;ll either forward a message to all listeners with broadcast!/3, or push a message directly down the socket with push/3. Incoming callbacks must return the socket to maintain ephemeral state. Here&#39;s an example of receiving an incoming &quot;new_msg&quot; event from one client, and broadcasting the message to all topic subscribers for this socket. def handle_in(&quot;new_msg&quot;, %{&quot;uid&quot; =&gt; uid, &quot;body&quot; =&gt; body}, socket) do broadcast!(socket, &quot;new_msg&quot;, %{uid: uid, body: body}) {:noreply, socket} end You can also push a message directly down the socket: # client asks for their current rank, push sent directly as a new event. def handle_in(&quot;current_rank&quot;, _, socket) do push(socket, &quot;current_rank&quot;, %{val: Game.get_rank(socket.assigns[:user])}) {:noreply, socket} end Replies In addition to pushing messages out when you receive a handle_in event, you can also reply directly to a client event for request/response style messaging. This is useful when a client must know the result of an operation or to simply ack messages. For example, imagine creating a resource and replying with the created record: def handle_in(&quot;create:post&quot;, attrs, socket) do changeset = Post.changeset(%Post{}, attrs) if changeset.valid? do post = Repo.insert!(changeset) response = MyApp.PostView.render(&quot;show.json&quot;, %{post: post}) {:reply, {:ok, response}, socket} else response = MyApp.ChangesetView.render(&quot;errors.json&quot;, %{changeset: changeset}) {:reply, {:error, response}, socket} end end Alternatively, you may just want to ack the status of the operation: def handle_in(&quot;create:post&quot;, attrs, socket) do changeset = Post.changeset(%Post{}, attrs) if changeset.valid? do Repo.insert!(changeset) {:reply, :ok, socket} else {:reply, :error, socket} end end Intercepting Outgoing Events When an event is broadcasted with broadcast/3, each channel subscriber can choose to intercept the event and have their handle_out/3 callback triggered. This allows the event&#39;s payload to be customized on a socket by socket basis to append extra information, or conditionally filter the message from being delivered. If the event is not intercepted with Phoenix.Channel.intercept/1, then the message is pushed directly to the client: intercept [&quot;new_msg&quot;, &quot;user_joined&quot;] # for every socket subscribing to this topic, append an `is_editable` # value for client metadata. def handle_out(&quot;new_msg&quot;, msg, socket) do push(socket, &quot;new_msg&quot;, Map.merge(msg, %{is_editable: User.can_edit_message?(socket.assigns[:user], msg)} )) {:noreply, socket} end # do not send broadcasted `&quot;user_joined&quot;` events if this socket&#39;s user # is ignoring the user who joined. def handle_out(&quot;user_joined&quot;, msg, socket) do unless User.ignoring?(socket.assigns[:user], msg.user_id) do push(socket, &quot;user_joined&quot;, msg) end {:noreply, socket} end Broadcasting to an external topic In some cases, you will want to broadcast messages without the context of a socket. This could be for broadcasting from within your channel to an external topic, or broadcasting from elsewhere in your application like a controller or another process. Such can be done via your endpoint: # within channel def handle_in(&quot;new_msg&quot;, %{&quot;uid&quot; =&gt; uid, &quot;body&quot; =&gt; body}, socket) do ... broadcast_from!(socket, &quot;new_msg&quot;, %{uid: uid, body: body}) MyApp.Endpoint.broadcast_from!(self(), &quot;room:superadmin&quot;, &quot;new_msg&quot;, %{uid: uid, body: body}) {:noreply, socket} end # within controller def create(conn, params) do ... MyApp.Endpoint.broadcast!(&quot;room:&quot; &lt;&gt; rid, &quot;new_msg&quot;, %{uid: uid, body: body}) MyApp.Endpoint.broadcast!(&quot;room:superadmin&quot;, &quot;new_msg&quot;, %{uid: uid, body: body}) redirect(conn, to: &quot;/&quot;) end Terminate On termination, the channel callback terminate/2 will be invoked with the error reason and the socket. If we are terminating because the client left, the reason will be {:shutdown, :left}. Similarly, if we are terminating because the client connection was closed, the reason will be {:shutdown, :closed}. If any of the callbacks return a :stop tuple, it will also trigger terminate with the reason given in the tuple. terminate/2, however, won&#39;t be invoked in case of errors nor in case of exits. This is the same behaviour as you find in Elixir abstractions like GenServer and others. Typically speaking, if you want to clean something up, it is better to monitor your channel process and do the clean up from another process. Similar to GenServer, it would also be possible :trap_exit to guarantee that terminate/2 is invoked. This practice is not encouraged though. Exit reasons when stopping a channel When the channel callbacks return a :stop tuple, such as: {:stop, :shutdown, socket} {:stop, {:error, :enoent}, socket} the second argument is the exit reason, which follows the same behaviour as standard GenServer exits. You have three options to choose from when shutting down a channel: :normal - in such cases, the exit won&#39;t be logged and linked processes do not exit :shutdown or {:shutdown, term} - in such cases, the exit won&#39;t be logged and linked processes exit with the same reason unless they&#39;re trapping exits any other term - in such cases, the exit will be logged and linked processes exit with the same reason unless they&#39;re trapping exits Subscribing to external topics Sometimes you may need to programmatically subscribe a socket to external topics in addition to the internal socket.topic. For example, imagine you have a bidding system where a remote client dynamically sets preferences on products they want to receive bidding notifications on. Instead of requiring a unique channel process and topic per preference, a more efficient and simple approach would be to subscribe a single channel to relevant notifications via your endpoint. For example: defmodule MyApp.Endpoint.NotificationChannel do use Phoenix.Channel def join(&quot;notification:&quot; &lt;&gt; user_id, %{&quot;ids&quot; =&gt; ids}, socket) do topics = for product_id &lt;- ids, do: &quot;product:\#{product_id}&quot; {:ok, socket |&gt; assign(:topics, []) |&gt; put_new_topics(topics)} end def handle_in(&quot;watch&quot;, %{&quot;product_id&quot; =&gt; id}, socket) do {:reply, :ok, put_new_topics(socket, [&quot;product:\#{id}&quot;])} end def handle_in(&quot;unwatch&quot;, %{&quot;product_id&quot; =&gt; id}, socket) do {:reply, :ok, MyApp.Endpoint.unsubscribe(&quot;product:\#{id}&quot;)} end defp put_new_topics(socket, topics) do Enum.reduce(topics, socket, fn topic, acc -&gt; topics = acc.assigns.topics if topic in topics do acc else :ok = MyApp.Endpoint.subscribe(topic) assign(acc, :topics, [topic | topics]) end end) end end Note: the caller must be responsible for preventing duplicate subscriptions. After calling subscribe/1 from your endpoint, the same flow applies to handling regular Elixir messages within your channel. Most often, you&#39;ll simply relay the %Phoenix.Socket.Broadcast{} event and payload: alias Phoenix.Socket.Broadcast def handle_info(%Broadcast{topic: _, event: event, payload: payload}, socket) do push(socket, event, payload) {:noreply, socket} end Hibernation From Erlang/OTP 20, channels automatically hibernate to save memory after 15_000 milliseconds of inactivity. This can be customized by passing the :hibernate_after option to use Phoenix.Channel: use Phoenix.Channel, hibernate_after: 60_000 You can also set it to :infinity to fully disable it. Logging By default, channel &quot;join&quot; and &quot;handle_in&quot; events are logged, using the level :info and :debug, respectively. Logs can be customized per event type or disabled by setting the :log_join and :log_handle_in options when using Phoenix.Channel. For example, the following configuration logs join events as :info, but disables logging for incoming events: use Phoenix.Channel, log_join: :info, log_handle_in: false"},{"ref":"Phoenix.Channel.html#broadcast/3","title":"Phoenix.Channel.broadcast/3","type":"function","doc":"Broadcast an event to all subscribers of the socket topic. The event&#39;s message must be a serializable map. Examples iex&gt; broadcast(socket, &quot;new_message&quot;, %{id: 1, content: &quot;hello&quot;}) :ok"},{"ref":"Phoenix.Channel.html#broadcast!/3","title":"Phoenix.Channel.broadcast!/3","type":"function","doc":"Same as broadcast/3, but raises if broadcast fails."},{"ref":"Phoenix.Channel.html#broadcast_from/3","title":"Phoenix.Channel.broadcast_from/3","type":"function","doc":"Broadcast event from pid to all subscribers of the socket topic. The channel that owns the socket will not receive the published message. The event&#39;s message must be a serializable map. Examples iex&gt; broadcast_from(socket, &quot;new_message&quot;, %{id: 1, content: &quot;hello&quot;}) :ok"},{"ref":"Phoenix.Channel.html#broadcast_from!/3","title":"Phoenix.Channel.broadcast_from!/3","type":"function","doc":"Same as broadcast_from/3, but raises if broadcast fails."},{"ref":"Phoenix.Channel.html#c:code_change/3","title":"Phoenix.Channel.code_change/3","type":"callback","doc":""},{"ref":"Phoenix.Channel.html#c:handle_call/3","title":"Phoenix.Channel.handle_call/3","type":"callback","doc":"Handle regular GenServer call messages. See GenServer.handle_call/3."},{"ref":"Phoenix.Channel.html#c:handle_cast/2","title":"Phoenix.Channel.handle_cast/2","type":"callback","doc":"Handle regular GenServer cast messages. See GenServer.handle_cast/2."},{"ref":"Phoenix.Channel.html#c:handle_in/3","title":"Phoenix.Channel.handle_in/3","type":"callback","doc":"Handle incoming events. Example def handle_in(&quot;ping&quot;, payload, socket) do {:reply, {:ok, payload}, socket} end"},{"ref":"Phoenix.Channel.html#c:handle_info/2","title":"Phoenix.Channel.handle_info/2","type":"callback","doc":"Handle regular Elixir process messages. See GenServer.handle_info/2."},{"ref":"Phoenix.Channel.html#c:handle_out/3","title":"Phoenix.Channel.handle_out/3","type":"callback","doc":"Intercepts outgoing events. See intercept/1."},{"ref":"Phoenix.Channel.html#intercept/1","title":"Phoenix.Channel.intercept/1","type":"macro","doc":"Defines which Channel events to intercept for handle_out/3 callbacks. By default, broadcasted events are pushed directly to the client, but intercepting events gives your channel a chance to customize the event for the client to append extra information or filter the message from being delivered. Note: intercepting events can introduce significantly more overhead if a large number of subscribers must customize a message since the broadcast will be encoded N times instead of a single shared encoding across all subscribers. Examples intercept [&quot;new_msg&quot;] def handle_out(&quot;new_msg&quot;, payload, socket) do push(socket, &quot;new_msg&quot;, Map.merge(payload, is_editable: User.can_edit_message?(socket.assigns[:user], payload) )) {:noreply, socket} end handle_out/3 callbacks must return one of: {:noreply, Socket.t} | {:noreply, Socket.t, timeout | :hibernate} | {:stop, reason :: term, Socket.t}"},{"ref":"Phoenix.Channel.html#c:join/3","title":"Phoenix.Channel.join/3","type":"callback","doc":"Handle channel joins by topic. To authorize a socket, return {:ok, socket} or {:ok, reply, socket}. To refuse authorization, return {:error, reason}. Example def join(&quot;room:lobby&quot;, payload, socket) do if authorized?(payload) do {:ok, socket} else {:error, %{reason: &quot;unauthorized&quot;}} end end"},{"ref":"Phoenix.Channel.html#push/3","title":"Phoenix.Channel.push/3","type":"function","doc":"Sends event to the socket. The event&#39;s message must be a serializable map. Examples iex&gt; push(socket, &quot;new_message&quot;, %{id: 1, content: &quot;hello&quot;}) :ok"},{"ref":"Phoenix.Channel.html#reply/2","title":"Phoenix.Channel.reply/2","type":"function","doc":"Replies asynchronously to a socket push. Useful when you need to reply to a push that can&#39;t otherwise be handled using the {:reply, {status, payload}, socket} return from your handle_in callbacks. reply/2 will be used in the rare cases you need to perform work in another process and reply when finished by generating a reference to the push with socket_ref/1. Note: In such cases, a socket_ref should be generated and passed to the external process, so the socket itself is not leaked outside the channel. The socket holds information such as assigns and transport configuration, so it&#39;s important to not copy this information outside of the channel that owns it. Examples def handle_in(&quot;work&quot;, payload, socket) do Worker.perform(payload, socket_ref(socket)) {:noreply, socket} end def handle_info({:work_complete, result, ref}, socket) do reply(ref, {:ok, result}) {:noreply, socket} end"},{"ref":"Phoenix.Channel.html#socket_ref/1","title":"Phoenix.Channel.socket_ref/1","type":"function","doc":"Generates a socket_ref for an async reply. See reply/2 for example usage."},{"ref":"Phoenix.Channel.html#c:terminate/2","title":"Phoenix.Channel.terminate/2","type":"callback","doc":"Invoked when the channel process is about to exit. See GenServer.terminate/2."},{"ref":"Phoenix.Channel.html#t:reply/0","title":"Phoenix.Channel.reply/0","type":"type","doc":""},{"ref":"Phoenix.Channel.html#t:socket_ref/0","title":"Phoenix.Channel.socket_ref/0","type":"type","doc":""},{"ref":"Phoenix.Controller.html","title":"Phoenix.Controller","type":"module","doc":"Controllers are used to group common functionality in the same (pluggable) module. For example, the route: get &quot;/users/:id&quot;, MyAppWeb.UserController, :show will invoke the show/2 action in the MyAppWeb.UserController: defmodule MyAppWeb.UserController do use MyAppWeb, :controller def show(conn, %{&quot;id&quot; =&gt; id}) do user = Repo.get(User, id) render(conn, &quot;show.html&quot;, user: user) end end An action is a regular function that receives the connection and the request parameters as arguments. The connection is a Plug.Conn struct, as specified by the Plug library. Options When used, the controller supports the following options: :namespace - sets the namespace to properly inflect the layout view. By default it uses the base alias in your controller name :log - the level to log. When false, disables controller logging Connection A controller by default provides many convenience functions for manipulating the connection, rendering templates, and more. Those functions are imported from two modules: Plug.Conn - a collection of low-level functions to work with the connection Phoenix.Controller - functions provided by Phoenix to support rendering, and other Phoenix specific behaviour If you want to have functions that manipulate the connection without fully implementing the controller, you can import both modules directly instead of use Phoenix.Controller. Plug pipeline As with routers, controllers also have their own plug pipeline. However, different from routers, controllers have a single pipeline: defmodule MyAppWeb.UserController do use MyAppWeb, :controller plug :authenticate, usernames: [&quot;jose&quot;, &quot;eric&quot;, &quot;sonny&quot;] def show(conn, params) do # authenticated users only end defp authenticate(conn, options) do if get_session(conn, :username) in options[:usernames] do conn else conn |&gt; redirect(to: &quot;/&quot;) |&gt; halt() end end end The :authenticate plug will be invoked before the action. If the plug calls Plug.Conn.halt/1 (which is by default imported into controllers), it will halt the pipeline and won&#39;t invoke the action. Guards plug/2 in controllers supports guards, allowing a developer to configure a plug to only run in some particular action: plug :authenticate, [usernames: [&quot;jose&quot;, &quot;eric&quot;, &quot;sonny&quot;]] when action in [:show, :edit] plug :authenticate, [usernames: [&quot;admin&quot;]] when not action in [:index] The first plug will run only when action is show or edit. The second plug will always run, except for the index action. Those guards work like regular Elixir guards and the only variables accessible in the guard are conn, the action as an atom and the controller as an alias. Controllers are plugs Like routers, controllers are plugs, but they are wired to dispatch to a particular function which is called an action. For example, the route: get &quot;/users/:id&quot;, UserController, :show will invoke UserController as a plug: UserController.call(conn, :show) which will trigger the plug pipeline and which will eventually invoke the inner action plug that dispatches to the show/2 function in the UserController. As controllers are plugs, they implement both init/1 and call/2, and it also provides a function named action/2 which is responsible for dispatching the appropriate action after the plug stack (and is also overridable). Overriding action/2 for custom arguments Phoenix injects an action/2 plug in your controller which calls the function matched from the router. By default, it passes the conn and params. In some cases, overriding the action/2 plug in your controller is a useful way to inject arguments into your actions that you would otherwise need to repeatedly fetch off the connection. For example, imagine if you stored a conn.assigns.current_user in the connection and wanted quick access to the user for every action in your controller: def action(conn, _) do args = [conn, conn.params, conn.assigns.current_user] apply(__MODULE__, action_name(conn), args) end def index(conn, _params, user) do videos = Repo.all(user_videos(user)) # ... end def delete(conn, %{&quot;id&quot; =&gt; id}, user) do video = Repo.get!(user_videos(user), id) # ... end Rendering and layouts One of the main features provided by controllers is the ability to perform content negotiation and render templates based on information sent by the client. Read render/3 to learn more. It is also important not to confuse Phoenix.Controller.render/3 with Phoenix.View.render/3. The former expects a connection and relies on content negotiation while the latter is connection-agnostic and typically invoked from your views."},{"ref":"Phoenix.Controller.html#accepts/2","title":"Phoenix.Controller.accepts/2","type":"function","doc":"Performs content negotiation based on the available formats. It receives a connection, a list of formats that the server is capable of rendering and then proceeds to perform content negotiation based on the request information. If the client accepts any of the given formats, the request proceeds. If the request contains a &quot;_format&quot; parameter, it is considered to be the format desired by the client. If no &quot;_format&quot; parameter is available, this function will parse the &quot;accept&quot; header and find a matching format accordingly. It is important to notice that browsers have historically sent bad accept headers. For this reason, this function will default to &quot;html&quot; format whenever: the accepted list of arguments contains the &quot;html&quot; format the accept header specified more than one media type preceded or followed by the wildcard media type &quot;*/*&quot; This function raises Phoenix.NotAcceptableError, which is rendered with status 406, whenever the server cannot serve a response in any of the formats expected by the client. Examples accepts/2 can be invoked as a function: iex&gt; accepts(conn, [&quot;html&quot;, &quot;json&quot;]) or used as a plug: plug :accepts, [&quot;html&quot;, &quot;json&quot;] plug :accepts, ~w(html json) Custom media types It is possible to add custom media types to your Phoenix application. The first step is to teach Plug about those new media types in your config/config.exs file: config :mime, :types, %{ &quot;application/vnd.api+json&quot; =&gt; [&quot;json-api&quot;] } The key is the media type, the value is a list of formats the media type can be identified with. For example, by using &quot;json-api&quot;, you will be able to use templates with extension &quot;index.json-api&quot; or to force a particular format in a given URL by sending &quot;?_format=json-api&quot;. After this change, you must recompile plug: $ mix deps.clean mime --build $ mix deps.get And now you can use it in accepts too: plug :accepts, [&quot;html&quot;, &quot;json-api&quot;]"},{"ref":"Phoenix.Controller.html#action_fallback/1","title":"Phoenix.Controller.action_fallback/1","type":"macro","doc":"Registers the plug to call as a fallback to the controller action. A fallback plug is useful to translate common domain data structures into a valid %Plug.Conn{} response. If the controller action fails to return a %Plug.Conn{}, the provided plug will be called and receive the controller&#39;s %Plug.Conn{} as it was before the action was invoked along with the value returned from the controller action. Examples defmodule MyController do use Phoenix.Controller action_fallback MyFallbackController def show(conn, %{&quot;id&quot; =&gt; id}, current_user) do with {:ok, post} &lt;- Blog.fetch_post(id), :ok &lt;- Authorizer.authorize(current_user, :view, post) do render(conn, &quot;show.json&quot;, post: post) end end end In the above example, with is used to match only a successful post fetch, followed by valid authorization for the current user. In the event either of those fail to match, with will not invoke the render block and instead return the unmatched value. In this case, imagine Blog.fetch_post/2 returned {:error, :not_found} or Authorizer.authorize/3 returned {:error, :unauthorized}. For cases where these data structures serve as return values across multiple boundaries in our domain, a single fallback module can be used to translate the value into a valid response. For example, you could write the following fallback controller to handle the above values: defmodule MyFallbackController do use Phoenix.Controller def call(conn, {:error, :not_found}) do conn |&gt; put_status(:not_found) |&gt; put_view(MyErrorView) |&gt; render(:&quot;404&quot;) end def call(conn, {:error, :unauthorized}) do conn |&gt; put_status(403) |&gt; put_view(MyErrorView) |&gt; render(:&quot;403&quot;) end end"},{"ref":"Phoenix.Controller.html#action_name/1","title":"Phoenix.Controller.action_name/1","type":"function","doc":"Returns the action name as an atom, raises if unavailable."},{"ref":"Phoenix.Controller.html#allow_jsonp/2","title":"Phoenix.Controller.allow_jsonp/2","type":"function","doc":"A plug that may convert a JSON response into a JSONP one. In case a JSON response is returned, it will be converted to a JSONP as long as the callback field is present in the query string. The callback field itself defaults to &quot;callback&quot;, but may be configured with the callback option. In case there is no callback or the response is not encoded in JSON format, it is a no-op. Only alphanumeric characters and underscore are allowed in the callback name. Otherwise an exception is raised. Examples # Will convert JSON to JSONP if callback=someFunction is given plug :allow_jsonp # Will convert JSON to JSONP if cb=someFunction is given plug :allow_jsonp, callback: &quot;cb&quot;"},{"ref":"Phoenix.Controller.html#clear_flash/1","title":"Phoenix.Controller.clear_flash/1","type":"function","doc":"Clears all flash messages."},{"ref":"Phoenix.Controller.html#controller_module/1","title":"Phoenix.Controller.controller_module/1","type":"function","doc":"Returns the controller module as an atom, raises if unavailable."},{"ref":"Phoenix.Controller.html#current_path/1","title":"Phoenix.Controller.current_path/1","type":"function","doc":"Returns the current request path, with and without query params. By default, the connection&#39;s query params are included in the generated path. Custom query params may be used instead by providing a map of your own params. You may also retrieve only the request path by passing an empty map of params. Examples iex&gt; current_path(conn) &quot;/users/123?existing=param&quot; iex&gt; current_path(conn, %{new: &quot;param&quot;}) &quot;/users/123?new=param&quot; iex&gt; current_path(conn, %{filter: %{status: [&quot;draft&quot;, &quot;published&quot;}) &quot;/users/123?filter[status][]=draft&amp;filter[status][]=published&quot; iex&gt; current_path(conn, %{}) &quot;/users/123&quot;"},{"ref":"Phoenix.Controller.html#current_path/2","title":"Phoenix.Controller.current_path/2","type":"function","doc":""},{"ref":"Phoenix.Controller.html#current_url/1","title":"Phoenix.Controller.current_url/1","type":"function","doc":"Returns the current request url with its default query parameters: iex&gt; current_url(conn) &quot;https://www.example.com/users/123?existing=param&quot; See current_url/2 to override the default parameters."},{"ref":"Phoenix.Controller.html#current_url/2","title":"Phoenix.Controller.current_url/2","type":"function","doc":"Returns the current request URL, with and without query params. The path will be retrieved from the currently requested path via current_path/1. The scheme, host and others will be received from the URL configuration in your Phoenix endpoint. The reason we don&#39;t use the host and scheme information in the request is because most applications are behind proxies and the host and scheme may not actually reflect the host and scheme accessed by the client. If you want to access the url precisely as requested by the client, see Plug.Conn.request_url/1. Examples iex&gt; current_url(conn) &quot;https://www.example.com/users/123?existing=param&quot; iex&gt; current_url(conn, %{new: &quot;param&quot;}) &quot;https://www.example.com/users/123?new=param&quot; iex&gt; current_url(conn, %{}) &quot;https://www.example.com/users/123&quot; Custom URL Generation In some cases, you&#39;ll need to generate a request&#39;s URL, but using a different scheme, different host, etc. This can be accomplished in two ways. If you want to do so in a case-by-case basis, you can define a custom function that gets the endpoint URI configuration and changes it accordingly. For example, to get the current URL always in HTTPS format: def current_secure_url(conn, params \\\\ %{}) do cur_uri = MyAppWeb.Endpoint.struct_url() cur_path = Phoenix.Controller.current_path(conn, params) MyAppWeb.Router.Helpers.url(%URI{cur_uri | scheme: &quot;https&quot;}) &lt;&gt; cur_path end However, if you want all generated URLs to always have a certain schema, host, etc, you may invoke put_router_url/2."},{"ref":"Phoenix.Controller.html#delete_csrf_token/0","title":"Phoenix.Controller.delete_csrf_token/0","type":"function","doc":"Deletes the CSRF token from the process dictionary. Note: The token is deleted only after a response has been sent."},{"ref":"Phoenix.Controller.html#endpoint_module/1","title":"Phoenix.Controller.endpoint_module/1","type":"function","doc":"Returns the endpoint module as an atom, raises if unavailable."},{"ref":"Phoenix.Controller.html#fetch_flash/2","title":"Phoenix.Controller.fetch_flash/2","type":"function","doc":"Fetches the flash storage."},{"ref":"Phoenix.Controller.html#get_csrf_token/0","title":"Phoenix.Controller.get_csrf_token/0","type":"function","doc":"Gets or generates a CSRF token. If a token exists, it is returned, otherwise it is generated and stored in the process dictionary."},{"ref":"Phoenix.Controller.html#get_flash/1","title":"Phoenix.Controller.get_flash/1","type":"function","doc":"Returns a map of previously set flash messages or an empty map. Examples iex&gt; get_flash(conn) %{} iex&gt; conn = put_flash(conn, :info, &quot;Welcome Back!&quot;) iex&gt; get_flash(conn) %{&quot;info&quot; =&gt; &quot;Welcome Back!&quot;}"},{"ref":"Phoenix.Controller.html#get_flash/2","title":"Phoenix.Controller.get_flash/2","type":"function","doc":"Returns a message from flash by key. Examples iex&gt; conn = put_flash(conn, :info, &quot;Welcome Back!&quot;) iex&gt; get_flash(conn, :info) &quot;Welcome Back!&quot;"},{"ref":"Phoenix.Controller.html#get_format/1","title":"Phoenix.Controller.get_format/1","type":"function","doc":"Returns the request format, such as &quot;json&quot;, &quot;html&quot;."},{"ref":"Phoenix.Controller.html#html/2","title":"Phoenix.Controller.html/2","type":"function","doc":"Sends html response. Examples iex&gt; html(conn, &quot;&lt;html&gt;&lt;head&gt;...&quot;)"},{"ref":"Phoenix.Controller.html#json/2","title":"Phoenix.Controller.json/2","type":"function","doc":"Sends JSON response. It uses the configured :json_library under the :phoenix application for :json to pick up the encoder module. Examples iex&gt; json(conn, %{id: 123})"},{"ref":"Phoenix.Controller.html#layout/1","title":"Phoenix.Controller.layout/1","type":"function","doc":"Retrieves the current layout."},{"ref":"Phoenix.Controller.html#layout_formats/1","title":"Phoenix.Controller.layout_formats/1","type":"function","doc":"Retrieves current layout formats."},{"ref":"Phoenix.Controller.html#merge_flash/2","title":"Phoenix.Controller.merge_flash/2","type":"function","doc":"Merges a map into the flash. Returns the updated connection. Examples iex&gt; conn = merge_flash(conn, info: &quot;Welcome Back!&quot;) iex&gt; get_flash(conn, :info) &quot;Welcome Back!&quot;"},{"ref":"Phoenix.Controller.html#protect_from_forgery/2","title":"Phoenix.Controller.protect_from_forgery/2","type":"function","doc":"Enables CSRF protection. Currently used as a wrapper function for Plug.CSRFProtection and mainly serves as a function plug in YourApp.Router. Check get_csrf_token/0 and delete_csrf_token/0 for retrieving and deleting CSRF tokens."},{"ref":"Phoenix.Controller.html#put_flash/3","title":"Phoenix.Controller.put_flash/3","type":"function","doc":"Persists a value in flash. Returns the updated connection. Examples iex&gt; conn = put_flash(conn, :info, &quot;Welcome Back!&quot;) iex&gt; get_flash(conn, :info) &quot;Welcome Back!&quot;"},{"ref":"Phoenix.Controller.html#put_format/2","title":"Phoenix.Controller.put_format/2","type":"function","doc":"Puts the format in the connection. See get_format/1 for retrieval."},{"ref":"Phoenix.Controller.html#put_layout/2","title":"Phoenix.Controller.put_layout/2","type":"function","doc":"Stores the layout for rendering. The layout must be a tuple, specifying the layout view and the layout name, or false. In case a previous layout is set, put_layout also accepts the layout name to be given as a string or as an atom. If a string, it must contain the format. Passing an atom means the layout format will be found at rendering time, similar to the template in render/3. It can also be set to false. In this case, no layout would be used. Examples iex&gt; layout(conn) false iex&gt; conn = put_layout conn, {AppView, &quot;application.html&quot;} iex&gt; layout(conn) {AppView, &quot;application.html&quot;} iex&gt; conn = put_layout conn, &quot;print.html&quot; iex&gt; layout(conn) {AppView, &quot;print.html&quot;} iex&gt; conn = put_layout conn, :print iex&gt; layout(conn) {AppView, :print} Raises Plug.Conn.AlreadySentError if conn is already sent."},{"ref":"Phoenix.Controller.html#put_layout_formats/2","title":"Phoenix.Controller.put_layout_formats/2","type":"function","doc":"Sets which formats have a layout when rendering. Examples iex&gt; layout_formats(conn) [&quot;html&quot;] iex&gt; put_layout_formats(conn, [&quot;html&quot;, &quot;mobile&quot;]) iex&gt; layout_formats(conn) [&quot;html&quot;, &quot;mobile&quot;] Raises Plug.Conn.AlreadySentError if conn is already sent."},{"ref":"Phoenix.Controller.html#put_new_layout/2","title":"Phoenix.Controller.put_new_layout/2","type":"function","doc":"Stores the layout for rendering if one was not stored yet. Raises Plug.Conn.AlreadySentError if conn is already sent."},{"ref":"Phoenix.Controller.html#put_new_view/2","title":"Phoenix.Controller.put_new_view/2","type":"function","doc":"Stores the view for rendering if one was not stored yet. Raises Plug.Conn.AlreadySentError if conn is already sent."},{"ref":"Phoenix.Controller.html#put_router_url/2","title":"Phoenix.Controller.put_router_url/2","type":"function","doc":"Puts the URL or %URI{} to be used for route generation. This function overrides the default URL generation pulled from the %Plug.Conn{}&#39;s endpoint configuration. Examples Imagine your application is configured to run on &quot;example.com&quot; but after the user signs in, you want all links to use &quot;some_user.example.com&quot;. You can do so by setting the proper router url configuration: def put_router_url_by_user(conn) do put_router_url(conn, get_user_from_conn(conn).account_name &lt;&gt; &quot;.example.com&quot;) end Now when you call Routes.some_route_url(conn, ...), it will use the router url set above. Keep in mind that, if you want to generate routes to the current domain, it is preferred to use Routes.some_route_path helpers, as those are always relative."},{"ref":"Phoenix.Controller.html#put_secure_browser_headers/2","title":"Phoenix.Controller.put_secure_browser_headers/2","type":"function","doc":"Put headers that improve browser security. It sets the following headers: x-frame-options - set to SAMEORIGIN to avoid clickjacking through iframes unless in the same origin x-content-type-options - set to nosniff. This requires script and style tags to be sent with proper content type x-xss-protection - set to &quot;1; mode=block&quot; to improve XSS protection on both Chrome and IE x-download-options - set to noopen to instruct the browser not to open a download directly in the browser, to avoid HTML files rendering inline and accessing the security context of the application (like critical domain cookies) x-permitted-cross-domain-policies - set to none to restrict Adobe Flash Player’s access to data cross-origin-window-policy - set to deny to avoid window control attacks A custom headers map may also be given to be merged with defaults."},{"ref":"Phoenix.Controller.html#put_static_url/2","title":"Phoenix.Controller.put_static_url/2","type":"function","doc":"Puts the URL or %URI{} to be used for the static url generation. Using this function on a %Plug.Conn{} struct tells static_url/2 to use the given information for URL generation instead of the the %Plug.Conn{}&#39;s endpoint configuration (much like put_router_url/2 but for static URLs)."},{"ref":"Phoenix.Controller.html#put_view/2","title":"Phoenix.Controller.put_view/2","type":"function","doc":"Stores the view for rendering. Raises Plug.Conn.AlreadySentError if conn is already sent."},{"ref":"Phoenix.Controller.html#redirect/2","title":"Phoenix.Controller.redirect/2","type":"function","doc":"Sends redirect response to the given url. For security, :to only accepts paths. Use the :external option to redirect to any URL. Examples iex&gt; redirect(conn, to: &quot;/login&quot;) iex&gt; redirect(conn, external: &quot;http://elixir-lang.org&quot;)"},{"ref":"Phoenix.Controller.html#render/2","title":"Phoenix.Controller.render/2","type":"function","doc":"Render the given template or the default template specified by the current action with the given assigns. See render/3 for more information."},{"ref":"Phoenix.Controller.html#render/3","title":"Phoenix.Controller.render/3","type":"function","doc":"Renders the given template and assigns based on the conn information. Once the template is rendered, the template format is set as the response content type (for example, an HTML template will set &quot;text/html&quot; as response content type) and the data is sent to the client with default status of 200. Arguments conn - the Plug.Conn struct template - which may be an atom or a string. If an atom, like :index, it will render a template with the same format as the one returned by get_format/1. For example, for an HTML request, it will render the &quot;index.html&quot; template. If the template is a string, it must contain the extension too, like &quot;index.json&quot; assigns - a dictionary with the assigns to be used in the view. Those assigns are merged and have higher precedence than the connection assigns (conn.assigns) Examples defmodule MyAppWeb.UserController do use Phoenix.Controller def show(conn, _params) do render(conn, &quot;show.html&quot;, message: &quot;Hello&quot;) end end The example above renders a template &quot;show.html&quot; from the MyAppWeb.UserView and sets the response content type to &quot;text/html&quot;. In many cases, you may want the template format to be set dynamically based on the request. To do so, you can pass the template name as an atom (without the extension): def show(conn, _params) do render(conn, :show, message: &quot;Hello&quot;) end In order for the example above to work, we need to do content negotiation with the accepts plug before rendering. You can do so by adding the following to your pipeline (in the router): plug :accepts, [&quot;html&quot;] Views By default, Controllers render templates in a view with a similar name to the controller. For example, MyAppWeb.UserController will render templates inside the MyAppWeb.UserView. This information can be changed any time by using the put_view/2 function: def show(conn, _params) do conn |&gt; put_view(MyAppWeb.SpecialView) |&gt; render(:show, message: &quot;Hello&quot;) end put_view/2 can also be used as a plug: defmodule MyAppWeb.UserController do use Phoenix.Controller plug :put_view, MyAppWeb.SpecialView def show(conn, _params) do render(conn, :show, message: &quot;Hello&quot;) end end Layouts Templates are often rendered inside layouts. By default, Phoenix will render layouts for html requests. For example: defmodule MyAppWeb.UserController do use Phoenix.Controller def show(conn, _params) do render(conn, &quot;show.html&quot;, message: &quot;Hello&quot;) end end will render the &quot;show.html&quot; template inside an &quot;app.html&quot; template specified in MyAppWeb.LayoutView. put_layout/2 can be used to change the layout, similar to how put_view/2 can be used to change the view. layout_formats/1 and put_layout_formats/2 can be used to configure which formats support/require layout rendering (defaults to &quot;html&quot; only)."},{"ref":"Phoenix.Controller.html#render/4","title":"Phoenix.Controller.render/4","type":"function","doc":"WARNING: This function is deprecated in favor of render/3 + put_view/2. A shortcut that renders the given template in the given view. Equivalent to: conn |&gt; put_view(view) |&gt; render(template, assigns)"},{"ref":"Phoenix.Controller.html#router_module/1","title":"Phoenix.Controller.router_module/1","type":"function","doc":"Returns the router module as an atom, raises if unavailable."},{"ref":"Phoenix.Controller.html#scrub_params/2","title":"Phoenix.Controller.scrub_params/2","type":"function","doc":"Scrubs the parameters from the request. This process is two-fold: Checks to see if the required_key is present Changes empty parameters of required_key (recursively) to nils This function is useful for removing empty strings sent via HTML forms. If you are providing an API, there is likely no need to invoke scrub_params/2. If the required_key is not present, it will raise Phoenix.MissingParamError. Examples iex&gt; scrub_params(conn, &quot;user&quot;)"},{"ref":"Phoenix.Controller.html#send_download/3","title":"Phoenix.Controller.send_download/3","type":"function","doc":"Sends the given file or binary as a download. The second argument must be {:binary, contents}, where contents will be sent as download, or{:file, path}, where path is the filesystem location of the file to be sent. Be careful to not interpolate the path from external parameters, as it could allow traversal of the filesystem. The download is achieved by setting &quot;content-disposition&quot; to attachment. The &quot;content-type&quot; will also be set based on the extension of the given filename but can be customized via the :content_type and :charset options. Options :filename - the filename to be presented to the user as download :content_type - the content type of the file or binary sent as download. It is automatically inferred from the filename extension :disposition - specifies dispositon type (:attachment or :inline). If :attachment was used, user will be prompted to save the file. If :inline was used, the browser will attempt to open the file. Defaults to :attachment. :charset - the charset of the file, such as &quot;utf-8&quot;. Defaults to none :offset - the bytes to offset when reading. Defaults to 0 :length - the total bytes to read. Defaults to :all Examples To send a file that is stored inside your application priv directory: path = Application.app_dir(:my_app, &quot;priv/prospectus.pdf&quot;) send_download(conn, {:file, path}) When using {:file, path}, the filename is inferred from the given path but may also be set explicitly. To allow the user to download contents that are in memory as a binary or string: send_download(conn, {:binary, &quot;world&quot;}, filename: &quot;hello.txt&quot;) See Plug.Conn.send_file/3 and Plug.Conn.send_resp/3 if you would like to access the low-level functions used to send files and responses via Plug."},{"ref":"Phoenix.Controller.html#status_message_from_template/1","title":"Phoenix.Controller.status_message_from_template/1","type":"function","doc":"Generates a status message from the template name. Examples iex&gt; status_message_from_template(&quot;404.html&quot;) &quot;Not Found&quot; iex&gt; status_message_from_template(&quot;whatever.html&quot;) &quot;Internal Server Error&quot;"},{"ref":"Phoenix.Controller.html#text/2","title":"Phoenix.Controller.text/2","type":"function","doc":"Sends text response. Examples iex&gt; text(conn, &quot;hello&quot;) iex&gt; text(conn, :implements_to_string)"},{"ref":"Phoenix.Controller.html#view_module/1","title":"Phoenix.Controller.view_module/1","type":"function","doc":"Retrieves the current view."},{"ref":"Phoenix.Controller.html#view_template/1","title":"Phoenix.Controller.view_template/1","type":"function","doc":"Returns the template name rendered in the view as a string (or nil if no template was rendered)."},{"ref":"Phoenix.Endpoint.html","title":"Phoenix.Endpoint","type":"behaviour","doc":"Defines a Phoenix endpoint. The endpoint is the boundary where all requests to your web application start. It is also the interface your application provides to the underlying web servers. Overall, an endpoint has three responsibilities: to provide a wrapper for starting and stopping the endpoint as part of a supervision tree to define an initial plug pipeline for requests to pass through to host web specific configuration for your application Endpoints An endpoint is simply a module defined with the help of Phoenix.Endpoint. If you have used the mix phx.new generator, an endpoint was automatically generated as part of your application: defmodule YourApp.Endpoint do use Phoenix.Endpoint, otp_app: :your_app # plug ... # plug ... plug YourApp.Router end Endpoints must be explicitly started as part of your application supervision tree. Endpoints are added by default to the supervision tree in generated applications. Endpoints can be added to the supervision tree as follows: children = [ YourApp.Endpoint ] Endpoint configuration All endpoints are configured in your application environment. For example: config :your_app, YourApp.Endpoint, secret_key_base: &quot;kjoy3o1zeidquwy1398juxzldjlksahdk3&quot; Endpoint configuration is split into two categories. Compile-time configuration means the configuration is read during compilation and changing it at runtime has no effect. The compile-time configuration is mostly related to error handling. Runtime configuration, instead, is accessed during or after your application is started and can be read through the config/2 function: YourApp.Endpoint.config(:port) YourApp.Endpoint.config(:some_config, :default_value) Dynamic configuration For dynamically configuring the endpoint, such as loading data from environment variables or configuration files, Phoenix invokes the init/2 callback on the endpoint, passing a :supervisor atom as first argument and the endpoint configuration as second. All of Phoenix configuration, except the Compile-time configuration below can be set dynamically from the init/2 callback. Compile-time configuration :code_reloader - when true, enables code reloading functionality. For the list of code reloader configuration options see Phoenix.CodeReloader.reload!/1 :debug_errors - when true, uses Plug.Debugger functionality for debugging failures in the application. Recommended to be set to true only in development as it allows listing of the application source code during debugging. Defaults to false :render_errors - responsible for rendering templates whenever there is a failure in the application. For example, if the application crashes with a 500 error during a HTML request, render(&quot;500.html&quot;, assigns) will be called in the view given to :render_errors. Defaults to: [view: MyApp.ErrorView, accepts: ~w(html), layout: false] The default format is used when none is set in the connection Runtime configuration :cache_static_manifest - a path to a json manifest file that contains static files and their digested version. This is typically set to &quot;priv/static/cache_manifest.json&quot; which is the file automatically generated by mix phx.digest. It can be either: a string containing a file system path or a tuple containing the application name and the path within that application. :check_origin - configure transports to check origin header or not. May be false, true, a list of hosts that are allowed, or a function provided as MFA tuple. Hosts also support wildcards. For example, using a list of hosts: check_origin: [&quot;//phoenixframework.org&quot;, &quot;//*.example.com&quot;] or a custom MFA function: check_origin: {MyAppWeb.Auth, :my_check_origin?, []} The MFA is invoked with the request %URI{} as the first argument, followed by arguments in the MFA list Defaults to true. :http - the configuration for the HTTP server. Currently uses Cowboy and accepts all options as defined by Plug.Cowboy. Defaults to false :https - the configuration for the HTTPS server. Currently uses Cowboy and accepts all options as defined by Plug.Cowboy. Defaults to false :force_ssl - ensures no data is ever sent via HTTP, always redirecting to HTTPS. It expects a list of options which are forwarded to Plug.SSL. By default it sets the &quot;strict-transport-security&quot; header in HTTPS requests, forcing browsers to always use HTTPS. If an unsafe request (HTTP) is sent, it redirects to the HTTPS version using the :host specified in the :url configuration. To dynamically redirect to the host of the current request, set :host in the :force_ssl configuration to nil :secret_key_base - a secret key used as a base to generate secrets for encrypting and signing data. For example, cookies and tokens are signed by default, but they may also be encrypted if desired. Defaults to nil as it must be set per application :server - when true, starts the web server when the endpoint supervision tree starts. Defaults to false. The mix phx.server task automatically sets this to true :url - configuration for generating URLs throughout the app. Accepts the :host, :scheme, :path and :port options. All keys except :path can be changed at runtime. Defaults to: [host: &quot;localhost&quot;, path: &quot;/&quot;] The :port option requires either an integer, string, or {:system, &quot;ENV_VAR&quot;}. When given a tuple like {:system, &quot;PORT&quot;}, the port will be referenced from System.get_env(&quot;PORT&quot;) at runtime as a workaround for releases where environment specific information is loaded only at compile-time. The :host option requires a string or {:system, &quot;ENV_VAR&quot;}. Similar to :port, when given a tuple like {:system, &quot;HOST&quot;}, the host will be referenced from System.get_env(&quot;HOST&quot;) at runtime. The :scheme option accepts &quot;http&quot; and &quot;https&quot; values. Default value is infered from top level :http or :https option. It is useful when hosting Phoenix behind a load balancer or reverse proxy and terminating SSL there. The :path option can be used to override root path. Useful when hosting Phoenix behind a reverse proxy with URL rewrite rules :static_url - configuration for generating URLs for static files. It will fallback to url if no option is provided. Accepts the same options as url :watchers - a set of watchers to run alongside your server. It expects a list of tuples containing the executable and its arguments. Watchers are guaranteed to run in the application directory, but only when the server is enabled. For example, the watcher below will run the &quot;watch&quot; mode of the webpack build tool when the server starts. You can configure it to whatever build tool or command you want: [node: [&quot;node_modules/webpack/bin/webpack.js&quot;, &quot;--mode&quot;, &quot;development&quot;, &quot;--watch-stdin&quot;]] The :cd option can be used on a watcher to override the folder from which the watcher will run. By default this will be the project&#39;s root: File.cwd!() [node: [&quot;node_modules/webpack/bin/webpack.js&quot;, &quot;--mode&quot;, &quot;development&quot;, &quot;--watch-stdin&quot;], cd: &quot;my_frontend&quot;] :live_reload - configuration for the live reload option. Configuration requires a :patterns option which should be a list of file patterns to watch. When these files change, it will trigger a reload. If you are using a tool like pow in development, you may need to set the :url option appropriately. live_reload: [ url: &quot;ws://localhost:4000&quot;, patterns: [ ~r{priv/static/.*(js|css|png|jpeg|jpg|gif)$}, ~r{web/views/.*(ex)$}, ~r{web/templates/.*(eex)$} ] ] :pubsub - configuration for this endpoint&#39;s pubsub adapter. Configuration either requires a :name of the registered pubsub server or a :name and :adapter pair. The pubsub name and adapter are compile time configuration, while the remaining options are runtime. The given adapter and name pair will be started as part of the supervision tree. If no adapter is specified, the pubsub system will work by sending events and subscribing to the given name. Defaults to: [adapter: Phoenix.PubSub.PG2, name: MyApp.PubSub] It also supports custom adapter configuration: [name: :my_pubsub, adapter: Phoenix.PubSub.Redis, host: &quot;192.168.100.1&quot;] Endpoint API In the previous section, we have used the config/2 function that is automatically generated in your endpoint. Here&#39;s a list of all the functions that are automatically defined in your endpoint: for handling paths and URLs: struct_url/0, url/0, path/1, static_url/0,static_path/1, and static_integrity/1 for handling channel subscriptions: subscribe/2 and unsubscribe/1 for broadcasting to channels: broadcast/3, broadcast!/3, broadcast_from/4, and broadcast_from!/4 for configuration: start_link/0, config/2, and config_change/2 as required by the Plug behaviour: Plug.init/1 and Plug.call/2 Instrumentation Phoenix uses the :telemetry library for instrumentation. The following events are published by Phoenix with the following measurements and metadata: [:phoenix, :endpoint, :start] - dispatched by Plug.Telemetry in your endpoint at the beginning of every request. Measurement: %{time: System.monotonic_time} Metadata: %{conn: Plug.Conn.t} [:phoenix, :endpoint, :stop] - dispatched by Plug.Telemetry in your endpoint whenever the response is sent Measurement: %{duration: native_time} Metadata: %{conn: Plug.Conn.t} [:phoenix, :router_dispatch, :start] - dispatched by Phoenix.Router before dispatching to a matched route Measurement: %{time: System.monotonic_time} Metadata: %{conn: Plug.Conn.t, route: binary, plug: module, plug_opts: term, path_params: map, pipe_through: [atom]} [:phoenix, :router_dispatch, :stop] - dispatched by Phoenix.Router after successfully dispatching to a matched route Measurement: %{duration: native_time} Metadata: %{conn: Plug.Conn.t, route: binary, plug: module, plug_opts: term, path_params: map, pipe_through: [atom]} [:phoenix, :error_rendered] - dispatched at the end of an error view being rendered Measurement: %{duration: native_time} Metadata: %{status: Plug.Conn.status, kind: Exception.kind, reason: term, stacktrace: Exception.stacktrace} [:phoenix, :socket_connected] - dispatched at the end of a socket connection Measurement: %{duration: native_time} Metadata: %{endpoint: atom, transport: atom, params: term, connect_info: map, vsn: binary, user_socket: atom, result: :ok | :error, serializer: atom} [:phoenix, :channel_joined] - dispatched at the end of a channel join Measurement: %{duration: native_time} Metadata: %{params: term, socket: Phoenix.Socket.t} [:phoenix, :channel_handled_in] - dispatched at the end of a channel handle in Measurement: %{duration: native_time} Metadata: %{event: binary, params: term, socket: Phoenix.Socket.t}"},{"ref":"Phoenix.Endpoint.html#c:broadcast/3","title":"Phoenix.Endpoint.broadcast/3","type":"callback","doc":"Broadcasts a msg as event in the given topic."},{"ref":"Phoenix.Endpoint.html#c:broadcast!/3","title":"Phoenix.Endpoint.broadcast!/3","type":"callback","doc":"Broadcasts a msg as event in the given topic. Raises in case of failures."},{"ref":"Phoenix.Endpoint.html#c:broadcast_from/4","title":"Phoenix.Endpoint.broadcast_from/4","type":"callback","doc":"Broadcasts a msg from the given from as event in the given topic."},{"ref":"Phoenix.Endpoint.html#c:broadcast_from!/4","title":"Phoenix.Endpoint.broadcast_from!/4","type":"callback","doc":"Broadcasts a msg from the given from as event in the given topic. Raises in case of failures."},{"ref":"Phoenix.Endpoint.html#c:config/2","title":"Phoenix.Endpoint.config/2","type":"callback","doc":"Access the endpoint configuration given by key."},{"ref":"Phoenix.Endpoint.html#c:config_change/2","title":"Phoenix.Endpoint.config_change/2","type":"callback","doc":"Reload the endpoint configuration on application upgrades."},{"ref":"Phoenix.Endpoint.html#c:init/2","title":"Phoenix.Endpoint.init/2","type":"callback","doc":"Initialize the endpoint configuration. Invoked when the endpoint supervisor starts, allows dynamically configuring the endpoint from system environment or other runtime sources."},{"ref":"Phoenix.Endpoint.html#c:path/1","title":"Phoenix.Endpoint.path/1","type":"callback","doc":"Generates the path information when routing to this endpoint."},{"ref":"Phoenix.Endpoint.html#server?/2","title":"Phoenix.Endpoint.server?/2","type":"function","doc":"Checks if Endpoint&#39;s web server has been configured to start. otp_app - The OTP app running the endpoint, for example :my_app endpoint - The endpoint module, for example MyApp.Endpoint Examples iex&gt; Phoenix.Endpoint.server?(:my_app, MyApp.Endpoint) true"},{"ref":"Phoenix.Endpoint.html#socket/3","title":"Phoenix.Endpoint.socket/3","type":"macro","doc":"Defines a websocket/longpoll mount-point for a socket. Note: for backwards compatibility purposes, the :websocket and :longpoll options only have an effect if the socket given as argument has no transport declarations in it. Options :websocket - controls the websocket configuration. Defaults to true. May be false or a keyword list of options. See &quot;Shared configuration&quot; and &quot;WebSocket configuration&quot; for the whole list :longpoll - controls the longpoll configuration. Defaults to false. May be true or a keyword list of options. See &quot;Shared configuration&quot; and &quot;Longpoll configuration&quot; for the whole list :shutdown - the maximum shutdown time of each channel when the endpoint is shutting down. Applies only to channel-based sockets Examples socket &quot;/ws&quot;, MyApp.UserSocket socket &quot;/ws/admin&quot;, MyApp.AdminUserSocket, longpoll: true, websocket: [compress: true] Path params It is possible to include variables in the path, these will be available in the params that are passed to the socket. socket &quot;/ws/:user_id&quot;, MyApp.UserSocket, websocket: [path: &quot;/project/:project_id&quot;] Note: This feature is not supported with the Cowboy 1 adapter. Shared configuration The configuration below can be given to both :websocket and :longpoll keys: :path - the path to use for the transport. Will default to the transport name (&quot;/websocket&quot; or &quot;/longpoll&quot;) :serializer - a list of serializers for messages. See Phoenix.Socket for more information :transport_log - if the transport layer itself should log and, if so, the level :check_origin - if we should check the origin of requests when the origin header is present. It defaults to true and, in such cases, it will check against the host value in YourApp.Endpoint.config(:url)[:host]. It may be set to false (not recommended) or to a list of explicitly allowed origins. check_origin: [&quot;https://example.com&quot;, &quot;//another.com:888&quot;, &quot;//other.com&quot;] Note: To connect from a native app be sure to either have the native app set an origin or allow any origin via check_origin: false :code_reloader - enable or disable the code reloader. Defaults to your endpoint configuration :connect_info - a list of keys that represent data to be copied from the transport to be made available in the user socket connect/3 callback The valid keys are: :peer_data - the result of Plug.Conn.get_peer_data/1 :x_headers - all request headers that have an &quot;x-&quot; prefix :uri - a %URI{} with information from the conn {:session, session_config} - the session information from Plug.Conn. The session_config is an exact copy of the arguments given to Plug.Session. This requires the &quot;_csrf_token&quot; to be given as request parameter with the value of URI.encode_www_form(Plug.CSRFProtection.get_csrf_token()) when connecting to the socket. Otherwise the session will be nil. Arbitrary keywords may also appear following the above valid keys, which is useful for passing custom connection information to the socket. For example: socket &quot;/socket&quot;, AppWeb.UserSocket, websocket: [ connect_info: [:peer_data, :x_headers, :uri, session: [store: :cookie]] ] With arbitrary keywords: socket &quot;/socket&quot;, AppWeb.UserSocket, websocket: [ connect_info: [:uri, custom_value: &quot;abcdef&quot;] ] Websocket configuration The following configuration applies only to :websocket. :timeout - the timeout for keeping websocket connections open after it last received data, defaults to 60_000ms :max_frame_size - the maximum allowed frame size in bytes. Supported from Cowboy 2.3 onwards, defaults to &quot;infinity&quot; :compress - whether to enable per message compression on all data frames, defaults to false :subprotocols - a list of supported websocket subprotocols. Used for handshake Sec-WebSocket-Protocol response header, defaults to nil. For example: subprotocols: [&quot;sip&quot;, &quot;mqtt&quot;] Longpoll configuration The following configuration applies only to :longpoll: :window_ms - how long the client can wait for new messages in its poll request :pubsub_timeout_ms - how long a request can wait for the pubsub layer to respond :crypto - options for verifying and signing the token, accepted by Phoenix.Token. By default tokens are valid for 2 weeks"},{"ref":"Phoenix.Endpoint.html#c:start_link/0","title":"Phoenix.Endpoint.start_link/0","type":"callback","doc":"Starts the endpoint supervision tree. Starts endpoint&#39;s configuration cache and possibly the servers for handling requests."},{"ref":"Phoenix.Endpoint.html#c:static_integrity/1","title":"Phoenix.Endpoint.static_integrity/1","type":"callback","doc":"Generates an integrity hash to a static file in priv/static."},{"ref":"Phoenix.Endpoint.html#c:static_lookup/1","title":"Phoenix.Endpoint.static_lookup/1","type":"callback","doc":"Generates a two item tuple containing the static_path and static_integrity."},{"ref":"Phoenix.Endpoint.html#c:static_path/1","title":"Phoenix.Endpoint.static_path/1","type":"callback","doc":"Generates a route to a static file in priv/static."},{"ref":"Phoenix.Endpoint.html#c:static_url/0","title":"Phoenix.Endpoint.static_url/0","type":"callback","doc":"Generates the static URL without any path information."},{"ref":"Phoenix.Endpoint.html#c:struct_url/0","title":"Phoenix.Endpoint.struct_url/0","type":"callback","doc":"Generates the endpoint base URL, but as a URI struct."},{"ref":"Phoenix.Endpoint.html#c:subscribe/2","title":"Phoenix.Endpoint.subscribe/2","type":"callback","doc":"Subscribes the caller to the given topic. See Phoenix.PubSub.subscribe/3 for options."},{"ref":"Phoenix.Endpoint.html#c:unsubscribe/1","title":"Phoenix.Endpoint.unsubscribe/1","type":"callback","doc":"Unsubscribes the caller from the given topic."},{"ref":"Phoenix.Endpoint.html#c:url/0","title":"Phoenix.Endpoint.url/0","type":"callback","doc":"Generates the endpoint base URL without any path information."},{"ref":"Phoenix.Endpoint.html#t:event/0","title":"Phoenix.Endpoint.event/0","type":"type","doc":""},{"ref":"Phoenix.Endpoint.html#t:msg/0","title":"Phoenix.Endpoint.msg/0","type":"type","doc":""},{"ref":"Phoenix.Endpoint.html#t:topic/0","title":"Phoenix.Endpoint.topic/0","type":"type","doc":""},{"ref":"Phoenix.Logger.html","title":"Phoenix.Logger","type":"module","doc":"Instrumenter to handle logging of various instrumentation events. Parameter filtering When logging parameters, Phoenix can filter out sensitive parameters such as passwords and tokens. Parameters to be filtered can be added via the :filter_parameters option: config :phoenix, :filter_parameters, [&quot;password&quot;, &quot;secret&quot;] With the configuration above, Phoenix will filter any parameter that contains the terms password or secret. The match is case sensitive. Phoenix&#39;s default is [&quot;password&quot;]. Phoenix can filter all parameters by default and selectively keep parameters. This can be configured like so: config :phoenix, :filter_parameters, {:keep, [&quot;id&quot;, &quot;order&quot;]} With the configuration above, Phoenix will filter all parameters, except those that match exactly id or order. If a kept parameter matches, all parameters nested under that one will also be kept. Disabling When you are using custom logging system it is not always desirable to enable Phoenix.Logger by default. You can always disable this in general by: config :phoenix, :logger, false"},{"ref":"Phoenix.Logger.html#phoenix_channel_handled_in/4","title":"Phoenix.Logger.phoenix_channel_handled_in/4","type":"function","doc":""},{"ref":"Phoenix.Logger.html#phoenix_channel_joined/4","title":"Phoenix.Logger.phoenix_channel_joined/4","type":"function","doc":""},{"ref":"Phoenix.MissingParamError.html","title":"Phoenix.MissingParamError","type":"exception","doc":"Raised when a key is expected to be present in the request parameters, but is not. This exception is raised by Phoenix.Controller.scrub_params/2 which: Checks to see if the required_key is present (can be empty) Changes all empty parameters to nils (&quot;&quot; -&gt; nil) If you are seeing this error, you should handle the error and surface it to the end user. It means that there is a parameter missing from the request."},{"ref":"Phoenix.Naming.html","title":"Phoenix.Naming","type":"module","doc":"Conveniences for inflecting and working with names in Phoenix."},{"ref":"Phoenix.Naming.html#camelize/1","title":"Phoenix.Naming.camelize/1","type":"function","doc":"Converts a string to camel case. Takes an optional :lower flag to return lowerCamelCase. Examples iex&gt; Phoenix.Naming.camelize(&quot;my_app&quot;) &quot;MyApp&quot; iex&gt; Phoenix.Naming.camelize(&quot;my_app&quot;, :lower) &quot;myApp&quot; In general, camelize can be thought of as the reverse of underscore, however, in some cases formatting may be lost: Phoenix.Naming.underscore &quot;SAPExample&quot; #=&gt; &quot;sap_example&quot; Phoenix.Naming.camelize &quot;sap_example&quot; #=&gt; &quot;SapExample&quot;"},{"ref":"Phoenix.Naming.html#camelize/2","title":"Phoenix.Naming.camelize/2","type":"function","doc":""},{"ref":"Phoenix.Naming.html#humanize/1","title":"Phoenix.Naming.humanize/1","type":"function","doc":"Converts an attribute/form field into its humanize version. Examples iex&gt; Phoenix.Naming.humanize(:username) &quot;Username&quot; iex&gt; Phoenix.Naming.humanize(:created_at) &quot;Created at&quot; iex&gt; Phoenix.Naming.humanize(&quot;user_id&quot;) &quot;User&quot;"},{"ref":"Phoenix.Naming.html#resource_name/2","title":"Phoenix.Naming.resource_name/2","type":"function","doc":"Extracts the resource name from an alias. Examples iex&gt; Phoenix.Naming.resource_name(MyApp.User) &quot;user&quot; iex&gt; Phoenix.Naming.resource_name(MyApp.UserView, &quot;View&quot;) &quot;user&quot;"},{"ref":"Phoenix.Naming.html#underscore/1","title":"Phoenix.Naming.underscore/1","type":"function","doc":"Converts a string to underscore case. Examples iex&gt; Phoenix.Naming.underscore(&quot;MyApp&quot;) &quot;my_app&quot; In general, underscore can be thought of as the reverse of camelize, however, in some cases formatting may be lost: Phoenix.Naming.underscore &quot;SAPExample&quot; #=&gt; &quot;sap_example&quot; Phoenix.Naming.camelize &quot;sap_example&quot; #=&gt; &quot;SapExample&quot;"},{"ref":"Phoenix.Naming.html#unsuffix/2","title":"Phoenix.Naming.unsuffix/2","type":"function","doc":"Removes the given suffix from the name if it exists. Examples iex&gt; Phoenix.Naming.unsuffix(&quot;MyApp.User&quot;, &quot;View&quot;) &quot;MyApp.User&quot; iex&gt; Phoenix.Naming.unsuffix(&quot;MyApp.UserView&quot;, &quot;View&quot;) &quot;MyApp.User&quot;"},{"ref":"Phoenix.NotAcceptableError.html","title":"Phoenix.NotAcceptableError","type":"exception","doc":"Raised when one of the accept* headers is not accepted by the server. This exception is commonly raised by Phoenix.Controller.accepts/2 which negotiates the media types the server is able to serve with the contents the client is able to render. If you are seeing this error, you should check if you are listing the desired formats in your :accepts plug or if you are setting the proper accept header in the client. The exception contains the acceptable mime types in the accepts field."},{"ref":"Phoenix.Param.html","title":"Phoenix.Param","type":"protocol","doc":"A protocol that converts data structures into URL parameters. This protocol is used by URL helpers and other parts of the Phoenix stack. For example, when you write: user_path(conn, :edit, @user) Phoenix knows how to extract the :id from @user thanks to this protocol. By default, Phoenix implements this protocol for integers, binaries, atoms, and structs. For structs, a key :id is assumed, but you may provide a specific implementation. Nil values cannot be converted to param. Custom parameters In order to customize the parameter for any struct, one can simply implement this protocol. However, for convenience, this protocol can also be derivable. For example: defmodule User do @derive Phoenix.Param defstruct [:id, :username] end By default, the derived implementation will also use the :id key. In case the user does not contain an :id key, the key can be specified with an option: defmodule User do @derive {Phoenix.Param, key: :username} defstruct [:username] end will automatically use :username in URLs. When using Ecto, you must call @derive before your schema call: @derive {Phoenix.Param, key: :username} schema &quot;users&quot; do"},{"ref":"Phoenix.Param.html#to_param/1","title":"Phoenix.Param.to_param/1","type":"function","doc":""},{"ref":"Phoenix.Param.html#t:t/0","title":"Phoenix.Param.t/0","type":"type","doc":""},{"ref":"Phoenix.Presence.html","title":"Phoenix.Presence","type":"behaviour","doc":"Provides Presence tracking to processes and channels. This behaviour provides presence features such as fetching presences for a given topic, as well as handling diffs of join and leave events as they occur in real-time. Using this module defines a supervisor and a module that implements the Phoenix.Tracker behaviour that uses Phoenix.PubSub to broadcast presence updates. In case you want to use only a subset of the functionality provided by Phoenix.Presence, such as tracking processes but without broadcasting updates, we recommend that you look at the Phoenix.Tracker functionality from the phoenix_pubsub project. Example Usage Start by defining a presence module within your application which uses Phoenix.Presence and provide the :otp_app which holds your configuration, as well as the :pubsub_server. defmodule MyApp.Presence do use Phoenix.Presence, otp_app: :my_app, pubsub_server: MyApp.PubSub end The :pubsub_server must point to an existing pubsub server running in your application, which is included by default as MyApp.PubSub for new applications. Next, add the new supervisor to your supervision tree in lib/my_app/application.ex: children = [ ... MyApp.Presence, ] Once added, presences can be tracked in your channel after joining: defmodule MyApp.MyChannel do use MyAppWeb, :channel alias MyApp.Presence def join(&quot;some:topic&quot;, _params, socket) do send(self(), :after_join) {:ok, assign(socket, :user_id, ...)} end def handle_info(:after_join, socket) do push(socket, &quot;presence_state&quot;, Presence.list(socket)) {:ok, _} = Presence.track(socket, socket.assigns.user_id, %{ online_at: inspect(System.system_time(:second)) }) {:noreply, socket} end end In the example above, the current presence information for the socket&#39;s topic is pushed to the client as a &quot;presence_state&quot; event. Next, Presence.track is used to register this channel&#39;s process as a presence for the socket&#39;s user ID, with a map of metadata. Finally, a diff of presence join and leave events will be sent to the client as they happen in real-time with the &quot;presence_diff&quot; event. The diff structure will be a map of :joins and :leaves of the form: %{joins: %{&quot;123&quot; =&gt; %{metas: [%{status: &quot;away&quot;, phx_ref: ...}]}, leaves: %{&quot;456&quot; =&gt; %{metas: [%{status: &quot;online&quot;, phx_ref: ...}]}, See Phoenix.Presence.list/2 for more information on the presence data structure. Fetching Presence Information Presence metadata should be minimized and used to store small, ephemeral state, such as a user&#39;s &quot;online&quot; or &quot;away&quot; status. More detailed information, such as user details that need to be fetched from the database, can be achieved by overriding the fetch/2 function. The fetch/2 callback is triggered when using list/1 and serves as a mechanism to fetch presence information a single time, before broadcasting the information to all channel subscribers. This prevents N query problems and gives you a single place to group isolated data fetching to extend presence metadata. The function must return a map of data matching the outlined Presence data structure, including the :metas key, but can extend the map of information to include any additional information. For example: def fetch(_topic, presences) do query = from u in User, where: u.id in ^Map.keys(presences), select: {u.id, u} users = query |&gt; Repo.all() |&gt; Enum.into(%{}) for {key, %{metas: metas}} &lt;- presences, into: %{} do {key, %{metas: metas, user: users[key]}} end end The function above fetches all users from the database who have registered presences for the given topic. The fetched information is then extended with a :user key of the user&#39;s information, while maintaining the required :metas field from the original presence data."},{"ref":"Phoenix.Presence.html#c:fetch/2","title":"Phoenix.Presence.fetch/2","type":"callback","doc":"Extend presence information with additional data. When list/1 is used to list all presences of the given topic, this callback is triggered once to modify the result before it is broadcasted to all channel subscribers. This avoids N query problems and provides a single place to extend presence metadata. You must return a map of data matching the original result, including the :metas key, but can extend the map to include any additional information. The default implementation simply passes presences through unchanged. Example def fetch(_topic, presences) do query = from u in User, where: u.id in ^Map.keys(presences), select: {u.id, u} users = query |&gt; Repo.all() |&gt; Enum.into(%{}) for {key, %{metas: metas}} &lt;- presences, into: %{} do {key, %{metas: metas, user: users[key]}} end end"},{"ref":"Phoenix.Presence.html#get_by_key/3","title":"Phoenix.Presence.get_by_key/3","type":"function","doc":"Returns the map of presence metadata for a topic-key pair. Examples Uses the same data format as Phoenix.Presence.list/2, but only returns metadata for the presences under a topic and key pair. For example, a user with key &quot;user1&quot;, connected to the same chat room &quot;room:1&quot; from two devices, could return: iex&gt; MyPresence.get_by_key(&quot;room:1&quot;, &quot;user1&quot;) %{name: &quot;User 1&quot;, metas: [%{device: &quot;Desktop&quot;}, %{device: &quot;Mobile&quot;}]} Like Phoenix.Presence.list/2, the presence metadata is passed to the fetch callback of your presence module to fetch any additional information."},{"ref":"Phoenix.Presence.html#c:handle_diff/2","title":"Phoenix.Presence.handle_diff/2","type":"callback","doc":""},{"ref":"Phoenix.Presence.html#c:init/1","title":"Phoenix.Presence.init/1","type":"callback","doc":""},{"ref":"Phoenix.Presence.html#c:list/1","title":"Phoenix.Presence.list/1","type":"callback","doc":"Returns presences for a channel or topic. Calls list/2 with presence module."},{"ref":"Phoenix.Presence.html#list/2","title":"Phoenix.Presence.list/2","type":"function","doc":"Returns presences for a topic. Presence data structure The presence information is returned as a map with presences grouped by key, cast as a string, and accumulated metadata, with the following form: %{key =&gt; %{metas: [%{phx_ref: ..., ...}, ...]}} For example, imagine a user with id 123 online from two different devices, as well as a user with id 456 online from just one device. The following presence information might be returned: %{&quot;123&quot; =&gt; %{metas: [%{status: &quot;away&quot;, phx_ref: ...}, %{status: &quot;online&quot;, phx_ref: ...}]}, &quot;456&quot; =&gt; %{metas: [%{status: &quot;online&quot;, phx_ref: ...}]}} The keys of the map will usually point to a resource ID. The value will contain a map with a :metas key containing a list of metadata for each resource. Additionally, every metadata entry will contain a :phx_ref key which can be used to uniquely identify metadata for a given key. In the event that the metadata was previously updated, a :phx_ref_prev key will be present containing the previous :phx_ref value."},{"ref":"Phoenix.Presence.html#c:start_link/1","title":"Phoenix.Presence.start_link/1","type":"callback","doc":""},{"ref":"Phoenix.Presence.html#c:track/3","title":"Phoenix.Presence.track/3","type":"callback","doc":"Track a channel&#39;s process as a presence. Tracked presences are grouped by key, cast as a string. For example, to group each user&#39;s channels together, use user IDs as keys. Each presence can be associated with a map of metadata to store small, emphemeral state, such as a user&#39;s online status. To store detailed information, see fetch/2. Example alias MyApp.Presence def handle_info(:after_join, socket) do {:ok, _} = Presence.track(socket, socket.assigns.user_id, %{ online_at: inspect(System.system_time(:second)) }) {:noreply, socket} end"},{"ref":"Phoenix.Presence.html#c:track/4","title":"Phoenix.Presence.track/4","type":"callback","doc":"Track an arbitary process as a presence. Same with track/3, except track any process by topic and key."},{"ref":"Phoenix.Presence.html#c:untrack/2","title":"Phoenix.Presence.untrack/2","type":"callback","doc":"Stop tracking a channel&#39;s process."},{"ref":"Phoenix.Presence.html#c:untrack/3","title":"Phoenix.Presence.untrack/3","type":"callback","doc":"Stop tracking a process."},{"ref":"Phoenix.Presence.html#c:update/3","title":"Phoenix.Presence.update/3","type":"callback","doc":"Update a channel presence&#39;s metadata. Replace a presence&#39;s metadata by passing a new map or a function that takes the current map and returns a new one."},{"ref":"Phoenix.Presence.html#c:update/4","title":"Phoenix.Presence.update/4","type":"callback","doc":"Update a process presence&#39;s metadata. Same as update/3, but with an arbitary process."},{"ref":"Phoenix.Presence.html#t:presence/0","title":"Phoenix.Presence.presence/0","type":"type","doc":""},{"ref":"Phoenix.Presence.html#t:presences/0","title":"Phoenix.Presence.presences/0","type":"type","doc":""},{"ref":"Phoenix.Presence.html#t:topic/0","title":"Phoenix.Presence.topic/0","type":"type","doc":""},{"ref":"Phoenix.Router.html","title":"Phoenix.Router","type":"module","doc":"Defines a Phoenix router. The router provides a set of macros for generating routes that dispatch to specific controllers and actions. Those macros are named after HTTP verbs. For example: defmodule MyAppWeb.Router do use Phoenix.Router get &quot;/pages/:page&quot;, PageController, :show end The get/3 macro above accepts a request of format &quot;/pages/VALUE&quot; and dispatches it to the show action in the PageController. Routes can also match glob-like patterns, routing any path with a common base to the same controller. For example: get &quot;/dynamic*anything&quot;, DynamicController, :show Phoenix&#39;s router is extremely efficient, as it relies on Elixir pattern matching for matching routes and serving requests. Helpers Phoenix automatically generates a module Helpers inside your router which contains named helpers to help developers generate and keep their routes up to date. Helpers are automatically generated based on the controller name. For example, the route: get &quot;/pages/:page&quot;, PageController, :show will generate the following named helper: MyAppWeb.Router.Helpers.page_path(conn_or_endpoint, :show, &quot;hello&quot;) &quot;/pages/hello&quot; MyAppWeb.Router.Helpers.page_path(conn_or_endpoint, :show, &quot;hello&quot;, some: &quot;query&quot;) &quot;/pages/hello?some=query&quot; MyAppWeb.Router.Helpers.page_url(conn_or_endpoint, :show, &quot;hello&quot;) &quot;http://example.com/pages/hello&quot; MyAppWeb.Router.Helpers.page_url(conn_or_endpoint, :show, &quot;hello&quot;, some: &quot;query&quot;) &quot;http://example.com/pages/hello?some=query&quot; If the route contains glob-like patterns, parameters for those have to be given as list: MyAppWeb.Router.Helpers.dynamic_path(conn_or_endpoint, :show, [&quot;dynamic&quot;, &quot;something&quot;]) &quot;/dynamic/something&quot; The URL generated in the named URL helpers is based on the configuration for :url, :http and :https. However, if for some reason you need to manually control the URL generation, the url helpers also allow you to pass in a URI struct: uri = %URI{scheme: &quot;https&quot;, host: &quot;other.example.com&quot;} MyAppWeb.Router.Helpers.page_url(uri, :show, &quot;hello&quot;) &quot;https://other.example.com/pages/hello&quot; The named helper can also be customized with the :as option. Given the route: get &quot;/pages/:page&quot;, PageController, :show, as: :special_page the named helper will be: MyAppWeb.Router.Helpers.special_page_path(conn, :show, &quot;hello&quot;) &quot;/pages/hello&quot; Scopes and Resources It is very common in Phoenix applications to namespace all of your routes under the application scope: scope &quot;/&quot;, MyAppWeb do get &quot;/pages/:id&quot;, PageController, :show end The route above will dispatch to MyAppWeb.PageController. This syntax is not only convenient for developers, since we don&#39;t have to repeat the MyAppWeb. prefix on all routes, but it also allows Phoenix to put less pressure on the Elixir compiler. If instead we had written: get &quot;/pages/:id&quot;, MyAppWeb.PageController, :show The Elixir compiler would infer that the router depends directly on MyAppWeb.PageController, which is not true. By using scopes, Phoenix can properly hint to the Elixir compiler the controller is not an actual dependency of the router. This provides more efficient compilation times. Scopes allow us to scope on any path or even on the helper name: scope &quot;/api/v1&quot;, MyAppWeb, as: :api_v1 do get &quot;/pages/:id&quot;, PageController, :show end For example, the route above will match on the path &quot;/api/v1/pages/:id&quot; and the named route will be api_v1_page_path, as expected from the values given to scope/2 option. Phoenix also provides a resources/4 macro that allows developers to generate &quot;RESTful&quot; routes to a given resource: defmodule MyAppWeb.Router do use Phoenix.Router resources &quot;/pages&quot;, PageController, only: [:show] resources &quot;/users&quot;, UserController, except: [:delete] end Finally, Phoenix ships with a mix phx.routes task that nicely formats all routes in a given router. We can use it to verify all routes included in the router above: $ mix phx.routes page_path GET /pages/:id PageController.show/2 user_path GET /users UserController.index/2 user_path GET /users/:id/edit UserController.edit/2 user_path GET /users/new UserController.new/2 user_path GET /users/:id UserController.show/2 user_path POST /users UserController.create/2 user_path PATCH /users/:id UserController.update/2 PUT /users/:id UserController.update/2 One can also pass a router explicitly as an argument to the task: $ mix phx.routes MyAppWeb.Router Check scope/2 and resources/4 for more information. Pipelines and plugs Once a request arrives at the Phoenix router, it performs a series of transformations through pipelines until the request is dispatched to a desired end-point. Such transformations are defined via plugs, as defined in the Plug specification. Once a pipeline is defined, it can be piped through per scope. For example: defmodule MyAppWeb.Router do use Phoenix.Router pipeline :browser do plug :fetch_session plug :accepts, [&quot;html&quot;] end scope &quot;/&quot; do pipe_through :browser # browser related routes and resources end end Phoenix.Router imports functions from both Plug.Conn and Phoenix.Controller to help define plugs. In the example above, fetch_session/2 comes from Plug.Conn while accepts/2 comes from Phoenix.Controller. Note that router pipelines are only invoked after a route is found. No plug is invoked in case no matches were found."},{"ref":"Phoenix.Router.html#connect/4","title":"Phoenix.Router.connect/4","type":"macro","doc":"Generates a route to handle a connect request to the given path. connect(&quot;/events/:id&quot;, EventController, :action) See match/5 for options."},{"ref":"Phoenix.Router.html#delete/4","title":"Phoenix.Router.delete/4","type":"macro","doc":"Generates a route to handle a delete request to the given path. delete(&quot;/events/:id&quot;, EventController, :action) See match/5 for options."},{"ref":"Phoenix.Router.html#forward/4","title":"Phoenix.Router.forward/4","type":"macro","doc":"Forwards a request at the given path to a plug. All paths that match the forwarded prefix will be sent to the forwarded plug. This is useful for sharing a router between applications or even breaking a big router into smaller ones. The router pipelines will be invoked prior to forwarding the connection. However, we don&#39;t advise forwarding to another endpoint. The reason is that plugs defined by your app and the forwarded endpoint would be invoked twice, which may lead to errors. Examples scope &quot;/&quot;, MyApp do pipe_through [:browser, :admin] forward &quot;/admin&quot;, SomeLib.AdminDashboard forward &quot;/api&quot;, ApiRouter end"},{"ref":"Phoenix.Router.html#get/4","title":"Phoenix.Router.get/4","type":"macro","doc":"Generates a route to handle a get request to the given path. get(&quot;/events/:id&quot;, EventController, :action) See match/5 for options."},{"ref":"Phoenix.Router.html#head/4","title":"Phoenix.Router.head/4","type":"macro","doc":"Generates a route to handle a head request to the given path. head(&quot;/events/:id&quot;, EventController, :action) See match/5 for options."},{"ref":"Phoenix.Router.html#match/5","title":"Phoenix.Router.match/5","type":"macro","doc":"Generates a route match based on an arbitrary HTTP method. Useful for defining routes not included in the builtin macros. The catch-all verb, :*, may also be used to match all HTTP methods. Options :as - configures the named helper exclusively :log - the level to log the route dispatching under, may be set to false. Defaults to :debug :host - a string containing the host scope, or prefix host scope, ie &quot;foo.bar.com&quot;, &quot;foo.&quot; :private - a map of private data to merge into the connection when a route matches :assigns - a map of data to merge into the connection when a route matches :metadata - a map of metadata used by the telemetry events and returned by route_info/4 :trailing_slash - a boolean to flag whether or not the helper functions append a trailing slash. Defaults to false. Examples match(:move, &quot;/events/:id&quot;, EventController, :move) match(:*, &quot;/any&quot;, SomeController, :any)"},{"ref":"Phoenix.Router.html#options/4","title":"Phoenix.Router.options/4","type":"macro","doc":"Generates a route to handle a options request to the given path. options(&quot;/events/:id&quot;, EventController, :action) See match/5 for options."},{"ref":"Phoenix.Router.html#patch/4","title":"Phoenix.Router.patch/4","type":"macro","doc":"Generates a route to handle a patch request to the given path. patch(&quot;/events/:id&quot;, EventController, :action) See match/5 for options."},{"ref":"Phoenix.Router.html#pipe_through/1","title":"Phoenix.Router.pipe_through/1","type":"macro","doc":"Defines a list of plugs (and pipelines) to send the connection through. See pipeline/2 for more information."},{"ref":"Phoenix.Router.html#pipeline/2","title":"Phoenix.Router.pipeline/2","type":"macro","doc":"Defines a plug pipeline. Pipelines are defined at the router root and can be used from any scope. Examples pipeline :api do plug :token_authentication plug :dispatch end A scope may then use this pipeline as: scope &quot;/&quot; do pipe_through :api end Every time pipe_through/1 is called, the new pipelines are appended to the ones previously given."},{"ref":"Phoenix.Router.html#plug/2","title":"Phoenix.Router.plug/2","type":"macro","doc":"Defines a plug inside a pipeline. See pipeline/2 for more information."},{"ref":"Phoenix.Router.html#post/4","title":"Phoenix.Router.post/4","type":"macro","doc":"Generates a route to handle a post request to the given path. post(&quot;/events/:id&quot;, EventController, :action) See match/5 for options."},{"ref":"Phoenix.Router.html#put/4","title":"Phoenix.Router.put/4","type":"macro","doc":"Generates a route to handle a put request to the given path. put(&quot;/events/:id&quot;, EventController, :action) See match/5 for options."},{"ref":"Phoenix.Router.html#resources/2","title":"Phoenix.Router.resources/2","type":"macro","doc":"See resources/4."},{"ref":"Phoenix.Router.html#resources/3","title":"Phoenix.Router.resources/3","type":"macro","doc":"See resources/4."},{"ref":"Phoenix.Router.html#resources/4","title":"Phoenix.Router.resources/4","type":"macro","doc":"Defines &quot;RESTful&quot; routes for a resource. The given definition: resources &quot;/users&quot;, UserController will include routes to the following actions: GET /users =&gt; :index GET /users/new =&gt; :new POST /users =&gt; :create GET /users/:id =&gt; :show GET /users/:id/edit =&gt; :edit PATCH /users/:id =&gt; :update PUT /users/:id =&gt; :update DELETE /users/:id =&gt; :delete Options This macro accepts a set of options: :only - a list of actions to generate routes for, for example: [:show, :edit] :except - a list of actions to exclude generated routes from, for example: [:delete] :param - the name of the parameter for this resource, defaults to &quot;id&quot; :name - the prefix for this resource. This is used for the named helper and as the prefix for the parameter in nested resources. The default value is automatically derived from the controller name, i.e. UserController will have name &quot;user&quot; :as - configures the named helper exclusively :singleton - defines routes for a singleton resource that is looked up by the client without referencing an ID. Read below for more information Singleton resources When a resource needs to be looked up without referencing an ID, because it contains only a single entry in the given context, the :singleton option can be used to generate a set of routes that are specific to such single resource: GET /user =&gt; :show GET /user/new =&gt; :new POST /user =&gt; :create GET /user/edit =&gt; :edit PATCH /user =&gt; :update PUT /user =&gt; :update DELETE /user =&gt; :delete Usage example: resources &quot;/account&quot;, AccountController, only: [:show], singleton: true Nested Resources This macro also supports passing a nested block of route definitions. This is helpful for nesting children resources within their parents to generate nested routes. The given definition: resources &quot;/users&quot;, UserController do resources &quot;/posts&quot;, PostController end will include the following routes: user_post_path GET /users/:user_id/posts PostController :index user_post_path GET /users/:user_id/posts/:id/edit PostController :edit user_post_path GET /users/:user_id/posts/new PostController :new user_post_path GET /users/:user_id/posts/:id PostController :show user_post_path POST /users/:user_id/posts PostController :create user_post_path PATCH /users/:user_id/posts/:id PostController :update PUT /users/:user_id/posts/:id PostController :update user_post_path DELETE /users/:user_id/posts/:id PostController :delete"},{"ref":"Phoenix.Router.html#route_info/4","title":"Phoenix.Router.route_info/4","type":"function","doc":"Returns the compile-time route info and runtime path params for a request. A map of metadata is returned with the following keys: :log - the configured log level. For example :debug :path_params - the map of runtime path params :pipe_through - the list of pipelines for the route&#39;s scope, for example [:browser] :plug - the plug to dipatch the route to, for example AppWeb.PostController :plug_opts - the options to pass when calling the plug, for example: :index :route - the string route pattern, such as &quot;/posts/:id&quot; Examples iex&gt; Phoenix.Router.route_info(AppWeb.Router, &quot;GET&quot;, &quot;/posts/123&quot;, &quot;myhost&quot;) %{ log: :debug, path_params: %{&quot;id&quot; =&gt; &quot;123&quot;}, pipe_through: [:browser], plug: AppWeb.PostController, plug_opts: :show, route: &quot;/posts/:id&quot;, } iex&gt; Phoenix.Router.route_info(MyRouter, &quot;GET&quot;, &quot;/not-exists&quot;, &quot;myhost&quot;) :error"},{"ref":"Phoenix.Router.html#scope/2","title":"Phoenix.Router.scope/2","type":"macro","doc":"Defines a scope in which routes can be nested. Examples scope path: &quot;/api/v1&quot;, as: :api_v1, alias: API.V1 do get &quot;/pages/:id&quot;, PageController, :show end The generated route above will match on the path &quot;/api/v1/pages/:id&quot; and will dispatch to :show action in API.V1.PageController. A named helper api_v1_page_path will also be generated. Options The supported options are: :path - a string containing the path scope :as - a string or atom containing the named helper scope :alias - an alias (atom) containing the controller scope. When set, this value may be overridden per route by passing alias: false to route definitions, such as get, post, etc. :host - a string containing the host scope, or prefix host scope, ie &quot;foo.bar.com&quot;, &quot;foo.&quot; :private - a map of private data to merge into the connection when a route matches :assigns - a map of data to merge into the connection when a route matches :log - the level to log the route dispatching under, may be set to false. Defaults to :debug :trailing_slash - whether or not the helper functions append a trailing slash. Defaults to false."},{"ref":"Phoenix.Router.html#scope/3","title":"Phoenix.Router.scope/3","type":"macro","doc":"Define a scope with the given path. This function is a shortcut for: scope path: path do ... end Examples scope &quot;/api/v1&quot;, as: :api_v1, alias: API.V1 do get &quot;/pages/:id&quot;, PageController, :show end"},{"ref":"Phoenix.Router.html#scope/4","title":"Phoenix.Router.scope/4","type":"macro","doc":"Defines a scope with the given path and alias. This function is a shortcut for: scope path: path, alias: alias do ... end Examples scope &quot;/api/v1&quot;, API.V1, as: :api_v1 do get &quot;/pages/:id&quot;, PageController, :show end"},{"ref":"Phoenix.Router.html#scoped_alias/2","title":"Phoenix.Router.scoped_alias/2","type":"function","doc":"Returns the full alias with the current scope&#39;s aliased prefix. Useful for applying the same short-hand alias handling to other values besides the second argument in route definitions. Examples scope &quot;/&quot;, MyPrefix do get &quot;/&quot;, ProxyPlug, controller: scoped_alias(__MODULE__, MyController) end"},{"ref":"Phoenix.Router.html#trace/4","title":"Phoenix.Router.trace/4","type":"macro","doc":"Generates a route to handle a trace request to the given path. trace(&quot;/events/:id&quot;, EventController, :action) See match/5 for options."},{"ref":"Phoenix.Router.NoRouteError.html","title":"Phoenix.Router.NoRouteError","type":"exception","doc":"Exception raised when no route is found."},{"ref":"Phoenix.Socket.InvalidMessageError.html","title":"Phoenix.Socket.InvalidMessageError","type":"exception","doc":"Raised when the socket message is invalid."},{"ref":"Phoenix.Socket.PoolSupervisor.WorkerSupervisor.html","title":"Phoenix.Socket.PoolSupervisor.WorkerSupervisor","type":"module","doc":""},{"ref":"Phoenix.Socket.PoolSupervisor.WorkerSupervisor.html#init/1","title":"Phoenix.Socket.PoolSupervisor.WorkerSupervisor.init/1","type":"function","doc":"Callback implementation for c::supervisor.init/1."},{"ref":"Phoenix.Socket.PoolSupervisor.WorkerSupervisor.html#start_link/3","title":"Phoenix.Socket.PoolSupervisor.WorkerSupervisor.start_link/3","type":"function","doc":""},{"ref":"Phoenix.Template.UndefinedError.html","title":"Phoenix.Template.UndefinedError","type":"exception","doc":"Exception raised when a template cannot be found."},{"ref":"Phoenix.Template.UndefinedError.html#message/1","title":"Phoenix.Template.UndefinedError.message/1","type":"function","doc":"Callback implementation for Exception.message/1."},{"ref":"Phoenix.Token.html","title":"Phoenix.Token","type":"module","doc":"Tokens provide a way to generate and verify bearer tokens for use in Channels or API authentication. The data stored in the token is signed to prevent tampering but not encrypted. This means it is safe to store identification information (such as user IDs) but should not be used to store confidential information (such as credit card numbers). Example When generating a unique token for use in an API or Channel it is advised to use a unique identifier for the user, typically the id from a database. For example: iex&gt; user_id = 1 iex&gt; token = Phoenix.Token.sign(MyApp.Endpoint, &quot;user salt&quot;, user_id) iex&gt; Phoenix.Token.verify(MyApp.Endpoint, &quot;user salt&quot;, token, max_age: 86400) {:ok, 1} In that example we have a user&#39;s id, we generate a token and verify it using the secret key base configured in the given endpoint. We guarantee the token will only be valid for one day by setting a max age (recommended). The first argument to both sign/4 and verify/4 can be one of: the module name of a Phoenix endpoint (shown above) - where the secret key base is extracted from the endpoint Plug.Conn - where the secret key base is extracted from the endpoint stored in the connection Phoenix.Socket - where the secret key base is extracted from the endpoint stored in the socket a string, representing the secret key base itself. A key base with at least 20 randomly generated characters should be used to provide adequate entropy The second argument is a cryptographic salt which must be the same in both calls to sign/4 and verify/4. For instance, it may be called &quot;user auth&quot; when generating a token that will be used to authenticate users on channels or on your APIs. The third argument can be any term (string, int, list, etc.) that you wish to codify into the token. Upon valid verification, this same term will be extracted from the token. Usage Once a token is signed, we can send it to the client in multiple ways. One is via the meta tag: &lt;%= tag :meta, name: &quot;channel_token&quot;, content: Phoenix.Token.sign(@conn, &quot;user salt&quot;, @current_user.id) %&gt; Or an endpoint that returns it: def create(conn, params) do user = User.create(params) render(conn, &quot;user.json&quot;, %{token: Phoenix.Token.sign(conn, &quot;user salt&quot;, user.id), user: user}) end Once the token is sent, the client may now send it back to the server as an authentication mechanism. For example, we can use it to authenticate a user on a Phoenix channel: defmodule MyApp.UserSocket do use Phoenix.Socket def connect(%{&quot;token&quot; =&gt; token}, socket, _connect_info) do case Phoenix.Token.verify(socket, &quot;user salt&quot;, token, max_age: 86400) do {:ok, user_id} -&gt; socket = assign(socket, :user, Repo.get!(User, user_id)) {:ok, socket} {:error, _} -&gt; :error end end def connect(_params, _socket, _connect_info), do: :error end In this example, the phoenix.js client will send the token in the connect command which is then validated by the server. Phoenix.Token can also be used for validating APIs, handling password resets, e-mail confirmation and more."},{"ref":"Phoenix.Token.html#decrypt/4","title":"Phoenix.Token.decrypt/4","type":"function","doc":"Decrypts the original data from the token and verifies its integrity. Options :max_age - verifies the token only if it has been generated &quot;max age&quot; ago in seconds. A reasonable value is 1 day (86400 seconds) :key_iterations - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to 1000 :key_length - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to 32 :key_digest - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to :sha256"},{"ref":"Phoenix.Token.html#encrypt/4","title":"Phoenix.Token.encrypt/4","type":"function","doc":"Encodes, encrypts, and signs data into a token you can send to clients. Options :key_iterations - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to 1000 :key_length - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to 32 :key_digest - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to :sha256 :signed_at - set the timestamp of the token in seconds. Defaults to System.system_time(:second)"},{"ref":"Phoenix.Token.html#sign/4","title":"Phoenix.Token.sign/4","type":"function","doc":"Encodes and signs data into a token you can send to clients. Options :key_iterations - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to 1000 :key_length - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to 32 :key_digest - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to :sha256 :signed_at - set the timestamp of the token in seconds. Defaults to System.system_time(:second)"},{"ref":"Phoenix.Token.html#verify/4","title":"Phoenix.Token.verify/4","type":"function","doc":"Decodes the original data from the token and verifies its integrity. Examples In this scenario we will create a token, sign it, then provide it to a client application. The client will then use this token to authenticate requests for resources from the server. See Phoenix.Token summary for more info about creating tokens. iex&gt; user_id = 99 iex&gt; secret = &quot;kjoy3o1zeidquwy1398juxzldjlksahdk3&quot; iex&gt; user_salt = &quot;user salt&quot; iex&gt; token = Phoenix.Token.sign(secret, user_salt, user_id) The mechanism for passing the token to the client is typically through a cookie, a JSON response body, or HTTP header. For now, assume the client has received a token it can use to validate requests for protected resources. When the server receives a request, it can use verify/4 to determine if it should provide the requested resources to the client: iex&gt; Phoenix.Token.verify(secret, user_salt, token, max_age: 86400) {:ok, 99} In this example, we know the client sent a valid token because verify/4 returned a tuple of type {:ok, user_id}. The server can now proceed with the request. However, if the client had sent an expired or otherwise invalid token verify/4 would have returned an error instead: iex&gt; Phoenix.Token.verify(secret, user_salt, expired, max_age: 86400) {:error, :expired} iex&gt; Phoenix.Token.verify(secret, user_salt, invalid, max_age: 86400) {:error, :invalid} Options :max_age - verifies the token only if it has been generated &quot;max age&quot; ago in seconds. A reasonable value is 1 day (86400 seconds) :key_iterations - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to 1000 :key_length - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to 32 :key_digest - option passed to Plug.Crypto.KeyGenerator when generating the encryption and signing keys. Defaults to :sha256"},{"ref":"Phoenix.View.html","title":"Phoenix.View","type":"module","doc":"Defines the view layer of a Phoenix application. This module is used to define the application&#39;s main view, which serves as the base for all other views and templates. The view layer also contains conveniences for rendering templates, including support for layouts and encoders per format. Examples Phoenix defines the view template at lib/your_app_web.ex: defmodule YourAppWeb do # ... def view do quote do use Phoenix.View, root: &quot;lib/your_app_web/templates&quot;, namespace: &quot;web&quot; # Import convenience functions from controllers import Phoenix.Controller, only: [get_flash: 1, get_flash: 2, view_module: 1] # Use all HTML functionality (forms, tags, etc) use Phoenix.HTML import YourAppWeb.ErrorHelpers import YourAppWeb.Gettext # Alias the Helpers module as Routes alias YourAppWeb.Router.Helpers, as: Routes end end # ... end You can use the definition above to define any view in your application: defmodule YourApp.UserView do use YourAppWeb, :view end Because we have defined the template root to be &quot;lib/your_app_web/templates&quot;, Phoenix.View will automatically load all templates at &quot;your_app_web/templates/user&quot; and include them in the YourApp.UserView. For example, imagine we have the template: # your_app_web/templates/user/index.html.eex Hello &lt;%= @name %&gt; The .eex extension maps to a template engine which tells Phoenix how to compile the code in the file into Elixir source code. After it is compiled, the template can be rendered as: Phoenix.View.render(YourApp.UserView, &quot;index.html&quot;, name: &quot;John Doe&quot;) #=&gt; {:safe, &quot;Hello John Doe&quot;} Rendering The main responsibility of a view is to render a template. A template has a name, which also contains a format. For example, in the previous section we have rendered the &quot;index.html&quot; template: Phoenix.View.render(YourApp.UserView, &quot;index.html&quot;, name: &quot;John Doe&quot;) #=&gt; {:safe, &quot;Hello John Doe&quot;} When a view renders a template, the result returned is an inner representation specific to the template format. In the example above, we got: {:safe, &quot;Hello John Doe&quot;}. The safe tuple annotates that our template is safe and that we don&#39;t need to escape its contents because all data has already been encoded. Let&#39;s try to inject custom code: Phoenix.View.render(YourApp.UserView, &quot;index.html&quot;, name: &quot;John&lt;br/&gt;Doe&quot;) #=&gt; {:safe, &quot;Hello John&amp;lt;br/&amp;gt;Doe&quot;} This inner representation allows us to render and compose templates easily. For example, if you want to render JSON data, we could do so by adding a &quot;show.json&quot; entry to render/2 in our view: defmodule YourApp.UserView do use YourApp.View def render(&quot;show.json&quot;, %{user: user}) do %{name: user.name, address: user.address} end end Notice that in order to render JSON data, we don&#39;t need to explicitly return a JSON string! Instead, we just return data that is encodable to JSON. Both JSON and HTML formats will be encoded only when passing the data to the controller via the render_to_iodata/3 function. The render_to_iodata/3 function uses the notion of format encoders to convert a particular format to its string/iodata representation. Phoenix ships with some template engines and format encoders, which can be further configured in the Phoenix application. You can read more about format encoders in Phoenix.Template documentation."},{"ref":"Phoenix.View.html#__using__/1","title":"Phoenix.View.__using__/1","type":"macro","doc":"When used, defines the current module as a main view module. Options :root - the template root to find templates :path - the optional path to search for templates within the :root. Defaults to the underscored view module name. A blank string may be provided to use the :root path directly as the template lookup path :namespace - the namespace to consider when calculating view paths :pattern - the wildcard pattern to apply to the root when finding templates. Default &quot;*&quot; The :root option is required while the :namespace defaults to the first nesting in the module name. For instance, both MyApp.UserView and MyApp.Admin.UserView have namespace MyApp. The :namespace and :path options are used to calculate template lookup paths. For example, if you are in MyApp.UserView and the namespace is MyApp, templates are expected at Path.join(root, &quot;user&quot;). On the other hand, if the view is MyApp.Admin.UserView, the path will be Path.join(root, &quot;admin/user&quot;) and so on. For explicit root path locations, the :path option can be provided instead. The :root and :path are joined to form the final lookup path. A blank string may be provided to use the :root path directly as the template lookup path. Setting the namespace to MyApp.Admin in the second example will force the template to also be looked up at Path.join(root, &quot;user&quot;)."},{"ref":"Phoenix.View.html#render/3","title":"Phoenix.View.render/3","type":"function","doc":"Renders a template. It expects the view module, the template as a string, and a set of assigns. Notice that this function returns the inner representation of a template. If you want the encoded template as a result, use render_to_iodata/3 instead. Examples Phoenix.View.render(YourApp.UserView, &quot;index.html&quot;, name: &quot;John Doe&quot;) #=&gt; {:safe, &quot;Hello John Doe&quot;} Assigns Assigns are meant to be user data that will be available in templates. However, there are keys under assigns that are specially handled by Phoenix, they are: :layout - tells Phoenix to wrap the rendered result in the given layout. See next section The following assigns are reserved, and cannot be set directly: @view_module - The view module being rendered @view_template - The @view_module&#39;s template being rendered Layouts Templates can be rendered within other templates using the :layout option. :layout accepts a tuple of the form {LayoutModule, &quot;template.extension&quot;}. To render the template within the layout, simply call render/3 using the @view_module and @view_template assigns: &lt;%= render(@view_module, @view_template, assigns) %&gt;"},{"ref":"Phoenix.View.html#render_existing/3","title":"Phoenix.View.render_existing/3","type":"function","doc":"Renders a template only if it exists. Same as render/3, but returns nil instead of raising. Useful for dynamically rendering templates in the layout that may or may not be implemented by the @view_module view. Examples Consider the case where the application layout allows views to dynamically render a section of script tags in the head of the document. Some views may wish to inject certain scripts, while others will not. &lt;head&gt; &lt;%= render_existing @view_module, &quot;scripts.html&quot;, assigns %&gt; &lt;/head&gt; Then the module for the @view_module view can decide to provide scripts with either a precompiled template, or by implementing the function directly, ie: def render(&quot;scripts.html&quot;, _assigns) do ~E(&lt;script src=&quot;file.js&quot;&gt;&lt;/script&gt;) end To use a precompiled template, create a scripts.html.eex file in the templates directory for the corresponding view you want it to render for. For example, for the UserView, create the scripts.html.eex file at your_app_web/templates/user/. Rendering based on controller template In some cases, you might need to render based on the template. For these cases, @view_template can pair with render_existing/3 for per-template based content, ie: &lt;head&gt; &lt;%= render_existing @view_module, &quot;scripts.&quot; &lt;&gt; @view_template, assigns %&gt; &lt;/head&gt; def render(&quot;scripts.show.html&quot;, _assigns) do ~E(&lt;script src=&quot;file.js&quot;&gt;&lt;/script&gt;) end def render(&quot;scripts.index.html&quot;, _assigns) do ~E(&lt;script src=&quot;file.js&quot;&gt;&lt;/script&gt;) end"},{"ref":"Phoenix.View.html#render_many/4","title":"Phoenix.View.render_many/4","type":"function","doc":"Renders a collection. A collection is any enumerable of structs. This function returns the rendered collection in a list: render_many users, UserView, &quot;show.html&quot; is roughly equivalent to: Enum.map(users, fn user -&gt; render(UserView, &quot;show.html&quot;, user: user) end) The underlying user is passed to the view and template as :user, which is inferred from the view name. The name of the key in assigns can be customized with the :as option: render_many users, UserView, &quot;show.html&quot;, as: :data is roughly equivalent to: Enum.map(users, fn user -&gt; render(UserView, &quot;show.html&quot;, data: user) end)"},{"ref":"Phoenix.View.html#render_one/4","title":"Phoenix.View.render_one/4","type":"function","doc":"Renders a single item if not nil. The following: render_one user, UserView, &quot;show.html&quot; is roughly equivalent to: if user != nil do render(UserView, &quot;show.html&quot;, user: user) end The underlying user is passed to the view and template as :user, which is inflected from the view name. The name of the key in assigns can be customized with the :as option: render_one user, UserView, &quot;show.html&quot;, as: :data is roughly equivalent to: if user != nil do render(UserView, &quot;show.html&quot;, data: user) end"},{"ref":"Phoenix.View.html#render_to_iodata/3","title":"Phoenix.View.render_to_iodata/3","type":"function","doc":"Renders the template and returns iodata."},{"ref":"Phoenix.View.html#render_to_string/3","title":"Phoenix.View.render_to_string/3","type":"function","doc":"Renders the template and returns a string."},{"ref":"Phoenix.ChannelTest.html","title":"Phoenix.ChannelTest","type":"module","doc":"Conveniences for testing Phoenix channels. In channel tests, we interact with channels via process communication, sending and receiving messages. It is also common to subscribe to the same topic the channel subscribes to, allowing us to assert if a given message was broadcast or not. Channel testing To get started, define the module attribute @endpoint in your test case pointing to your application endpoint. Then you can directly create a socket and subscribe_and_join/4 topics and channels: {:ok, _, socket} = socket(UserSocket, &quot;user:id&quot;, %{some_assigns: 1}) |&gt; subscribe_and_join(RoomChannel, &quot;room:lobby&quot;, %{&quot;id&quot; =&gt; 3}) You usually want to set the same ID and assigns your UserSocket.connect/3 callback would set. Alternatively, you can use the connect/3 helper to call your UserSocket.connect/3 callback and initialize the socket with the socket id: {:ok, socket} = connect(UserSocket, %{&quot;some&quot; =&gt; &quot;params&quot;}, %{}) {:ok, _, socket} = subscribe_and_join(socket, &quot;room:lobby&quot;, %{&quot;id&quot; =&gt; 3}) Once called, subscribe_and_join/4 will subscribe the current test process to the &quot;room:lobby&quot; topic and start a channel in another process. It returns {:ok, reply, socket} or {:error, reply}. Now, in the same way the channel has a socket representing communication it will push to the client. Our test has a socket representing communication to be pushed to the server. For example, we can use the push/3 function in the test to push messages to the channel (it will invoke handle_in/3): push(socket, &quot;my_event&quot;, %{&quot;some&quot; =&gt; &quot;data&quot;}) Similarly, we can broadcast messages from the test itself on the topic that both test and channel are subscribed to, triggering handle_out/3 on the channel: broadcast_from(socket, &quot;my_event&quot;, %{&quot;some&quot; =&gt; &quot;data&quot;}) Note only broadcast_from/3 and broadcast_from!/3 are available in tests to avoid broadcast messages to be resent to the test process. While the functions above are pushing data to the channel (server) we can use assert_push/3 to verify the channel pushed a message to the client: assert_push &quot;my_event&quot;, %{&quot;some&quot; =&gt; &quot;data&quot;} Or even assert something was broadcast into pubsub: assert_broadcast &quot;my_event&quot;, %{&quot;some&quot; =&gt; &quot;data&quot;} Finally, every time a message is pushed to the channel, a reference is returned. We can use this reference to assert a particular reply was sent from the server: ref = push(socket, &quot;counter&quot;, %{}) assert_reply ref, :ok, %{&quot;counter&quot; =&gt; 1} Checking side-effects Often one may want to do side-effects inside channels, like writing to the database, and verify those side-effects during their tests. Imagine the following handle_in/3 inside a channel: def handle_in(&quot;publish&quot;, %{&quot;id&quot; =&gt; id}, socket) do Repo.get!(Post, id) |&gt; Post.publish() |&gt; Repo.update!() {:noreply, socket} end Because the whole communication is asynchronous, the following test would be very brittle: push(socket, &quot;publish&quot;, %{&quot;id&quot; =&gt; 3}) assert Repo.get_by(Post, id: 3, published: true) The issue is that we have no guarantees the channel has done processing our message after calling push/3. The best solution is to assert the channel sent us a reply before doing any other assertion. First change the channel to send replies: def handle_in(&quot;publish&quot;, %{&quot;id&quot; =&gt; id}, socket) do Repo.get!(Post, id) |&gt; Post.publish() |&gt; Repo.update!() {:reply, :ok, socket} end Then expect them in the test: ref = push(socket, &quot;publish&quot;, %{&quot;id&quot; =&gt; 3}) assert_reply ref, :ok assert Repo.get_by(Post, id: 3, published: true) Leave and close This module also provides functions to simulate leaving and closing a channel. Once you leave or close a channel, because the channel is linked to the test process on join, it will crash the test process: leave(socket) ** (EXIT from #PID&lt;...&gt;) {:shutdown, :leave} You can avoid this by unlinking the channel process in the test: Process.unlink(socket.channel_pid) Notice leave/1 is async, so it will also return a reference which you can use to check for a reply: ref = leave(socket) assert_reply ref, :ok On the other hand, close is always sync and it will return only after the channel process is guaranteed to have been terminated: :ok = close(socket) This mimics the behaviour existing in clients. To assert that your channel closes or errors asynchronously, you can monitor the channel process with the tools provided by Elixir, and wait for the :DOWN message. Imagine an implementation of the handle_info/2 function that closes the channel when it receives :some_message: def handle_info(:some_message, socket) do {:stop, :normal, socket} end In your test, you can assert that the close happened by: Process.monitor(socket.channel_pid) send(socket.channel_pid, :some_message) assert_receive {:DOWN, _, _, _, :normal}"},{"ref":"Phoenix.ChannelTest.html#assert_broadcast/3","title":"Phoenix.ChannelTest.assert_broadcast/3","type":"macro","doc":"Asserts the channel has broadcast a message within timeout. Before asserting anything was broadcast, we must first subscribe to the topic of the channel in the test process: @endpoint.subscribe(&quot;foo:ok&quot;) Now we can match on event and payload as patterns: assert_broadcast &quot;some_event&quot;, %{&quot;data&quot; =&gt; _} In the assertion above, we don&#39;t particularly care about the data being sent, as long as something was sent. The timeout is in milliseconds and defaults to the :assert_receive_timeout set on the :ex_unit application (which defaults to 100ms)."},{"ref":"Phoenix.ChannelTest.html#assert_push/3","title":"Phoenix.ChannelTest.assert_push/3","type":"macro","doc":"Asserts the channel has pushed a message back to the client with the given event and payload within timeout. Notice event and payload are patterns. This means one can write: assert_push &quot;some_event&quot;, %{&quot;data&quot; =&gt; _} In the assertion above, we don&#39;t particularly care about the data being sent, as long as something was sent. The timeout is in milliseconds and defaults to the :assert_receive_timeout set on the :ex_unit application (which defaults to 100ms). NOTE: Because event and payload are patterns, they will be matched. This means that if you wish to assert that the received payload is equivalent to an existing variable, you need to pin the variable in the assertion expression. Good: expected_payload = %{foo: &quot;bar&quot;} assert_push &quot;some_event&quot;, ^expected_payload Bad: expected_payload = %{foo: &quot;bar&quot;} assert_push &quot;some_event&quot;, expected_payload # The code above does not assert the payload matches the described map."},{"ref":"Phoenix.ChannelTest.html#assert_reply/4","title":"Phoenix.ChannelTest.assert_reply/4","type":"macro","doc":"Asserts the channel has replied to the given message within timeout. Notice status and payload are patterns. This means one can write: ref = push(channel, &quot;some_event&quot;) assert_reply ref, :ok, %{&quot;data&quot; =&gt; _} In the assertion above, we don&#39;t particularly care about the data being sent, as long as something was replied. The timeout is in milliseconds and defaults to the :assert_receive_timeout set on the :ex_unit application (which defaults to 100ms)."},{"ref":"Phoenix.ChannelTest.html#broadcast_from/3","title":"Phoenix.ChannelTest.broadcast_from/3","type":"function","doc":"Broadcast event from pid to all subscribers of the socket topic. The test process will not receive the published message. This triggers the handle_out/3 callback in the channel. Examples iex&gt; broadcast_from(socket, &quot;new_message&quot;, %{id: 1, content: &quot;hello&quot;}) :ok"},{"ref":"Phoenix.ChannelTest.html#broadcast_from!/3","title":"Phoenix.ChannelTest.broadcast_from!/3","type":"function","doc":"Same as broadcast_from/3, but raises if broadcast fails."},{"ref":"Phoenix.ChannelTest.html#close/2","title":"Phoenix.ChannelTest.close/2","type":"function","doc":"Emulates the client closing the socket. Closing socket is synchronous and has a default timeout of 5000 milliseconds."},{"ref":"Phoenix.ChannelTest.html#connect/3","title":"Phoenix.ChannelTest.connect/3","type":"macro","doc":"Initiates a transport connection for the socket handler. Useful for testing UserSocket authentication. Returns the result of the handler&#39;s connect/3 callback."},{"ref":"Phoenix.ChannelTest.html#join/2","title":"Phoenix.ChannelTest.join/2","type":"function","doc":"See join/4."},{"ref":"Phoenix.ChannelTest.html#join/3","title":"Phoenix.ChannelTest.join/3","type":"function","doc":"See join/4."},{"ref":"Phoenix.ChannelTest.html#join/4","title":"Phoenix.ChannelTest.join/4","type":"function","doc":"Joins the channel under the given topic and payload. The given channel is joined in a separate process which is linked to the test process. It returns {:ok, reply, socket} or {:error, reply}."},{"ref":"Phoenix.ChannelTest.html#leave/1","title":"Phoenix.ChannelTest.leave/1","type":"function","doc":"Emulates the client leaving the channel."},{"ref":"Phoenix.ChannelTest.html#push/3","title":"Phoenix.ChannelTest.push/3","type":"function","doc":"Pushes a message into the channel. The triggers the handle_in/3 callback in the channel. Examples iex&gt; push(socket, &quot;new_message&quot;, %{id: 1, content: &quot;hello&quot;}) reference"},{"ref":"Phoenix.ChannelTest.html#refute_broadcast/3","title":"Phoenix.ChannelTest.refute_broadcast/3","type":"macro","doc":"Asserts the channel has not broadcast a message within timeout. Like assert_broadcast, the event and payload are patterns. The timeout is in milliseconds and defaults to the :refute_receive_timeout set on the :ex_unit application (which defaults to 100ms). Keep in mind this macro will block the test by the timeout value, so use it only when necessary as overuse will certainly slow down your test suite."},{"ref":"Phoenix.ChannelTest.html#refute_push/3","title":"Phoenix.ChannelTest.refute_push/3","type":"macro","doc":"Asserts the channel has not pushed a message to the client matching the given event and payload within timeout. Like assert_push, the event and payload are patterns. The timeout is in milliseconds and defaults to the :refute_receive_timeout set on the :ex_unit application (which defaults to 100ms). Keep in mind this macro will block the test by the timeout value, so use it only when necessary as overuse will certainly slow down your test suite."},{"ref":"Phoenix.ChannelTest.html#refute_reply/4","title":"Phoenix.ChannelTest.refute_reply/4","type":"macro","doc":"Asserts the channel has not replied with a matching payload within timeout. Like assert_reply, the event and payload are patterns. The timeout is in milliseconds and defaults to the :refute_receive_timeout set on the :ex_unit application (which defaults to 100ms). Keep in mind this macro will block the test by the timeout value, so use it only when necessary as overuse will certainly slow down your test suite."},{"ref":"Phoenix.ChannelTest.html#socket/1","title":"Phoenix.ChannelTest.socket/1","type":"macro","doc":"Builds a socket for the given socket_module. The socket is then used to subscribe and join channels. Use this function when you want to create a blank socket to pass to functions like UserSocket.connect/3. Otherwise, use socket/3 if you want to build a socket with existing id and assigns. Examples socket(MyApp.UserSocket)"},{"ref":"Phoenix.ChannelTest.html#socket/3","title":"Phoenix.ChannelTest.socket/3","type":"macro","doc":"Builds a socket for the given socket_module with given id and assigns. Examples socket(MyApp.UserSocket, &quot;user_id&quot;, %{some: :assign})"},{"ref":"Phoenix.ChannelTest.html#subscribe_and_join/2","title":"Phoenix.ChannelTest.subscribe_and_join/2","type":"function","doc":"See subscribe_and_join/4."},{"ref":"Phoenix.ChannelTest.html#subscribe_and_join/3","title":"Phoenix.ChannelTest.subscribe_and_join/3","type":"function","doc":"See subscribe_and_join/4."},{"ref":"Phoenix.ChannelTest.html#subscribe_and_join/4","title":"Phoenix.ChannelTest.subscribe_and_join/4","type":"function","doc":"Subscribes to the given topic and joins the channel under the given topic and payload. By subscribing to the topic, we can use assert_broadcast/3 to verify a message has been sent through the pubsub layer. By joining the channel, we can interact with it directly. The given channel is joined in a separate process which is linked to the test process. If no channel module is provided, the socket&#39;s handler is used to lookup the matching channel for the given topic. It returns {:ok, reply, socket} or {:error, reply}."},{"ref":"Phoenix.ChannelTest.html#subscribe_and_join!/2","title":"Phoenix.ChannelTest.subscribe_and_join!/2","type":"function","doc":"See subscribe_and_join!/4."},{"ref":"Phoenix.ChannelTest.html#subscribe_and_join!/3","title":"Phoenix.ChannelTest.subscribe_and_join!/3","type":"function","doc":"See subscribe_and_join!/4."},{"ref":"Phoenix.ChannelTest.html#subscribe_and_join!/4","title":"Phoenix.ChannelTest.subscribe_and_join!/4","type":"function","doc":"Same as subscribe_and_join/4, but returns either the socket or throws an error. This is helpful when you are not testing joining the channel and just need the socket."},{"ref":"Phoenix.ConnTest.html","title":"Phoenix.ConnTest","type":"module","doc":"Conveniences for testing Phoenix endpoints and connection related helpers. You likely want to use this module or make it part of your ExUnit.CaseTemplate. Once used, this module automatically imports all functions defined here as well as the functions in Plug.Conn. Endpoint testing Phoenix.ConnTest typically works against endpoints. That&#39;s the preferred way to test anything that your router dispatches to: @endpoint MyAppWeb.Endpoint test &quot;says welcome on the home page&quot; do conn = get(build_conn(), &quot;/&quot;) assert conn.resp_body =~ &quot;Welcome!&quot; end test &quot;logs in&quot; do conn = post(build_conn(), &quot;/login&quot;, [username: &quot;john&quot;, password: &quot;doe&quot;]) assert conn.resp_body =~ &quot;Logged in!&quot; end The @endpoint module attribute contains the endpoint under testing, most commonly your application endpoint itself. If you are using the MyApp.ConnCase generated by Phoenix, it is automatically set for you. As in your router and controllers, the connection is the main abstraction in testing. build_conn() returns a new connection and functions in this module can be used to manipulate the connection before dispatching to the endpoint. For example, one could set the accepts header for json requests as follows: build_conn() |&gt; put_req_header(&quot;accept&quot;, &quot;application/json&quot;) |&gt; get(&quot;/&quot;) You can also create your own helpers, such as json_conn() that uses build_conn/0 and put_req_header/3, so you avoid repeating the connection setup throughout your tests. Controller testing The functions in this module can also be used for controller testing. While endpoint testing is preferred over controller testing, especially since the controller in Phoenix plays an integration role between your domain and your views, unit testing controllers may be helpful in some situations. For such cases, you need to set the @endpoint attribute to your controller and pass an atom representing the action to dispatch: @endpoint MyAppWeb.HomeController test &quot;says welcome on the home page&quot; do conn = get(build_conn(), :index) assert conn.resp_body =~ &quot;Welcome!&quot; end Keep in mind that, once the @endpoint variable is set, all tests after setting it will be affected. Views testing Under other circumstances, you may be testing a view or another layer that requires a connection for processing. For such cases, a connection can be created using the conn/3 helper: MyApp.UserView.render(&quot;hello.html&quot;, conn: build_conn(:get, &quot;/&quot;)) While build_conn/0 returns a connection with no request information to it, build_conn/2 returns a connection with the given request information already filled in. Recycling Browsers implement a storage by using cookies. When a cookie is set in the response, the browser stores it and sends it in the next request. To emulate this behaviour, this module provides the idea of recycling. The recycle/1 function receives a connection and returns a new connection, similar to the one returned by build_conn/0 with all the response cookies from the previous connection defined as request headers. This is useful when testing multiple routes that require cookies or session to work. Keep in mind Phoenix will automatically recycle the connection between dispatches. This usually works out well most times, but it may discard information if you are modifying the connection before the next dispatch: # No recycling as the connection is fresh conn = get(build_conn(), &quot;/&quot;) # The connection is recycled, creating a new one behind the scenes conn = post(conn, &quot;/login&quot;) # We can also recycle manually in case we want custom headers conn = conn |&gt; recycle() |&gt; put_req_header(&quot;x-special&quot;, &quot;nice&quot;) # No recycling as we did it explicitly conn = delete(conn, &quot;/logout&quot;) Recycling also recycles the &quot;accept&quot; and &quot;authorization&quot; headers, as well as peer data information."},{"ref":"Phoenix.ConnTest.html#assert_error_sent/2","title":"Phoenix.ConnTest.assert_error_sent/2","type":"function","doc":"Asserts an error was wrapped and sent with the given status. Useful for testing actions that you expect raise an error and have the response wrapped in an HTTP status, with content usually rendered by your MyApp.ErrorView. The function accepts a status either as an integer HTTP status or atom, such as 404 or :not_found. The list of allowed atoms is available in Plug.Conn.Status. If an error is raised, a 3-tuple of the wrapped response is returned matching the status, headers, and body of the response: {404, [{&quot;content-type&quot;, &quot;text/html&quot;} | _], &quot;Page not found&quot;} Examples assert_error_sent :not_found, fn -&gt; get(build_conn(), &quot;/users/not-found&quot;) end response = assert_error_sent 404, fn -&gt; get(build_conn(), &quot;/users/not-found&quot;) end assert {404, [_h | _t], &quot;Page not found&quot;} = response"},{"ref":"Phoenix.ConnTest.html#build_conn/0","title":"Phoenix.ConnTest.build_conn/0","type":"function","doc":"Creates a connection to be used in upcoming requests."},{"ref":"Phoenix.ConnTest.html#build_conn/3","title":"Phoenix.ConnTest.build_conn/3","type":"function","doc":"Creates a connection to be used in upcoming requests with a preset method, path and body. This is useful when a specific connection is required for testing a plug or a particular function."},{"ref":"Phoenix.ConnTest.html#bypass_through/1","title":"Phoenix.ConnTest.bypass_through/1","type":"function","doc":"Calls the Endpoint and Router pipelines. Useful for unit testing Plugs where Endpoint and/or router pipeline plugs are required for proper setup. Note the use of get(&quot;/&quot;) following bypass_through in the examples below. To execute the plug pipelines, you must issue a request against the router. Most often, you can simply send a GET request against the root path, but you may also specify a different method or path which your pipelines may operate against. Examples For example, imagine you are testing an authentication plug in isolation, but you need to invoke the Endpoint plugs and router Ripelines to set up session and flash related dependencies. One option is to invoke an existing route that uses the proper pipelines. You can do so by passing the connection and the router name to bypass_through: conn = conn |&gt; bypass_through(MyAppWeb.Router) |&gt; get(&quot;/some_url&quot;) |&gt; MyApp.RequireAuthentication.call([]) assert conn.halted You can also specify which pipelines you want to run: conn = conn |&gt; bypass_through(MyAppWeb.Router, [:browser]) |&gt; get(&quot;/&quot;) |&gt; MyApp.RequireAuthentication.call([]) assert conn.halted Alternatively, you could only invoke the Endpoint&#39;s plugs: conn = conn |&gt; bypass_through() |&gt; get(&quot;/&quot;) |&gt; MyApp.RequireAuthentication.call([]) assert conn.halted"},{"ref":"Phoenix.ConnTest.html#bypass_through/2","title":"Phoenix.ConnTest.bypass_through/2","type":"function","doc":"Calls the Endpoint and Router pipelines for the current route. See bypass_through/1."},{"ref":"Phoenix.ConnTest.html#bypass_through/3","title":"Phoenix.ConnTest.bypass_through/3","type":"function","doc":"Calls the Endpoint and the given Router pipelines. See bypass_through/1."},{"ref":"Phoenix.ConnTest.html#clear_flash/1","title":"Phoenix.ConnTest.clear_flash/1","type":"function","doc":"Clears up the flash storage."},{"ref":"Phoenix.ConnTest.html#conn/0","title":"Phoenix.ConnTest.conn/0","type":"function","doc":"Deprecated version of conn/0. Use build_conn/0 instead."},{"ref":"Phoenix.ConnTest.html#conn/3","title":"Phoenix.ConnTest.conn/3","type":"function","doc":"Deprecated version of conn/3. Use build_conn/3 instead."},{"ref":"Phoenix.ConnTest.html#connect/3","title":"Phoenix.ConnTest.connect/3","type":"macro","doc":"Dispatches to the current endpoint. See dispatch/5 for more information."},{"ref":"Phoenix.ConnTest.html#delete/3","title":"Phoenix.ConnTest.delete/3","type":"macro","doc":"Dispatches to the current endpoint. See dispatch/5 for more information."},{"ref":"Phoenix.ConnTest.html#delete_req_cookie/2","title":"Phoenix.ConnTest.delete_req_cookie/2","type":"function","doc":"Deletes a request cookie."},{"ref":"Phoenix.ConnTest.html#dispatch/5","title":"Phoenix.ConnTest.dispatch/5","type":"function","doc":"Dispatches the connection to the given endpoint. When invoked via get/3, post/3 and friends, the endpoint is automatically retrieved from the @endpoint module attribute, otherwise it must be given as an argument. The connection will be configured with the given method, path_or_action and params_or_body. If path_or_action is a string, it is considered to be the request path and stored as so in the connection. If an atom, it is assumed to be an action and the connection is dispatched to the given action. Parameters and body This function, as well as get/3, post/3 and friends, accepts the request body or parameters as last argument: get(build_conn(), &quot;/&quot;, some: &quot;param&quot;) get(build_conn(), &quot;/&quot;, &quot;some=param&amp;url=encoded&quot;) The allowed values are: nil - meaning there is no body a binary - containing a request body. For such cases, :headers must be given as option with a content-type a map or list - containing the parameters which will automatically set the content-type to multipart. The map or list may contain other lists or maps and all entries will be normalized to string keys a struct - unlike other maps, a struct will be passed through as-is without normalizing its entries"},{"ref":"Phoenix.ConnTest.html#ensure_recycled/1","title":"Phoenix.ConnTest.ensure_recycled/1","type":"function","doc":"Ensures the connection is recycled if it wasn&#39;t already. See recycle/1 for more information."},{"ref":"Phoenix.ConnTest.html#fetch_flash/1","title":"Phoenix.ConnTest.fetch_flash/1","type":"function","doc":"Fetches the flash storage."},{"ref":"Phoenix.ConnTest.html#get/3","title":"Phoenix.ConnTest.get/3","type":"macro","doc":"Dispatches to the current endpoint. See dispatch/5 for more information."},{"ref":"Phoenix.ConnTest.html#get_flash/1","title":"Phoenix.ConnTest.get_flash/1","type":"function","doc":"Gets the whole flash storage."},{"ref":"Phoenix.ConnTest.html#get_flash/2","title":"Phoenix.ConnTest.get_flash/2","type":"function","doc":"Gets the given key from the flash storage."},{"ref":"Phoenix.ConnTest.html#head/3","title":"Phoenix.ConnTest.head/3","type":"macro","doc":"Dispatches to the current endpoint. See dispatch/5 for more information."},{"ref":"Phoenix.ConnTest.html#html_response/2","title":"Phoenix.ConnTest.html_response/2","type":"function","doc":"Asserts the given status code, that we have an html response and returns the response body if one was set or sent. Examples assert html_response(conn, 200) =~ &quot;&lt;html&gt;&quot;"},{"ref":"Phoenix.ConnTest.html#json_response/2","title":"Phoenix.ConnTest.json_response/2","type":"function","doc":"Asserts the given status code, that we have a json response and returns the decoded JSON response if one was set or sent. Examples body = json_response(conn, 200) assert &quot;can&#39;t be blank&quot; in body[&quot;errors&quot;]"},{"ref":"Phoenix.ConnTest.html#options/3","title":"Phoenix.ConnTest.options/3","type":"macro","doc":"Dispatches to the current endpoint. See dispatch/5 for more information."},{"ref":"Phoenix.ConnTest.html#patch/3","title":"Phoenix.ConnTest.patch/3","type":"macro","doc":"Dispatches to the current endpoint. See dispatch/5 for more information."},{"ref":"Phoenix.ConnTest.html#post/3","title":"Phoenix.ConnTest.post/3","type":"macro","doc":"Dispatches to the current endpoint. See dispatch/5 for more information."},{"ref":"Phoenix.ConnTest.html#put/3","title":"Phoenix.ConnTest.put/3","type":"macro","doc":"Dispatches to the current endpoint. See dispatch/5 for more information."},{"ref":"Phoenix.ConnTest.html#put_flash/3","title":"Phoenix.ConnTest.put_flash/3","type":"function","doc":"Puts the given value under key in the flash storage."},{"ref":"Phoenix.ConnTest.html#put_req_cookie/3","title":"Phoenix.ConnTest.put_req_cookie/3","type":"function","doc":"Puts a request cookie."},{"ref":"Phoenix.ConnTest.html#recycle/2","title":"Phoenix.ConnTest.recycle/2","type":"function","doc":"Recycles the connection. Recycling receives a connection and returns a new connection, containing cookies and relevant information from the given one. This emulates behaviour performed by browsers where cookies returned in the response are available in following requests. By default, only the headers &quot;accept&quot;, &quot;accept-language&quot;, and &quot;authorization&quot; are recycled. However, a custom set of headers can be specified by passing a list of strings representing its names as the second argument of the function. Note recycle/1 is automatically invoked when dispatching to the endpoint, unless the connection has already been recycled."},{"ref":"Phoenix.ConnTest.html#redirected_params/1","title":"Phoenix.ConnTest.redirected_params/1","type":"function","doc":"Returns the matched params from the URL the connection was redirected to. Uses the provided %Plug.Conn{}s router matched in the previous request. Raises if the response&#39;s location header is not set. Examples assert redirected_to(conn) =~ &quot;/posts/123&quot; assert %{id: &quot;123&quot;} = redirected_params(conn)"},{"ref":"Phoenix.ConnTest.html#redirected_to/2","title":"Phoenix.ConnTest.redirected_to/2","type":"function","doc":"Returns the location header from the given redirect response. Raises if the response does not match the redirect status code (defaults to 302). Examples assert redirected_to(conn) =~ &quot;/foo/bar&quot; assert redirected_to(conn, 301) =~ &quot;/foo/bar&quot; assert redirected_to(conn, :moved_permanently) =~ &quot;/foo/bar&quot;"},{"ref":"Phoenix.ConnTest.html#response/2","title":"Phoenix.ConnTest.response/2","type":"function","doc":"Asserts the given status code and returns the response body if one was set or sent. Examples conn = get(build_conn(), &quot;/&quot;) assert response(conn, 200) =~ &quot;hello world&quot;"},{"ref":"Phoenix.ConnTest.html#response_content_type/2","title":"Phoenix.ConnTest.response_content_type/2","type":"function","doc":"Returns the content type as long as it matches the given format. Examples # Assert we have an html response with utf-8 charset assert response_content_type(conn, :html) =~ &quot;charset=utf-8&quot;"},{"ref":"Phoenix.ConnTest.html#text_response/2","title":"Phoenix.ConnTest.text_response/2","type":"function","doc":"Asserts the given status code, that we have a text response and returns the response body if one was set or sent. Examples assert text_response(conn, 200) =~ &quot;hello&quot;"},{"ref":"Phoenix.ConnTest.html#trace/3","title":"Phoenix.ConnTest.trace/3","type":"macro","doc":"Dispatches to the current endpoint. See dispatch/5 for more information."},{"ref":"Phoenix.CodeReloader.html","title":"Phoenix.CodeReloader","type":"module","doc":"A plug and module to handle automatic code reloading. For each request, Phoenix goes through all modules and checks if any of them implement a __phoenix_recompile__?/0 function. If they do and it returns true, the module source file is touched, forcing it to be recompiled. For this functionality to work, Phoenix requires you to add the :phoenix compiler to your list of compilers: compilers: [:phoenix] ++ Mix.compilers() This is useful, for example, to recompile modules that depend on external systems, such as directories, databases, etc. Note if you simply depend on external files, @external_resource annotation should be used. To avoid race conditions, all code reloads are funneled through a sequential call operation."},{"ref":"Phoenix.CodeReloader.html#call/2","title":"Phoenix.CodeReloader.call/2","type":"function","doc":"API used by Plug to invoke the code reloader on every request."},{"ref":"Phoenix.CodeReloader.html#init/1","title":"Phoenix.CodeReloader.init/1","type":"function","doc":"API used by Plug to start the code reloader."},{"ref":"Phoenix.CodeReloader.html#reload!/1","title":"Phoenix.CodeReloader.reload!/1","type":"function","doc":"Reloads code for the current Mix project by invoking the :reloadable_compilers on the list of :reloadable_apps. This is configured in your application environment like: config :your_app, YourApp.Endpoint, reloadable_compilers: [:gettext, :phoenix, :elixir], reloadable_apps: [:ui, :backend] Keep in mind :reloadable_compilers must be a subset of the :compilers specified in project/0 in your mix.exs. The :reloadable_apps defaults to nil. In such case default behaviour is to reload current project if it consists of single app, or all applications within umbrella project. You can set :reloadable_apps to subset of default applications to reload only some of them, empty list - to effectively disable code reloader, or include external applications from library dependencies."},{"ref":"Phoenix.Endpoint.Cowboy2Adapter.html","title":"Phoenix.Endpoint.Cowboy2Adapter","type":"module","doc":"The Cowboy2 adapter for Phoenix. It implements the required child_spec/3 function as well as WebSocket transport functionality. Custom dispatch options You can provide custom dispatch options in order to use Phoenix&#39;s builtin Cowboy server with custom handlers. For example, to handle raw WebSockets as shown in Cowboy&#39;s docs). The options are passed to both :http and :https keys in the endpoint configuration. However, once you pass your custom dispatch options, you will need to manually wire the Phoenix endpoint by adding the following rule: {:_, Phoenix.Endpoint.Cowboy2Handler, {MyAppWeb.Endpoint, []}} For example: config :myapp, MyAppWeb.Endpoint, http: [dispatch: [ {:_, [ {&quot;/foo&quot;, MyAppWeb.CustomHandler, []}, {:_, Phoenix.Endpoint.Cowboy2Handler, {MyAppWeb.Endpoint, []}} ]}]] It is also important to specify your handlers first, otherwise Phoenix will intercept the requests before they get to your handler."},{"ref":"Phoenix.Endpoint.CowboyAdapter.html","title":"Phoenix.Endpoint.CowboyAdapter","type":"module","doc":"The Cowboy adapter for Phoenix. It implements the required child_spec/3 function as well as the handler for the WebSocket transport. Custom dispatch options NOTE: This feature depends on the internals of Cowboy 1.0 API and how it integrates with Phoenix. Those may change at any time, without backwards compatibility. You can provide custom dispatch options in order to use Phoenix&#39;s builtin Cowboy server with custom handlers. For example, to handle raw WebSockets as shown in Cowboy&#39;s docs). The options are passed to both :http and :https keys in the endpoint configuration. However, once you pass your custom dispatch options, you will need to manually wire all Phoenix endpoints, including the socket transports. You will need the following rules: Per websocket transport: {&quot;/socket/websocket&quot;, Phoenix.Endpoint.CowboyWebSocket, {Phoenix.Transports.WebSocket, {MyAppWeb.Endpoint, MyAppWeb.UserSocket, websocket_config}}} Per longpoll transport: {&quot;/socket/long_poll&quot;, Plug.Adapters.Cowboy.Handler, {Phoenix.Transports.LongPoll, {MyAppWeb.Endpoint, MyAppWeb.UserSocket, longpoll_config}}} For the live-reload websocket: {&quot;/phoenix/live_reload/socket/websocket&quot;, Phoenix.Endpoint.CowboyWebSocket, {Phoenix.Transports.WebSocket, {MyAppWeb.Endpoint, Phoenix.LiveReloader.Socket, websocket_config}}} If you decide to include the live-reload websocket, you should disable it when building for production. For the endpoint: {:_, Plug.Adapters.Cowboy.Handler, {MyAppWeb.Endpoint, []}} For example: config :myapp, MyAppWeb.Endpoint, http: [dispatch: [ {:_, [ {&quot;/foo&quot;, MyAppWeb.CustomHandler, []}, {&quot;/bar&quot;, MyAppWeb.AnotherHandler, []}, {&quot;/phoenix/live_reload/socket/websocket&quot;, Phoenix.Endpoint.CowboyWebSocket, {Phoenix.Transports.WebSocket, {MyAppWeb.Endpoint, Phoenix.LiveReloader.Socket, websocket_config}}}, {:_, Plug.Adapters.Cowboy.Handler, {MyAppWeb.Endpoint, []}} ]}]] Note: if you reconfigure HTTP options in MyAppWeb.Endpoint.init/1, your dispatch options set in mix config will be overwritten. It is also important to specify your handlers first, otherwise Phoenix will intercept the requests before they get to your handler."},{"ref":"Phoenix.Socket.html","title":"Phoenix.Socket","type":"behaviour","doc":"A socket implementation that multiplexes messages over channels. Phoenix.Socket is used as a module for establishing and maintaining the socket state via the Phoenix.Socket struct. Once connected to a socket, incoming and outgoing events are routed to channels. The incoming client data is routed to channels via transports. It is the responsibility of the socket to tie transports and channels together. By default, Phoenix supports both websockets and longpoll when invoking Phoenix.Endpoint.socket/3 in your endpoint: socket &quot;/socket&quot;, MyApp.Socket, websocket: true, longpoll: false The command above means incoming socket connections can be made via a WebSocket connection. Events are routed by topic to channels: channel &quot;room:lobby&quot;, MyApp.LobbyChannel See Phoenix.Channel for more information on channels. Socket Behaviour Socket handlers are mounted in Endpoints and must define two callbacks: connect/3 - receives the socket params, connection info if any, and authenticates the connection. Must return a Phoenix.Socket struct, often with custom assigns id/1 - receives the socket returned by connect/3 and returns the id of this connection as a string. The id is used to identify socket connections, often to a particular user, allowing us to force disconnections. For sockets requiring no authentication, nil can be returned Examples defmodule MyApp.UserSocket do use Phoenix.Socket channel &quot;room:*&quot;, MyApp.RoomChannel def connect(params, socket, _connect_info) do {:ok, assign(socket, :user_id, params[&quot;user_id&quot;])} end def id(socket), do: &quot;users_socket:\#{socket.assigns.user_id}&quot; end # Disconnect all user&#39;s socket connections and their multiplexed channels MyApp.Endpoint.broadcast(&quot;users_socket:&quot; &lt;&gt; user.id, &quot;disconnect&quot;, %{}) Socket fields :id - The string id of the socket :assigns - The map of socket assigns, default: %{} :channel - The current channel module :channel_pid - The channel pid :endpoint - The endpoint module where this socket originated, for example: MyApp.Endpoint :handler - The socket module where this socket originated, for example: MyApp.UserSocket :joined - If the socket has effectively joined the channel :join_ref - The ref sent by the client when joining :ref - The latest ref sent by the client :pubsub_server - The registered name of the socket&#39;s pubsub server :topic - The string topic, for example &quot;room:123&quot; :transport - An identifier for the transport, used for logging :transport_pid - The pid of the socket&#39;s transport process :serializer - The serializer for socket messages Logging Logging for socket connections is set via the :log option, for example: use Phoenix.Socket, log: :debug Defaults to the :info log level. Pass false to disable logging. Garbage collection It&#39;s possible to force garbage collection in the transport process after processing large messages. For example, to trigger such from your channels, run: send(socket.transport_pid, :garbage_collect) Client-server communication The encoding of server data and the decoding of client data is done according to a serializer, defined in Phoenix.Socket.Serializer. By default, JSON encoding is used to broker messages to and from clients with Phoenix.Socket.V2.JSONSerializer. The serializer decode! function must return a Phoenix.Socket.Message which is forwarded to channels except: &quot;heartbeat&quot; events in the &quot;phoenix&quot; topic - should just emit an OK reply &quot;phx_join&quot; on any topic - should join the topic &quot;phx_leave&quot; on any topic - should leave the topic Each message also has a ref field which is used to track responses. The server may send messages or replies back. For messages, the ref uniquely identifies the message. For replies, the ref matches the original message. Both data-types also include a join_ref that uniquely identifies the currently joined channel. The Phoenix.Socket implementation may also send special messages and replies: &quot;phx_error&quot; - in case of errors, such as a channel process crashing, or when attempting to join an already joined channel &quot;phx_close&quot; - the channel was gracefully closed Phoenix ships with a JavaScript implementation of both websocket and long polling that interacts with Phoenix.Socket and can be used as reference for those interested in implementing custom clients. Custom sockets and transports See the Phoenix.Socket.Transport documentation for more information on writing your own socket that does not leverage channels or for writing your own transports that interacts with other sockets. Custom channels You can list any module as a channel as long as it implements a start_link/1 function that receives a tuple with three elements: {auth_payload, from, socket} A custom channel implementation MUST invoke GenServer.reply(from, {:ok | :error, reply_payload}) during its initialization with a custom reply_payload that will be sent as a reply to the client. Failing to do so will block the socket forever. A custom channel receives Phoenix.Socket.Message structs as regular messages from the transport. Replies to those messages and custom messages can be sent to the socket at any moment by building an appropriate Phoenix.Socket.Reply and Phoenix.Socket.Message structs, encoding them with the serializer and dispatching the serialized result to the transport. For example, to handle &quot;phx_leave&quot; messages, which is recommended to be handled by all channel implementations, one may do: def handle_info( %Message{topic: topic, event: &quot;phx_leave&quot;} = message, %{topic: topic, serializer: serializer, transport_pid: transport_pid} = socket ) do send transport_pid, serializer.encode!(build_leave_reply(message)) {:stop, {:shutdown, :left}, socket} end We also recommend all channels to monitor the transport_pid on init and exit if the transport exits. We also advise to rewrite :normal exit reasons (usually due to the socket being closed) to the {:shutdown, :closed} to guarantee links are broken on the channel exit (as a :normal exit does not break links): def handle_info({:DOWN, _, _, transport_pid, reason}, %{transport_pid: transport_pid} = socket) do reason = if reason == :normal, do: {:shutdown, :closed}, else: reason {:stop, reason, socket} end Any process exit is treated as an error by the socket layer unless a {:socket_close, pid, reason} message is sent to the socket before shutdown. Custom channel implementations cannot be tested with Phoenix.ChannelTest and are currently considered experimental. The underlying API may be changed at any moment. Note: in future Phoenix versions we will require custom channels to provide a custom child_spec/1 function instead of start_link/1. Since the default behaviour of child_spec/1 is to invoke start_link/1, this behaviour should be backwards compatible in almost all cases."},{"ref":"Phoenix.Socket.html#assign/2","title":"Phoenix.Socket.assign/2","type":"function","doc":""},{"ref":"Phoenix.Socket.html#assign/3","title":"Phoenix.Socket.assign/3","type":"function","doc":"Adds key value pairs to socket assigns. A single key value pair may be passed, a keyword list or map of assigns may be provided to be merged into existing socket assigns. Examples iex&gt; assign(socket, :name, &quot;Elixir&quot;) iex&gt; assign(socket, name: &quot;Elixir&quot;, logo: &quot;💧&quot;)"},{"ref":"Phoenix.Socket.html#channel/3","title":"Phoenix.Socket.channel/3","type":"macro","doc":"Defines a channel matching the given topic and transports. topic_pattern - The string pattern, for example &quot;room:*&quot;, &quot;users:*&quot;, or &quot;system&quot; module - The channel module handler, for example MyApp.RoomChannel opts - The optional list of options, see below Options :assigns - the map of socket assigns to merge into the socket on join Examples channel &quot;topic1:*&quot;, MyChannel Topic Patterns The channel macro accepts topic patterns in two flavors. A splat (the * character) argument can be provided as the last character to indicate a &quot;topic:subtopic&quot; match. If a plain string is provided, only that topic will match the channel handler. Most use-cases will use the &quot;topic:*&quot; pattern to allow more versatile topic scoping. See Phoenix.Channel for more information"},{"ref":"Phoenix.Socket.html#c:connect/2","title":"Phoenix.Socket.connect/2","type":"callback","doc":"Receives the socket params and authenticates the connection. Socket params and assigns Socket params are passed from the client and can be used to verify and authenticate a user. After verification, you can put default assigns into the socket that will be set for all channels, ie {:ok, assign(socket, :user_id, verified_user_id)} To deny connection, return :error. See Phoenix.Token documentation for examples in performing token verification on connect."},{"ref":"Phoenix.Socket.html#c:connect/3","title":"Phoenix.Socket.connect/3","type":"callback","doc":""},{"ref":"Phoenix.Socket.html#c:id/1","title":"Phoenix.Socket.id/1","type":"callback","doc":"Identifies the socket connection. Socket IDs are topics that allow you to identify all sockets for a given user: def id(socket), do: &quot;users_socket:\#{socket.assigns.user_id}&quot; Would allow you to broadcast a &quot;disconnect&quot; event and terminate all active sockets and channels for a given user: MyApp.Endpoint.broadcast(&quot;users_socket:&quot; &lt;&gt; user.id, &quot;disconnect&quot;, %{}) Returning nil makes this socket anonymous."},{"ref":"Phoenix.Socket.html#t:t/0","title":"Phoenix.Socket.t/0","type":"type","doc":""},{"ref":"Phoenix.Socket.Broadcast.html","title":"Phoenix.Socket.Broadcast","type":"module","doc":"Defines a message sent from pubsub to channels and vice-versa. The message format requires the following keys: :topic - The string topic or topic:subtopic pair namespace, for example &quot;messages&quot;, &quot;messages:123&quot; :event- The string event name, for example &quot;phx_join&quot; :payload - The message payload"},{"ref":"Phoenix.Socket.Broadcast.html#t:t/0","title":"Phoenix.Socket.Broadcast.t/0","type":"type","doc":""},{"ref":"Phoenix.Socket.Message.html","title":"Phoenix.Socket.Message","type":"module","doc":"Defines a message dispatched over transport to channels and vice-versa. The message format requires the following keys: :topic - The string topic or topic:subtopic pair namespace, for example &quot;messages&quot;, &quot;messages:123&quot; :event- The string event name, for example &quot;phx_join&quot; :payload - The message payload :ref - The unique string ref :join_ref - The unique string ref when joining"},{"ref":"Phoenix.Socket.Message.html#from_map!/1","title":"Phoenix.Socket.Message.from_map!/1","type":"function","doc":"Converts a map with string keys into a message struct. Raises Phoenix.Socket.InvalidMessageError if not valid."},{"ref":"Phoenix.Socket.Message.html#t:t/0","title":"Phoenix.Socket.Message.t/0","type":"type","doc":""},{"ref":"Phoenix.Socket.Reply.html","title":"Phoenix.Socket.Reply","type":"module","doc":"Defines a reply sent from channels to transports. The message format requires the following keys: :topic - The string topic or topic:subtopic pair namespace, for example &quot;messages&quot;, &quot;messages:123&quot; :status - The reply status as an atom :payload - The reply payload :ref - The unique string ref :join_ref - The unique string ref when joining"},{"ref":"Phoenix.Socket.Reply.html#t:t/0","title":"Phoenix.Socket.Reply.t/0","type":"type","doc":""},{"ref":"Phoenix.Socket.Serializer.html","title":"Phoenix.Socket.Serializer","type":"behaviour","doc":"A behaviour that serializes incoming and outgoing socket messages. By default Phoenix provides Phoenix.Socket.V2.JSONSerializer that encodes to JSON and decodes JSON messages. Custom serializers may be configured in the socket."},{"ref":"Phoenix.Socket.Serializer.html#c:decode!/2","title":"Phoenix.Socket.Serializer.decode!/2","type":"callback","doc":"Decodes iodata into Phoenix.Socket.Message struct."},{"ref":"Phoenix.Socket.Serializer.html#c:encode!/1","title":"Phoenix.Socket.Serializer.encode!/1","type":"callback","doc":"Encodes Phoenix.Socket.Message and Phoenix.Socket.Reply structs to push format."},{"ref":"Phoenix.Socket.Serializer.html#c:fastlane!/1","title":"Phoenix.Socket.Serializer.fastlane!/1","type":"callback","doc":"Encodes a Phoenix.Socket.Broadcast struct to fastlane format."},{"ref":"Phoenix.Socket.Transport.html","title":"Phoenix.Socket.Transport","type":"behaviour","doc":"Outlines the Socket &lt;-&gt; Transport communication. This module specifies a behaviour that all sockets must implement. Phoenix.Socket is just one possible implementation of a socket that multiplexes events over multiple channels. Developers can implement their own sockets as long as they implement the behaviour outlined here. Developers interested in implementing custom transports must invoke the socket API defined in this module. This module also provides many conveniences to make it easier to build custom transports. Workflow Whenever your endpoint starts, it will automatically invoke the child_spec/1 on each listed socket and start that specification under the endpoint supervisor. For this reason, custom transports that are manually started in the supervision tree must be listed after the endpoint. Whenever the transport receives a connection, it should invoke the connect/1 callback with a map of metadata. Different sockets may require different metadatas. If the connection is accepted, the transport can move the connection to another process, if so desires, or keep using the same process. The process responsible for managing the socket should then call init/1. For each message received from the client, the transport must call handle_in/2 on the socket. For each informational message the transport receives, it should call handle_info/2 on the socket. On termination, terminate/2 must be called. A special atom with reason :closed can be used to specify that the client terminated the connection. Example Here is a simple pong socket implementation: defmodule PingSocket do @behaviour Phoenix.Socket.Transport def child_spec(opts) do # We won&#39;t spawn any process, so let&#39;s return a dummy task %{id: Task, start: {Task, :start_link, [fn -&gt; :ok end]}, restart: :transient} end def connect(map) do # Callback to retrieve relevant data from the connection. # The map contains options, params, transport and endpoint keys. {:ok, state} end def init(state) do # Now we are effectively inside the process that maintains the socket. {:ok, state} end def handle_in({&quot;ping&quot;, _opts}, state) do {:reply, :ok, {:text, &quot;pong&quot;}, state} end def handle_info(_, state) do {:ok, state} end def terminate(_reason, _state) do :ok end end It can be mounted in your endpoint like any other socket: socket &quot;/socket&quot;, PingSocket, websocket: true, longpoll: true You can now interact with the socket under /socket/websocket and /socket/longpoll. Security This module also provides functions to enable a secure environment on transports that, at some point, have access to a Plug.Conn. The functionality provided by this module helps in performing &quot;origin&quot; header checks and ensuring only SSL connections are allowed."},{"ref":"Phoenix.Socket.Transport.html#check_origin/5","title":"Phoenix.Socket.Transport.check_origin/5","type":"function","doc":"Checks the origin request header against the list of allowed origins. Should be called by transports before connecting when appropriate. If the origin header matches the allowed origins, no origin header was sent or no origin was configured, it will return the given connection. Otherwise a 403 Forbidden response will be sent and the connection halted. It is a noop if the connection has been halted."},{"ref":"Phoenix.Socket.Transport.html#check_subprotocols/2","title":"Phoenix.Socket.Transport.check_subprotocols/2","type":"function","doc":"Checks the Websocket subprotocols request header against the allowed subprotocols. Should be called by transports before connecting when appropriate. If the sec-websocket-protocol header matches the allowed subprotocols, it will put sec-websocket-protocol response header and return the given connection. If no sec-websocket-protocol header was sent it will return the given connection. Otherwise a 403 Forbidden response will be sent and the connection halted. It is a noop if the connection has been halted."},{"ref":"Phoenix.Socket.Transport.html#c:child_spec/1","title":"Phoenix.Socket.Transport.child_spec/1","type":"callback","doc":"Returns a child specification for socket management. This is invoked only once per socket regardless of the number of transports and should be responsible for setting up any process structure used exclusively by the socket regardless of transports. Each socket connection is started by the transport and the process that controls the socket likely belongs to the transport. However, some sockets spawn new processes, such as Phoenix.Socket which spawns channels, and this gives the ability to start a supervision tree associated to the socket. It receives the socket options from the endpoint, for example: socket &quot;/my_app&quot;, MyApp.Socket, shutdown: 5000 means child_spec([shutdown: 5000]) will be invoked."},{"ref":"Phoenix.Socket.Transport.html#code_reload/3","title":"Phoenix.Socket.Transport.code_reload/3","type":"function","doc":"Runs the code reloader if enabled."},{"ref":"Phoenix.Socket.Transport.html#c:connect/1","title":"Phoenix.Socket.Transport.connect/1","type":"callback","doc":"Connects to the socket. The transport passes a map of metadata and the socket returns {:ok, state} or :error. The state must be stored by the transport and returned in all future operations. This function is used for authorization purposes and it may be invoked outside of the process that effectively runs the socket. In the default Phoenix.Socket implementation, the metadata expects the following keys: :endpoint - the application endpoint :transport - the transport name :params - the connection parameters :options - a keyword list of transport options, often given by developers when configuring the transport. It must include a :serializer field with the list of serializers and their requirements"},{"ref":"Phoenix.Socket.Transport.html#connect_info/3","title":"Phoenix.Socket.Transport.connect_info/3","type":"function","doc":"Extracts connection information from conn and returns a map. Keys are retrieved from the optional transport option :connect_info. This functionality is transport specific. Please refer to your transports&#39; documentation for more information. The supported keys are: :peer_data - the result of Plug.Conn.get_peer_data/1 :x_headers - a list of all request headers that have an &quot;x-&quot; prefix :uri - a %URI{} derived from the conn"},{"ref":"Phoenix.Socket.Transport.html#force_ssl/4","title":"Phoenix.Socket.Transport.force_ssl/4","type":"function","doc":"Forces SSL in the socket connection. Uses the endpoint configuration to decide so. It is a noop if the connection has been halted."},{"ref":"Phoenix.Socket.Transport.html#c:handle_in/2","title":"Phoenix.Socket.Transport.handle_in/2","type":"callback","doc":"Handles incoming socket messages. The message is represented as {payload, options}. It must return one of: {:ok, state} - continues the socket with no reply {:reply, status, reply, state} - continues the socket with reply {:stop, reason, state} - stops the socket The reply is a tuple contain an opcode atom and a message that can be any term. The built-in websocket transport supports both :text and :binary opcode and the message must be always iodata. Long polling only supports text opcode."},{"ref":"Phoenix.Socket.Transport.html#c:handle_info/2","title":"Phoenix.Socket.Transport.handle_info/2","type":"callback","doc":"Handles info messages. The message is a term. It must return one of: {:ok, state} - continues the socket with no reply {:push, reply, state} - continues the socket with reply {:stop, reason, state} - stops the socket The reply is a tuple contain an opcode atom and a message that can be any term. The built-in websocket transport supports both :text and :binary opcode and the message must be always iodata. Long polling only supports text opcode."},{"ref":"Phoenix.Socket.Transport.html#c:init/1","title":"Phoenix.Socket.Transport.init/1","type":"callback","doc":"Initializes the socket state. This must be executed from the process that will effectively operate the socket."},{"ref":"Phoenix.Socket.Transport.html#c:terminate/2","title":"Phoenix.Socket.Transport.terminate/2","type":"callback","doc":"Invoked on termination. If reason is :closed, it means the client closed the socket."},{"ref":"Phoenix.Socket.Transport.html#transport_log/2","title":"Phoenix.Socket.Transport.transport_log/2","type":"function","doc":"Logs the transport request. Available for transports that generate a connection."},{"ref":"Phoenix.Socket.Transport.html#t:state/0","title":"Phoenix.Socket.Transport.state/0","type":"type","doc":""},{"ref":"Phoenix.Template.html","title":"Phoenix.Template","type":"module","doc":"Templates are used by Phoenix when rendering responses. Since many views render significant content, for example a whole HTML file, it is common to put these files into a particular directory, typically &quot;APP_web/templates&quot;. This module provides conveniences for reading all files from a particular directory and embedding them into a single module. Imagine you have a directory with templates: # templates/foo.html.eex Hello &lt;%= @name %&gt; # templates.ex defmodule Templates do use Phoenix.Template, root: &quot;templates&quot; def render(template, assigns) do render_template(template, assigns) end end Phoenix.Template will define a private function named render_template/2 with one clause per file system template. We expose this private function via render/2, which can be invoked as: Templates.render(&quot;foo.html&quot;, %{name: &quot;John Doe&quot;}) In practice, developers rarely use Phoenix.Template directly. Instead they use Phoenix.View which wraps the template functionality and adds some extra conveniences. Options :root - the root template path to find templates :pattern - the wildcard pattern to apply to the root when finding templates. Default &quot;*&quot; :template_engines - a map of template engines extensions to template engine handlers Terminology Here is a quick introduction into Phoenix templates terms: template name - is the name of the template as given by the user, without the template engine extension, for example: &quot;users.html&quot; template path - is the complete path of the template in the filesystem, for example, &quot;path/to/users.html.eex&quot; template root - the directory where templates are defined template engine - a module that receives a template path and transforms its source code into Elixir quoted expressions Custom Template Engines Phoenix supports custom template engines. Engines tell Phoenix how to convert a template path into quoted expressions. See Phoenix.Template.Engine for more information on the API required to be implemented by custom engines. Once a template engine is defined, you can tell Phoenix about it via the template engines option: config :phoenix, :template_engines, eex: Phoenix.Template.EExEngine, exs: Phoenix.Template.ExsEngine If you want to support a given engine only on a certain template, you can pass it as an option on use Phoenix.Template: use Phoenix.Template, template_engines: %{ foo: Phoenix.Template.FooEngine } Format encoders Besides template engines, Phoenix has the concept of format encoders. Format encoders work per format and are responsible for encoding a given format to string once the view layer finishes processing. A format encoder must export a function called encode_to_iodata!/1 which receives the rendering artifact and returns iodata. New encoders can be added via the format encoder option: config :phoenix, :format_encoders, html: Phoenix.Template.HTML"},{"ref":"Phoenix.Template.html#engines/0","title":"Phoenix.Template.engines/0","type":"function","doc":"Returns a keyword list with all template engines extensions followed by their modules."},{"ref":"Phoenix.Template.html#find_all/2","title":"Phoenix.Template.find_all/2","type":"function","doc":"Returns all template paths in a given template root."},{"ref":"Phoenix.Template.html#format_encoder/1","title":"Phoenix.Template.format_encoder/1","type":"function","doc":"Returns the format encoder for the given template name."},{"ref":"Phoenix.Template.html#hash/2","title":"Phoenix.Template.hash/2","type":"function","doc":"Returns the hash of all template paths in the given root. Used by Phoenix to check if a given root path requires recompilation."},{"ref":"Phoenix.Template.html#module_to_template_root/3","title":"Phoenix.Template.module_to_template_root/3","type":"function","doc":"Converts a module, without the suffix, to a template root. Examples iex&gt; Phoenix.Template.module_to_template_root(MyApp.UserView, MyApp, &quot;View&quot;) &quot;user&quot; iex&gt; Phoenix.Template.module_to_template_root(MyApp.Admin.User, MyApp, &quot;View&quot;) &quot;admin/user&quot; iex&gt; Phoenix.Template.module_to_template_root(MyApp.Admin.User, MyApp.Admin, &quot;View&quot;) &quot;user&quot; iex&gt; Phoenix.Template.module_to_template_root(MyApp.View, MyApp, &quot;View&quot;) &quot;&quot; iex&gt; Phoenix.Template.module_to_template_root(MyApp.View, MyApp.View, &quot;View&quot;) &quot;&quot;"},{"ref":"Phoenix.Template.html#template_path_to_name/2","title":"Phoenix.Template.template_path_to_name/2","type":"function","doc":"Converts the template path into the template name. Examples iex&gt; Phoenix.Template.template_path_to_name( ...&gt; &quot;lib/templates/admin/users/show.html.eex&quot;, ...&gt; &quot;lib/templates&quot;) &quot;admin/users/show.html&quot;"},{"ref":"Phoenix.Template.html#t:name/0","title":"Phoenix.Template.name/0","type":"type","doc":""},{"ref":"Phoenix.Template.html#t:path/0","title":"Phoenix.Template.path/0","type":"type","doc":""},{"ref":"Phoenix.Template.html#t:root/0","title":"Phoenix.Template.root/0","type":"type","doc":""},{"ref":"Phoenix.Template.EExEngine.html","title":"Phoenix.Template.EExEngine","type":"module","doc":"The Phoenix engine that handles the .eex extension."},{"ref":"Phoenix.Template.EExEngine.html#compile/2","title":"Phoenix.Template.EExEngine.compile/2","type":"function","doc":"Callback implementation for Phoenix.Template.Engine.compile/2."},{"ref":"Phoenix.Template.Engine.html","title":"Phoenix.Template.Engine","type":"behaviour","doc":"Specifies the API for adding custom template engines into Phoenix. Engines must implement the compile/2 function, that receives the template file and the template name and outputs the template quoted expression: def compile(template_path, template_name) See Phoenix.Template.EExEngine for an example engine implementation."},{"ref":"Phoenix.Template.Engine.html#c:compile/2","title":"Phoenix.Template.Engine.compile/2","type":"callback","doc":""},{"ref":"Phoenix.Template.ExsEngine.html","title":"Phoenix.Template.ExsEngine","type":"module","doc":"The Phoenix engine that handles the .exs extension."},{"ref":"Phoenix.Template.ExsEngine.html#compile/2","title":"Phoenix.Template.ExsEngine.compile/2","type":"function","doc":"Callback implementation for Phoenix.Template.Engine.compile/2."},{"ref":"Phoenix.Template.HTML.html","title":"Phoenix.Template.HTML","type":"module","doc":"The default HTML encoder that ships with Phoenix. It expects {:safe, body} as a safe response or body as a string which will be HTML escaped."},{"ref":"Phoenix.Template.HTML.html#encode_to_iodata!/1","title":"Phoenix.Template.HTML.encode_to_iodata!/1","type":"function","doc":"Encodes the HTML templates to iodata."},{"ref":"overview.html","title":"Overview","type":"extras","doc":"Overview Phoenix is a web development framework written in Elixir which implements the server-side Model View Controller (MVC) pattern. Many of its components and concepts will seem familiar to those of us with experience in other web frameworks like Ruby on Rails or Python&#39;s Django. Phoenix provides the best of both worlds - high developer productivity and high application performance. It also has some interesting new twists like channels for implementing realtime features and pre-compiled templates for blazing speed. If you are already familiar with Elixir, great! If not, there are a number of places to learn. The Elixir guides and the Elixir learning resources page are two great places to start. We also have a list of helpful resources to learn more about Phoenix and some of the projects it depends on. The aim of this introductory guide is to present a brief, high-level overview of Phoenix, the parts that make it up, and the layers underneath that support it. If you would prefer to read these guides as an EPUB click here! Phoenix Phoenix is made up of a number of distinct parts, each with its own purpose and role to play in building a web application. We will cover them all in depth throughout these guides, but here&#39;s a quick breakdown. Endpoint the start and end of the request lifecycle handles all aspects of requests up until the point where the router takes over provides a core set of plugs to apply to all requests dispatches requests into a designated router Router parses incoming requests and dispatches them to the correct controller/action, passing parameters as needed provides helpers to generate route paths or urls to resources defines named pipelines through which we may pass our requests Pipelines - allow easy application of groups of plugs to a set of routes Controllers provide functions, called actions, to handle requests actions: prepare data and pass it into views invoke rendering via views perform redirects Views render templates act as a presentation layer define helper functions, available in templates, to decorate data for presentation Templates files containing the contents that will be served in a response provide the basic structure for a response, and allow dynamic data to be substituted in are precompiled and fast Channels manage sockets for easy realtime communication are analogous to controllers except that they allow bi-directional communication with persistent connections PubSub underlies the channel layer and allows clients to subscribe to topics abstracts the underlying pubsub adapter for third-party pubsub integration"},{"ref":"overview.html#phoenix-layers","title":"Overview - Phoenix Layers","type":"extras","doc":"We just covered the internal parts that make up Phoenix, but it&#39;s important to remember Phoenix itself is actually the top layer of a multi-layer system designed to be modular and flexible. The other layers include Cowboy, Plug, and Ecto. Cowboy By default, the web server used by Phoenix (and Plug) is Cowboy. It is uncommon to interface with Cowboy directly when using Phoenix. If you do require using Cowboy directly, please refer to the Cowboy documentation. Plug Plug is a specification for constructing composable modules to build web applications. Plugs are reusable modules or functions built to that specification. They provide discrete behaviors - like request header parsing or logging. Because the Plug API is small and consistent, plugs can be defined and executed in a set order, like a pipeline. They can also be re-used within a project or across projects. Plugs can be written to handle almost anything, from authentication to parameter pre-processing, and even rendering. Phoenix takes great advantage of Plug in general - the router and controllers especially so. One of the most important things about Plug is that it provides adapters to HTTP servers which will ultimately deliver application content to our users. Currently Plug only provides an adapter for Cowboy, a web server written in Erlang by Loïc Hoguin of 99s. Have a look at the Plug Guide for more details. Ecto Ecto is a language integrated query composition tool and database wrapper for Elixir. With Ecto, we can read and write to different databases, model our domain data, write complex queries in a type-safe way, protect against attack vectors - including SQL injection, and much more. Ecto is built around four main abstractions: Repo - A repository represents a connection to an individual database. Every database operation is done via the repository. Schema - Schemas are our data definitions. They define table names and fields as well as each field&#39;s type. Schemas also define associations - the relationships between our resources. Query - Queries tie both schemas and repositories together, allowing us to elegantly retrieve data from the repository and cast it into the schemas themselves. Changeset - Changesets declare transformations we need to perform on our data before our application can use it. These include type casting, validations, and more. A new Phoenix application will use Ecto with PostgreSQL storage by default."},{"ref":"overview.html#a-note-about-these-guides","title":"Overview - A Note about these guides","type":"extras","doc":"If you find an issue with the guides or would like to help improve these guides please checkout the Phoenix Guides on github. Issues and Pull Requests are happily accepted!"},{"ref":"installation.html","title":"Installation","type":"extras","doc":"Installation In the Overview Guide we got a look at the Phoenix ecosystem and how the pieces interrelate. Now it&#39;s time to install any software we might need before we jump into the Up and Running Guide. Please take a look at this list and make sure to install anything necessary for your system. Having dependencies installed in advance can prevent frustrating problems later on. Elixir 1.5 or later Phoenix is written in Elixir, and our application code will also be written in Elixir. We won&#39;t get far in a Phoenix app without it! The Elixir site maintains a great Installation Page to help. If we have just installed Elixir for the first time, we will need to install the Hex package manager as well. Hex is necessary to get a Phoenix app running (by installing dependencies) and to install any extra dependencies we might need along the way. Here&#39;s the command to install Hex (If you have Hex already installed, it will upgrade Hex to the latest version): $ mix local.hex Erlang 18 or later Elixir code compiles to Erlang byte code to run on the Erlang virtual machine. Without Erlang, Elixir code has no virtual machine to run on, so we need to install Erlang as well. When we install Elixir using instructions from the Elixir Installation Page, we will usually get Erlang too. If Erlang was not installed along with Elixir, please see the Erlang Instructions section of the Elixir Installation Page for instructions. People using Debian-based systems may need to explicitly install Erlang to get all the needed packages. $ wget https://packages.erlang-solutions.com/erlang-solutions_1.0_all.deb &amp;&amp; sudo dpkg -i erlang-solutions_1.0_all.deb $ sudo apt-get update $ sudo apt-get install esl-erlang Phoenix To check that we are on Elixir 1.5 and Erlang 18 or later, run: elixir -v Erlang/OTP 19 [erts-8.3] [source] [64-bit] [smp:8:8] [async-threads:10] [hipe] [kernel-poll:false] [dtrace] Elixir 1.5.3 Once we have Elixir and Erlang, we are ready to install the Phoenix Mix archive. A Mix archive is a Zip file which contains an application as well as its compiled BEAM files. It is tied to a specific version of the application. The archive is what we will use to generate a new, base Phoenix application which we can build from. Here&#39;s the command to install the Phoenix archive: $ mix archive.install hex phx_new 1.4.15 Plug, Cowboy, and Ecto These are either Elixir or Erlang projects which are part of Phoenix applications by default. We won&#39;t need to do anything special to install them. If we let Mix install our dependencies as we create our new application, these will be taken care of for us. If we don&#39;t, Phoenix will tell us how to do so after the app creation is done. node.js (&gt;= 5.0.0) Node is an optional dependency. Phoenix will use webpack to compile static assets (JavaScript, CSS, etc), by default. Webpack uses the node package manager (npm) to install its dependencies, and npm requires node.js. If we don&#39;t have any static assets, or we want to use another build tool, we can pass the --no-webpack flag when creating a new application and node won&#39;t be required at all. We can get node.js from the download page. When selecting a package to download, it&#39;s important to note that Phoenix requires version 5.0.0 or greater. Mac OS X users can also install node.js via homebrew. Note: io.js, which is an npm compatible platform originally based on Node.js, is not known to work with Phoenix. Debian/Ubuntu users might see an error that looks like this: sh: 1: node: not found npm WARN This failure might be due to the use of legacy binary &quot;node&quot; This is due to Debian having conflicting binaries for node: discussion on stackoverflow There are two options to fix this problem, either: install nodejs-legacy: $ apt-get install nodejs-legacy or create a symlink $ ln -s /usr/bin/nodejs /usr/bin/node PostgreSQL PostgreSQL is a relational database server. Phoenix configures applications to use it by default, but we can switch to MySQL by passing the --database mysql flag when creating a new application. When we work with Ecto schemas in these guides, we will use PostgreSQL and the Postgrex adapter for it. In order to follow along with the examples, we should install PostgreSQL and start the server. The PostgreSQL wiki has installation guides for a number of different systems. Postgrex is a direct Phoenix dependency, and it will be automatically installed along with the rest of our dependencies as we start building our app. inotify-tools (for linux users) This is a Linux-only filesystem watcher that Phoenix uses for live code reloading. (Mac OS X or Windows users can safely ignore it.) Linux users need to install this dependency. Please consult the inotify-tools wiki for distribution-specific installation instructions. Our First Phoenix Application Now that we have everything installed, let&#39;s create our first Phoenix application and get up and running."},{"ref":"learning.html","title":"Learning","type":"extras","doc":"Learning Here&#39;s a list of other resources for learning about Phoenix and some of the projects it depends on."},{"ref":"learning.html#phoenix","title":"Learning - Phoenix","type":"extras","doc":"Books Programming Phoenix (print and ebook) Online Resources The Phoenix Project Official Documentation (current stable release) Videos Phoenix author Chris McCord&#39;s videos covering the roadmap to Phoenix 1.0 and an overview of the current state of Phoenix. Phoenix Takes Flight, Chris McCord Phoenix - a framework for the modern web, Chris McCord Phoenix 1.3 - Lonestar ElixirConf 2017 Keynote, Chris McCord"},{"ref":"learning.html#plug","title":"Learning - Plug","type":"extras","doc":"The Elixir middleware layer that Phoenix makes extensive use of. Source Code and Readme Documentation"},{"ref":"learning.html#ecto","title":"Learning - Ecto","type":"extras","doc":"The default data layer for Phoenix. Source Code and Readme Documentation"},{"ref":"learning.html#phoenix-html","title":"Learning - Phoenix HTML","type":"extras","doc":"The project which contains many HTML helper functions used in Phoenix. Source Code and Readme Documentation"},{"ref":"learning.html#exunit","title":"Learning - ExUnit","type":"extras","doc":"Documentation"},{"ref":"learning.html#cowboy","title":"Learning - Cowboy","type":"extras","doc":"The webserver Phoenix is based on. Source Code and Readme User Guides Manual/Function Reference"},{"ref":"learning.html#eex","title":"Learning - EEx","type":"extras","doc":"The default templating system for Phoenix. Source Code and Readme Documentation"},{"ref":"community.html","title":"Community","type":"extras","doc":"Community The Elixir and Phoenix communities are friendly and welcoming. All questions and comments are valuable, so please come join the discussion! There are a number of places to connect with community members at all experience levels. We&#39;re on Freenode IRC in the #elixir-lang channel. Request an invitation and join the #phoenix channel on Slack. Read about bug reports or open an issue in the Phoenix issue tracker. Ask or answer questions about Phoenix on Elixir Forum or Stack Overflow. To discuss new features in the framework, email the phoenix-core mailing list. Follow the Phoenix Framework on Twitter. The source for these guides is on GitHub. To help improve the guides, please report an issue or open a pull request."},{"ref":"up_and_running.html","title":"Up and Running","type":"extras","doc":"Up and Running The aim of this first guide is to get a Phoenix application up and running as quickly as possible. Before we begin, please take a minute to read the Installation Guide. By installing any necessary dependencies beforehand, we&#39;ll be able to get our application up and running smoothly. At this point, we should have Elixir, Erlang, Hex, and the Phoenix archive installed. We should also have PostgreSQL and node.js installed to build a default application. Ok, we&#39;re ready to go! We can run mix phx.new from any directory in order to bootstrap our Phoenix application. Phoenix will accept either an absolute or relative path for the directory of our new project. Assuming that the name of our application is hello, let&#39;s run the following command: $ mix phx.new hello A note about webpack before we begin: Phoenix will use webpack for asset management by default. Webpack&#39;s dependencies are installed via the node package manager, not mix. Phoenix will prompt us to install them at the end of the mix phx.new task. If we say &quot;no&quot; at that point, and if we don&#39;t install those dependencies later with npm install, our application will raise errors when we try to start it, and our assets may not load properly. If we don&#39;t want to use webpack at all, we can simply pass --no-webpack to mix phx.new. A note about Ecto: Ecto allows our Phoenix application to communicate with a data store, such as PostgreSQL, MySQL, and others. If our application will not require this component we can skip this dependency by passing the --no-ecto flag to mix phx.new. This flag may also be combined with --no-webpack to create a skeleton application. To learn more about mix phx.new you can read the Mix Tasks Guide. mix phx.new hello * creating hello/config/config.exs * creating hello/config/dev.exs * creating hello/config/prod.exs ... * creating hello/assets/static/images/phoenix.png * creating hello/assets/static/favicon.ico Fetch and install dependencies? [Yn] Phoenix generates the directory structure and all the files we will need for our application. When it&#39;s done, it will ask us if we want it to install our dependencies for us. Let&#39;s say yes to that. Fetch and install dependencies? [Yn] Y * running mix deps.get * running mix deps.compile * running cd assets &amp;&amp; npm install &amp;&amp; node node_modules/webpack/bin/webpack.js --mode development We are almost there! The following steps are missing: $ cd hello Then configure your database in config/dev.exs and run: $ mix ecto.create Start your Phoenix app with: $ mix phx.server You can also run your app inside IEx (Interactive Elixir) as: $ iex -S mix phx.server Once our dependencies are installed, the task will prompt us to change into our project directory and start our application. Phoenix assumes that our PostgreSQL database will have a postgres user account with the correct permissions and a password of &quot;postgres&quot;. If that isn&#39;t the case, please see the Mix Tasks Guide to learn more about the mix ecto.create task. Ok, let&#39;s give it a try. First, we&#39;ll cd into the hello/ directory we&#39;ve just created: $ cd hello Now we&#39;ll create our database: $ mix ecto.create Compiling 13 files (.ex) Generated hello app The database for Hello.Repo has been created Note: if this is the first time you are running this command, Phoenix may also ask to install Rebar. Go ahead with the installation as Rebar is used to build Erlang packages. And finally, we&#39;ll start the Phoenix server: $ mix phx.server [info] Running HelloWeb.Endpoint with cowboy 2.5.0 at http://localhost:4000 Webpack is watching the files… ... If we choose not to have Phoenix install our dependencies when we generate a new application, the mix phx.new task will prompt us to take the necessary steps when we do want to install them. Fetch and install dependencies? [Yn] n We are almost there! The following steps are missing: $ cd hello $ mix deps.get $ cd assets &amp;&amp; npm install &amp;&amp; node node_modules/webpack/bin/webpack.js --mode development Then configure your database in config/dev.exs and run: $ mix ecto.create Start your Phoenix app with: $ mix phx.server You can also run your app inside IEx (Interactive Elixir) as: $ iex -S mix phx.server By default Phoenix accepts requests on port 4000. If we point our favorite web browser at http://localhost:4000, we should see the Phoenix Framework welcome page. If your screen looks like the image above, congratulations! You now have a working Phoenix application. In case you can&#39;t see the page above, try accessing it via http://127.0.0.1:4000 and later make sure your OS has defined &quot;localhost&quot; as &quot;127.0.0.1&quot;. Locally, our application is running in an iex session. To stop it, we hit ctrl-c twice, just as we would to stop iex normally. The next step is customizing our application just a bit to give us a sense of how a Phoenix app is put together."},{"ref":"adding_pages.html","title":"Adding Pages","type":"extras","doc":"Adding Pages Our task for this guide is to add two new pages to our Phoenix project. One will be a purely static page, and the other will take part of the path from the URL as input and pass it through to a template for display. Along the way, we will gain familiarity with the basic components of a Phoenix project: the router, controllers, views, and templates. When Phoenix generates a new application for us, it builds a top-level directory structure like this: ├── _build ├── assets ├── config ├── deps ├── lib │ └── hello │ └── hello_web │ └── hello.ex │ └── hello_web.ex ├── priv ├── test Most of our work in this guide will be in the lib/hello_web directory, which holds the web-related parts of our application. It looks like this when expanded: ├── channels │ └── user_socket.ex ├── controllers │ └── page_controller.ex ├── templates │ ├── layout │ │ └── app.html.eex │ └── page │ └── index.html.eex └── views │ ├── error_helpers.ex │ ├── error_view.ex │ ├── layout_view.ex │ └── page_view.ex ├── endpoint.ex ├── gettext.ex ├── router.ex All of the files which are currently in the controllers, templates, and views directories are there to create the &quot;Welcome to Phoenix!&quot; page we saw in the last guide. We will see how we can re-use some of that code shortly. When running in development, code changes will be automatically recompiled on new web requests. All of our application&#39;s static assets like js, css, and image files live in assets, which are built into priv/static by webpack or other front-end build tools. We won&#39;t be making any changes here for now, but it is good to know where to look for future reference. ├── assets │ ├── css │ │ └── app.css │ ├── js │ │ └── app.js │ └── static │ └── node_modules │ └── vendor There are also non web-related files we should know about. Our application file (which starts our Elixir application and its supervision tree) is at lib/hello/application.ex. We also have our Ecto Repo in lib/hello/repo.ex for interacting with the database. You can learn more in the guide for Ecto. lib ├── hello | ├── application.ex | └── repo.ex ├── hello_web | ├── channels | ├── controllers | ├── templates | ├── views | ├── endpoint.ex | ├── gettext.ex | └── router.ex Our lib/hello_web directory contains web-related files – routers, controllers, templates, channels, etc. The rest of our greater Elixir application lives inside lib/hello, and you structure code here like any other Elixir application. Enough prep, let&#39;s get on with our first new Phoenix page! A New Route Routes map unique HTTP verb/path pairs to controller/action pairs which will handle them. Phoenix generates a router file for us in new applications at lib/hello_web/router.ex. This is where we will be working for this section. The route for our &quot;Welcome to Phoenix!&quot; page from the previous Up And Running Guide looks like this. get &quot;/&quot;, PageController, :index Let&#39;s digest what this route is telling us. Visiting http://localhost:4000/ issues an HTTP GET request to the root path. All requests like this will be handled by the index function in the HelloWeb.PageController module defined in lib/hello_web/controllers/page_controller.ex. The page we are going to build will simply say &quot;Hello World, from Phoenix!&quot; when we point our browser to http://localhost:4000/hello. The first thing we need to do to create that page is define a route for it. Let&#39;s open up lib/hello_web/router.ex in a text editor. It should currently look like this: defmodule HelloWeb.Router do use HelloWeb, :router pipeline :browser do plug :accepts, [&quot;html&quot;] plug :fetch_session plug :fetch_flash plug :protect_from_forgery plug :put_secure_browser_headers end pipeline :api do plug :accepts, [&quot;json&quot;] end scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index end # Other scopes may use custom stacks. # scope &quot;/api&quot;, HelloWeb do # pipe_through :api # end end For now, we&#39;ll ignore the pipelines and the use of scope here and just focus on adding a route. (We cover these topics in the Routing Guide, if you&#39;re curious.) Let&#39;s add a new route to the router that maps a GET request for /hello to the index action of a soon-to-be-created HelloWeb.HelloController: get &quot;/hello&quot;, HelloController, :index The scope &quot;/&quot; block of our router.ex file should now look like this: scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index get &quot;/hello&quot;, HelloController, :index end A New Controller Controllers are Elixir modules, and actions are Elixir functions defined in them. The purpose of actions is to gather any data and perform any tasks needed for rendering. Our route specifies that we need a HelloWeb.HelloController module with an index/2 action. To make that happen, let&#39;s create a new lib/hello_web/controllers/hello_controller.ex file, and make it look like the following: defmodule HelloWeb.HelloController do use HelloWeb, :controller def index(conn, _params) do render(conn, &quot;index.html&quot;) end end We&#39;ll save a discussion of use HelloWeb, :controller for the Controllers Guide. For now, let&#39;s focus on the index/2 action. All controller actions take two arguments. The first is conn, a struct which holds a ton of data about the request. The second is params, which are the request parameters. Here, we are not using params, and we avoid compiler warnings by adding the leading _. The core of this action is render(conn, &quot;index.html&quot;). This tells Phoenix to find a template called index.html.eex and render it. Phoenix will look for the template in a directory named after our controller, so lib/hello_web/templates/hello. Note: Using an atom as the template name will also work here, render(conn, :index), but the template will be chosen based off the Accept headers, e.g. &quot;index.html&quot; or &quot;index.json&quot;. The modules responsible for rendering are views, and we&#39;ll make a new one of those next. A New View Phoenix views have several important jobs. They render templates. They also act as a presentation layer for raw data from the controller, preparing it for use in a template. Functions which perform this transformation should go in a view. As an example, say we have a data structure which represents a user with a first_name field and a last_name field, and in a template, we want to show the user&#39;s full name. We could write code in the template to merge those fields into a full name, but the better approach is to write a function in the view to do it for us, then call that function in the template. The result is a cleaner and more legible template. In order to render any templates for our HelloController, we need a HelloView. The names are significant here - the first part of the names of the view and controller must match. Let&#39;s create an empty one for now, and leave a more detailed description of views for later. Create lib/hello_web/views/hello_view.ex and make it look like this: defmodule HelloWeb.HelloView do use HelloWeb, :view end A New Template Phoenix templates are just that, templates into which data can be rendered. The standard templating engine Phoenix uses is EEx, which stands for Embedded Elixir. Phoenix enhances EEx to include automatic escaping of values. This protects you from security vulnerabilities like Cross-Site-Scripting with no extra work on your part. All of our template files will have the .eex file extension. Templates are scoped to a view, which are scoped to a controller. Phoenix creates a lib/hello_web/templates directory where we can put all these. It is best to namespace these for organization, so for our hello page, that means we need to create a hello directory under lib/hello_web/templates and then create an index.html.eex file within it. Let&#39;s do that now. Create lib/hello_web/templates/hello/index.html.eex and make it look like this: &lt;div class=&quot;phx-hero&quot;&gt; &lt;h2&gt;Hello World, from Phoenix!&lt;/h2&gt; &lt;/div&gt; Now that we&#39;ve got the route, controller, view, and template, we should be able to point our browsers at http://localhost:4000/hello and see our greeting from Phoenix! (In case you stopped the server along the way, the task to restart it is mix phx.server.) There are a couple of interesting things to notice about what we just did. We didn&#39;t need to stop and re-start the server while we made these changes. Yes, Phoenix has hot code reloading! Also, even though our index.html.eex file consisted of only a single div tag, the page we get is a full HTML document. Our index template is rendered into the application layout - lib/hello_web/templates/layout/app.html.eex. If you open it, you&#39;ll see a line that looks like this: &lt;%= render @view_module, @view_template, assigns %&gt; which is what renders our template into the layout before the HTML is sent off to the browser. A note on hot code reloading, some editors with their automatic linters may prevent hot code reloading from working. If it&#39;s not working for you, please see the dicussion in this issue."},{"ref":"adding_pages.html#another-new-page","title":"Adding Pages - Another New Page","type":"extras","doc":"Let&#39;s add just a little complexity to our application. We&#39;re going to add a new page that will recognize a piece of the URL, label it as a &quot;messenger&quot; and pass it through the controller into the template so our messenger can say hello. As we did last time, the first thing we&#39;ll do is create a new route. A New Route For this exercise, we&#39;re going to re-use the HelloController we just created and just add a new show action. We&#39;ll add a line just below our last route, like this: scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index get &quot;/hello&quot;, HelloController, :index get &quot;/hello/:messenger&quot;, HelloController, :show end Notice that we put the atom :messenger in the path. Phoenix will take whatever value that appears in that position in the URL and pass a Map with the key messenger pointing to that value to the controller. For example, if we point the browser at: http://localhost:4000/hello/Frank, the value of &quot;:messenger&quot; will be &quot;Frank&quot;. A New Action Requests to our new route will be handled by the HelloWeb.HelloController show action. We already have the controller at lib/hello_web/controllers/hello_controller.ex, so all we need to do is edit that file and add a show action to it. This time, we&#39;ll need to keep one of the items in the map of params that gets passed into the action, so that we can pass it (the messenger) to the template. To do that, we add this show function to the controller: def show(conn, %{&quot;messenger&quot; =&gt; messenger}) do render(conn, &quot;show.html&quot;, messenger: messenger) end There are a couple of things to notice here. We pattern match against the params passed into the show function so that the messenger variable will be bound to the value we put in the :messenger position in the URL. For example, if our URL is http://localhost:4000/hello/Frank, the messenger variable would be bound to Frank. Within the body of the show action, we also pass a third argument into the render function, a key/value pair where :messenger is the key, and the messenger variable is passed as the value. Note: If the body of the action needs access to the full map of parameters bound to the params variable in addition to the bound messenger variable, we could define show/2 like this: def show(conn, %{&quot;messenger&quot; =&gt; messenger} = params) do ... end It&#39;s good to remember that the keys to the params map will always be strings, and that the equals sign does not represent assignment, but is instead a pattern match assertion. A New Template For the last piece of this puzzle, we&#39;ll need a new template. Since it is for the show action of the HelloController, it will go into the lib/hello_web/templates/hello directory and be called show.html.eex. It will look surprisingly like our index.html.eex template, except that we will need to display the name of our messenger. To do that, we&#39;ll use the special EEx tags for executing Elixir expressions - &lt;%= %&gt;. Notice that the initial tag has an equals sign like this: &lt;%= . That means that any Elixir code that goes between those tags will be executed, and the resulting value will replace the tag. If the equals sign were missing, the code would still be executed, but the value would not appear on the page. And this is what the template should look like: &lt;div class=&quot;phx-hero&quot;&gt; &lt;h2&gt;Hello World, from &lt;%= @messenger %&gt;!&lt;/h2&gt; &lt;/div&gt; Our messenger appears as @messenger. In this case, this is not a module attribute. It is a special bit of metaprogrammed syntax which stands in for assigns.messenger. The result is much nicer on the eyes and much easier to work with in a template. We&#39;re done. If you point your browser here: http://localhost:4000/hello/Frank, you should see a page that looks like this: Play around a bit. Whatever you put after /hello/ will appear on the page as your messenger."},{"ref":"routing.html","title":"Routing","type":"extras","doc":"Routing Routers are the main hubs of Phoenix applications. They match HTTP requests to controller actions, wire up real-time channel handlers, and define a series of pipeline transformations for scoping middleware to sets of routes. The router file that Phoenix generates, lib/hello_web/router.ex, will look something like this one: defmodule HelloWeb.Router do use HelloWeb, :router pipeline :browser do plug :accepts, [&quot;html&quot;] plug :fetch_session plug :fetch_flash plug :protect_from_forgery plug :put_secure_browser_headers end pipeline :api do plug :accepts, [&quot;json&quot;] end scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index end # Other scopes may use custom stacks. # scope &quot;/api&quot;, HelloWeb do # pipe_through :api # end end Both the router and controller module names will be prefixed with the name you gave your application instead of HelloWeb. The first line of this module, use HelloWeb, :router, simply makes Phoenix router functions available in our particular router. Scopes have their own section in this guide, so we won&#39;t spend time on the scope &quot;/&quot;, HelloWeb do block here. The pipe_through :browser line will get a full treatment in the Pipeline section of this guide. For now, you only need to know that pipelines allow a set of middleware transformations to be applied to different sets of routes. Inside the scope block, however, we have our first actual route: get &quot;/&quot;, PageController, :index get is a Phoenix macro which expands out to define one clause of the match/5 function. It corresponds to the HTTP verb GET. Similar macros exist for other HTTP verbs including POST, PUT, PATCH, DELETE, OPTIONS, CONNECT, TRACE and HEAD. The first argument to these macros is the path. Here, it is the root of the application, /. The next two arguments are the controller and action we want to have handle this request. These macros may also take other options, which we will see throughout the rest of this guide. If this were the only route in our router module, the clause of the match/5 function would look like this after the macro is expanded: def match(:get, &quot;/&quot;, PageController, :index, []) The body of the match/5 function sets up the connection and invokes the matched controller action. As we add more routes, more clauses of the match function will be added to our router module. These will behave like any other multi-clause function in Elixir. They will be tried in order from the top, and the first clause to match the parameters given (verb and path) will be executed. After a match is found, the search will stop and no other clauses will be tried. This means that it is possible to create a route which will never match, based on the HTTP verb and the path, regardless of the controller and action. If we do create an ambiguous route, the router will still compile, but we will get a warning. Let&#39;s see this in action. Define this route at the bottom of the scope &quot;/&quot;, HelloWeb do block in the router. get &quot;/&quot;, RootController, :index Then run mix compile at the root of your project."},{"ref":"routing.html#examining-routes","title":"Routing - Examining Routes","type":"extras","doc":"Phoenix provides a great tool for investigating routes in an application, the mix task phx.routes. Let&#39;s see how this works. Go to the root of a newly-generated Phoenix application and run mix phx.routes. (If you haven&#39;t already done so, you&#39;ll need to run mix do deps.get, compile before running the routes task.) You should see something like the following, generated from the only route we currently have: $ mix phx.routes page_path GET / HelloWeb.PageController :index The output tells us that any HTTP GET request for the root of the application will be handled by the index action of the HelloWeb.PageController. page_path is an example of what Phoenix calls a path helper, and we&#39;ll talk about those very soon."},{"ref":"routing.html#resources","title":"Routing - Resources","type":"extras","doc":"The router supports other macros besides those for HTTP verbs like get, post, and put. The most important among them is resources, which expands out to eight clauses of the match/5 function. Let&#39;s add a resource to our lib/hello_web/router.ex file like this: scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index resources &quot;/users&quot;, UserController end For this purpose, it doesn&#39;t matter that we don&#39;t actually have a HelloWeb.UserController. Then go to the root of your project, and run mix phx.routes You should see something like the following: user_path GET /users HelloWeb.UserController :index user_path GET /users/:id/edit HelloWeb.UserController :edit user_path GET /users/new HelloWeb.UserController :new user_path GET /users/:id HelloWeb.UserController :show user_path POST /users HelloWeb.UserController :create user_path PATCH /users/:id HelloWeb.UserController :update PUT /users/:id HelloWeb.UserController :update user_path DELETE /users/:id HelloWeb.UserController :delete Of course, the name of your project will replace HelloWeb. This is the standard matrix of HTTP verbs, paths, and controller actions. Let&#39;s look at them individually, in a slightly different order. A GET request to /users will invoke the index action to show all the users. A GET request to /users/:id will invoke the show action with an id to show an individual user identified by that ID. A GET request to /users/new will invoke the new action to present a form for creating a new user. A POST request to /users will invoke the create action to save a new user to the data store. A GET request to /users/:id/edit will invoke the edit action with an ID to retrieve an individual user from the data store and present the information in a form for editing. A PATCH request to /users/:id will invoke the update action with an ID to save the updated user to the data store. A PUT request to /users/:id will also invoke the update action with an ID to save the updated user to the data store. A DELETE request to /users/:id will invoke the delete action with an ID to remove the individual user from the data store. If we don&#39;t feel that we need all of these routes, we can be selective using the :only and :except options. Let&#39;s say we have a read-only posts resource. We could define it like this: resources &quot;/posts&quot;, PostController, only: [:index, :show] Running mix phx.routes shows that we now only have the routes to the index and show actions defined. post_path GET /posts HelloWeb.PostController :index post_path GET /posts/:id HelloWeb.PostController :show Similarly, if we have a comments resource, and we don&#39;t want to provide a route to delete one, we could define a route like this. resources &quot;/comments&quot;, CommentController, except: [:delete] Running mix phx.routes now shows that we have all the routes except the DELETE request to the delete action. comment_path GET /comments HelloWeb.CommentController :index comment_path GET /comments/:id/edit HelloWeb.CommentController :edit comment_path GET /comments/new HelloWeb.CommentController :new comment_path GET /comments/:id HelloWeb.CommentController :show comment_path POST /comments HelloWeb.CommentController :create comment_path PATCH /comments/:id HelloWeb.CommentController :update PUT /comments/:id HelloWeb.CommentController :update The Phoenix.Router.resources/4 macro describes additional options for customizing resource routes."},{"ref":"routing.html#forward","title":"Routing - Forward","type":"extras","doc":"The Phoenix.Router.forward/4 macro can be used to send all requests that start with a particular path to a particular plug. Let&#39;s say we have a part of our system that is responsible (it could even be a separate application or library) for running jobs in the background, it could have its own web interface for checking the status of the jobs. We can forward to this admin interface using: defmodule HelloWeb.Router do use HelloWeb, :router ... scope &quot;/&quot;, HelloWeb do ... end forward &quot;/jobs&quot;, BackgroundJob.Plug end This means that all routes starting with /jobs will be sent to the HelloWeb.BackgroundJob.Plug module. We can even use the forward/4 macro in a pipeline. If we wanted to ensure that the user was authenticated and an administrator in order to see the jobs page, we could use the following in our router. defmodule HelloWeb.Router do use HelloWeb, :router ... scope &quot;/&quot; do pipe_through [:authenticate_user, :ensure_admin] forward &quot;/jobs&quot;, BackgroundJob.Plug end end This means that the plugs in the authenticate_user and ensure_admin pipelines will be called before the BackgroundJob.Plug allowing them to send an appropriate response and call halt() . The opts that are passed to the init/1 callback of a Plug can be passed as a 3rd argument. For example, maybe the background job page lets you set the name of your application to be displayed on the page. This could be passed with: forward &quot;/jobs&quot;, BackgroundJob.Plug, name: &quot;Hello Phoenix&quot; There is a fourth router_opts argument that can be passed. These options are outlined in the Phoenix.Router.scope/2 documentation. Although it is possible to forward to any module plug, it is not advised to forward to another endpoint. This is because plugs defined by your app and the forwarded endpoint would be invoked twice, which may lead to errors. Writing an actual background job worker is beyond the scope of this guide. However for convenience and to allow you to test the code above, here is the implementation of BackgroundJob.Plug that you can copy into your application inside lib/plugs/background_job_plug.ex: defmodule HelloWeb.BackgroundJob.Plug do def init(opts), do: opts def call(conn, opts) do conn |&gt; Plug.Conn.assign(:name, Keyword.get(opts, :name, &quot;Background Job&quot;)) |&gt; HelloWeb.BackgroundJob.Router.call(opts) end end defmodule HelloWeb.BackgroundJob.Router do use Plug.Router plug :match plug :dispatch get &quot;/&quot;, do: send_resp(conn, 200, &quot;Welcome to \#{conn.assigns.name}&quot;) get &quot;/active&quot;, do: send_resp(conn, 200, &quot;5 Active Jobs&quot;) get &quot;/pending&quot;, do: send_resp(conn, 200, &quot;3 Pending Jobs&quot;) match _, do: send_resp(conn, 404, &quot;Not found&quot;) end"},{"ref":"routing.html#path-helpers","title":"Routing - Path Helpers","type":"extras","doc":"Path helpers are functions which are dynamically defined on the Router.Helpers module for an individual application. For us, that is HelloWeb.Router.Helpers. Their names are derived from the name of the controller used in the route definition. Our controller is HelloWeb.PageController, and page_path is the function which will return the path to the root of our application. That&#39;s a mouthful. Let&#39;s see it in action. Run iex -S mix at the root of the project. When we call the page_path function on our router helpers with the Endpoint or connection and action as arguments, it returns the path to us. iex&gt; HelloWeb.Router.Helpers.page_path(HelloWeb.Endpoint, :index) &quot;/&quot; This is significant because we can use the page_path function in a template to link to the root of our application. We can then use this helper in our templates: &lt;a href=&quot;&lt;%= Routes.page_path(@conn, :index) %&gt;&quot;&gt;To the Welcome Page!&lt;/a&gt; The reason we can use Routes.page_path instead of the full HelloWeb.Router.Helpers.page_path name is because HelloWeb.Router.Helpers is aliased as Routes by default in the view/0 definition (lib/hello_web.ex) and made available to our templates through use HelloWeb, :view. We can, of course, use HelloWeb.Router.Helpers.page_path(@conn, :index) instead, but the convention is to use the aliased version for conciseness (note that the alias is only set automatically for use in views, controllers and templates - outside these you need either the full name, or to alias it yourself inside the module definition: alias HelloWeb.Router.Helpers, as: Routes). Please see the View Guide for more information. This pays off tremendously if we should ever have to change the path of our route in the router. Since the path helpers are built dynamically from the routes, any calls to page_path in our templates will still work. More on Path Helpers When we ran the phx.routes task for our user resource, it listed the user_path as the path helper function for each line of output. Here is what that translates to for each action: iex&gt; alias HelloWeb.Router.Helpers, as: Routes iex&gt; alias HelloWeb.Endpoint iex&gt; Routes.user_path(Endpoint, :index) &quot;/users&quot; iex&gt; Routes.user_path(Endpoint, :show, 17) &quot;/users/17&quot; iex&gt; Routes.user_path(Endpoint, :new) &quot;/users/new&quot; iex&gt; Routes.user_path(Endpoint, :create) &quot;/users&quot; iex&gt; Routes.user_path(Endpoint, :edit, 37) &quot;/users/37/edit&quot; iex&gt; Routes.user_path(Endpoint, :update, 37) &quot;/users/37&quot; iex&gt; Routes.user_path(Endpoint, :delete, 17) &quot;/users/17&quot; What about paths with query strings? By adding an optional fourth argument of key value pairs, the path helpers will return those pairs in the query string. iex&gt; Routes.user_path(Endpoint, :show, 17, admin: true, active: false) &quot;/users/17?admin=true&amp;active=false&quot; What if we need a full url instead of a path? Just replace _path with _url: iex(3)&gt; Routes.user_url(Endpoint, :index) &quot;http://localhost:4000/users&quot; The _url functions will get the host, port, proxy port, and SSL information needed to construct the full URL from the configuration parameters set for each environment. We&#39;ll talk about configuration in more detail in its own guide. For now, you can take a look at config/dev.exs file in your own project to see those values. Whenever possible prefer to pass a conn in place of an Endpoint."},{"ref":"routing.html#nested-resources","title":"Routing - Nested Resources","type":"extras","doc":"It is also possible to nest resources in a Phoenix router. Let&#39;s say we also have a posts resource which has a many-to-one relationship with users. That is to say, a user can create many posts, and an individual post belongs to only one user. We can represent that by adding a nested route in lib/hello_web/router.ex like this: resources &quot;/users&quot;, UserController do resources &quot;/posts&quot;, PostController end When we run mix phx.routes now, in addition to the routes we saw for users above, we get the following set of routes: ... user_post_path GET /users/:user_id/posts HelloWeb.PostController :index user_post_path GET /users/:user_id/posts/:id/edit HelloWeb.PostController :edit user_post_path GET /users/:user_id/posts/new HelloWeb.PostController :new user_post_path GET /users/:user_id/posts/:id HelloWeb.PostController :show user_post_path POST /users/:user_id/posts HelloWeb.PostController :create user_post_path PATCH /users/:user_id/posts/:id HelloWeb.PostController :update PUT /users/:user_id/posts/:id HelloWeb.PostController :update user_post_path DELETE /users/:user_id/posts/:id HelloWeb.PostController :delete We see that each of these routes scopes the posts to a user ID. For the first one, we will invoke the PostController index action, but we will pass in a user_id. This implies that we would display all the posts for that individual user only. The same scoping applies for all these routes. When calling path helper functions for nested routes, we will need to pass the IDs in the order they came in the route definition. For the following show route, 42 is the user_id, and 17 is the post_id. Let&#39;s remember to alias our HelloWeb.Endpoint before we begin. iex&gt; alias HelloWeb.Endpoint iex&gt; HelloWeb.Router.Helpers.user_post_path(Endpoint, :show, 42, 17) &quot;/users/42/posts/17&quot; Again, if we add a key/value pair to the end of the function call, it is added to the query string. iex&gt; HelloWeb.Router.Helpers.user_post_path(Endpoint, :index, 42, active: true) &quot;/users/42/posts?active=true&quot; If we had aliased the Helpers module as before (it is only automatically aliased for views, templates and controllers, in this case, since we&#39;re inside iex we need to do it ourselves), we could instead do: iex&gt; alias HelloWeb.Router.Helpers, as: Routes iex&gt; alias HelloWeb.Endpoint iex&gt; Routes.user_post_path(Endpoint, :index, 42, active: true) &quot;/users/42/posts?active=true&quot;"},{"ref":"routing.html#scoped-routes","title":"Routing - Scoped Routes","type":"extras","doc":"Scopes are a way to group routes under a common path prefix and scoped set of plug middleware. We might want to do this for admin functionality, APIs, and especially for versioned APIs. Let&#39;s say we have user generated reviews on a site, and that those reviews first need to be approved by an admin. The semantics of these resources are quite different, and they might not share the same controller. Scopes enable us to segregate these routes. The paths to the user facing reviews would look like a standard resource. /reviews /reviews/1234 /reviews/1234/edit ... The admin review paths could be prefixed with /admin. /admin/reviews /admin/reviews/1234 /admin/reviews/1234/edit ... We accomplish this with a scoped route that sets a path option to /admin like this one. For now, let&#39;s not nest this scope inside of any other scopes (like the scope &quot;/&quot;, HelloWeb do one provided for us in a new app). scope &quot;/admin&quot; do pipe_through :browser resources &quot;/reviews&quot;, HelloWeb.Admin.ReviewController end Note also, that the way this scope is currently defined, we need to fully qualify our controller name, HelloWeb.Admin.ReviewController. We&#39;ll fix that in a minute. Running mix phx.routes again, in addition to the previous set of routes we get the following: ... review_path GET /admin/reviews HelloWeb.Admin.ReviewController :index review_path GET /admin/reviews/:id/edit HelloWeb.Admin.ReviewController :edit review_path GET /admin/reviews/new HelloWeb.Admin.ReviewController :new review_path GET /admin/reviews/:id HelloWeb.Admin.ReviewController :show review_path POST /admin/reviews HelloWeb.Admin.ReviewController :create review_path PATCH /admin/reviews/:id HelloWeb.Admin.ReviewController :update PUT /admin/reviews/:id HelloWeb.Admin.ReviewController :update review_path DELETE /admin/reviews/:id HelloWeb.Admin.ReviewController :delete This looks good, but there is a problem here. Remember that we wanted both user facing reviews routes /reviews as well as the admin ones /admin/reviews. If we now include the user facing reviews in our router like this: scope &quot;/&quot;, HelloWeb do pipe_through :browser ... resources &quot;/reviews&quot;, ReviewController ... end scope &quot;/admin&quot; do resources &quot;/reviews&quot;, HelloWeb.Admin.ReviewController end and we run mix phx.routes, we get this output: ... review_path GET /reviews HelloWeb.ReviewController :index review_path GET /reviews/:id/edit HelloWeb.ReviewController :edit review_path GET /reviews/new HelloWeb.ReviewController :new review_path GET /reviews/:id HelloWeb.ReviewController :show review_path POST /reviews HelloWeb.ReviewController :create review_path PATCH /reviews/:id HelloWeb.ReviewController :update PUT /reviews/:id HelloWeb.ReviewController :update review_path DELETE /reviews/:id HelloWeb.ReviewController :delete ... review_path GET /admin/reviews HelloWeb.Admin.ReviewController :index review_path GET /admin/reviews/:id/edit HelloWeb.Admin.ReviewController :edit review_path GET /admin/reviews/new HelloWeb.Admin.ReviewController :new review_path GET /admin/reviews/:id HelloWeb.Admin.ReviewController :show review_path POST /admin/reviews HelloWeb.Admin.ReviewController :create review_path PATCH /admin/reviews/:id HelloWeb.Admin.ReviewController :update PUT /admin/reviews/:id HelloWeb.Admin.ReviewController :update review_path DELETE /admin/reviews/:id HelloWeb.Admin.ReviewController :delete The actual routes we get all look right, except for the path helper review_path at the beginning of each line. We are getting the same helper for both the user facing review routes and the admin ones, which is not correct. We can fix this problem by adding an as: :admin option to our admin scope. scope &quot;/&quot;, HelloWeb do pipe_through :browser ... resources &quot;/reviews&quot;, ReviewController ... end scope &quot;/admin&quot;, as: :admin do resources &quot;/reviews&quot;, HelloWeb.Admin.ReviewController end mix phx.routes now shows us we have what we are looking for. ... review_path GET /reviews HelloWeb.ReviewController :index review_path GET /reviews/:id/edit HelloWeb.ReviewController :edit review_path GET /reviews/new HelloWeb.ReviewController :new review_path GET /reviews/:id HelloWeb.ReviewController :show review_path POST /reviews HelloWeb.ReviewController :create review_path PATCH /reviews/:id HelloWeb.ReviewController :update PUT /reviews/:id HelloWeb.ReviewController :update review_path DELETE /reviews/:id HelloWeb.ReviewController :delete ... admin_review_path GET /admin/reviews HelloWeb.Admin.ReviewController :index admin_review_path GET /admin/reviews/:id/edit HelloWeb.Admin.ReviewController :edit admin_review_path GET /admin/reviews/new HelloWeb.Admin.ReviewController :new admin_review_path GET /admin/reviews/:id HelloWeb.Admin.ReviewController :show admin_review_path POST /admin/reviews HelloWeb.Admin.ReviewController :create admin_review_path PATCH /admin/reviews/:id HelloWeb.Admin.ReviewController :update PUT /admin/reviews/:id HelloWeb.Admin.ReviewController :update admin_review_path DELETE /admin/reviews/:id HelloWeb.Admin.ReviewController :delete The path helpers now return what we want them to as well. Run iex -S mix and give it a try yourself. iex(1)&gt; HelloWeb.Router.Helpers.review_path(HelloWeb.Endpoint, :index) &quot;/reviews&quot; iex(2)&gt; HelloWeb.Router.Helpers.admin_review_path(HelloWeb.Endpoint, :show, 1234) &quot;/admin/reviews/1234&quot; What if we had a number of resources that were all handled by admins? We could put all of them inside the same scope like this: scope &quot;/admin&quot;, as: :admin do pipe_through :browser resources &quot;/images&quot;, HelloWeb.Admin.ImageController resources &quot;/reviews&quot;, HelloWeb.Admin.ReviewController resources &quot;/users&quot;, HelloWeb.Admin.UserController end Here&#39;s what mix phx.routes tells us: ... admin_image_path GET /admin/images HelloWeb.Admin.ImageController :index admin_image_path GET /admin/images/:id/edit HelloWeb.Admin.ImageController :edit admin_image_path GET /admin/images/new HelloWeb.Admin.ImageController :new admin_image_path GET /admin/images/:id HelloWeb.Admin.ImageController :show admin_image_path POST /admin/images HelloWeb.Admin.ImageController :create admin_image_path PATCH /admin/images/:id HelloWeb.Admin.ImageController :update PUT /admin/images/:id HelloWeb.Admin.ImageController :update admin_image_path DELETE /admin/images/:id HelloWeb.Admin.ImageController :delete admin_review_path GET /admin/reviews HelloWeb.Admin.ReviewController :index admin_review_path GET /admin/reviews/:id/edit HelloWeb.Admin.ReviewController :edit admin_review_path GET /admin/reviews/new HelloWeb.Admin.ReviewController :new admin_review_path GET /admin/reviews/:id HelloWeb.Admin.ReviewController :show admin_review_path POST /admin/reviews HelloWeb.Admin.ReviewController :create admin_review_path PATCH /admin/reviews/:id HelloWeb.Admin.ReviewController :update PUT /admin/reviews/:id HelloWeb.Admin.ReviewController :update admin_review_path DELETE /admin/reviews/:id HelloWeb.Admin.ReviewController :delete admin_user_path GET /admin/users HelloWeb.Admin.UserController :index admin_user_path GET /admin/users/:id/edit HelloWeb.Admin.UserController :edit admin_user_path GET /admin/users/new HelloWeb.Admin.UserController :new admin_user_path GET /admin/users/:id HelloWeb.Admin.UserController :show admin_user_path POST /admin/users HelloWeb.Admin.UserController :create admin_user_path PATCH /admin/users/:id HelloWeb.Admin.UserController :update PUT /admin/users/:id HelloWeb.Admin.UserController :update admin_user_path DELETE /admin/users/:id HelloWeb.Admin.UserController :delete This is great, exactly what we want, but we can make it even better. Notice that for each resource, we needed to fully qualify the controller name by prefixing it with HelloWeb.Admin. That&#39;s tedious and error prone. Assuming that the name of each controller begins with HelloWeb.Admin, then we can add a HelloWeb.Admin option to our scope declaration just after the scope path, and all of our routes will have the correct, fully qualified controller name. scope &quot;/admin&quot;, HelloWeb.Admin, as: :admin do pipe_through :browser resources &quot;/images&quot;, ImageController resources &quot;/reviews&quot;, ReviewController resources &quot;/users&quot;, UserController end Now run mix phx.routes again and you can see that we get the same result as above when we qualified each controller name individually. This doesn&#39;t just apply to nested routes, we can even nest all of the routes for our application inside a scope that simply has an alias for the name of our Phoenix app, and eliminate the duplication of our application name in our controller names. Phoenix already does this for us in the generated router for a new application (see beginning of this section). Notice here the use of HelloWeb in the scope declaration: defmodule HelloWeb.Router do use HelloWeb, :router scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/images&quot;, ImageController, :index resources &quot;/reviews&quot;, ReviewController resources &quot;/users&quot;, UserController end end Again mix phx.routes tells us that all of our controllers now have the correct, fully-qualified names. image_path GET /images HelloWeb.ImageController :index review_path GET /reviews HelloWeb.ReviewController :index review_path GET /reviews/:id/edit HelloWeb.ReviewController :edit review_path GET /reviews/new HelloWeb.ReviewController :new review_path GET /reviews/:id HelloWeb.ReviewController :show review_path POST /reviews HelloWeb.ReviewController :create review_path PATCH /reviews/:id HelloWeb.ReviewController :update PUT /reviews/:id HelloWeb.ReviewController :update review_path DELETE /reviews/:id HelloWeb.ReviewController :delete user_path GET /users HelloWeb.UserController :index user_path GET /users/:id/edit HelloWeb.UserController :edit user_path GET /users/new HelloWeb.UserController :new user_path GET /users/:id HelloWeb.UserController :show user_path POST /users HelloWeb.UserController :create user_path PATCH /users/:id HelloWeb.UserController :update PUT /users/:id HelloWeb.UserController :update user_path DELETE /users/:id HelloWeb.UserController :delete Although technically scopes can also be nested (just like resources), the use of nested scopes is generally discouraged because it can sometimes make our code confusing and less clear. With that said, suppose that we had a versioned API with resources defined for images, reviews and users. Then technically we could setup routes for the versioned API like this: scope &quot;/api&quot;, HelloWeb.Api, as: :api do pipe_through :api scope &quot;/v1&quot;, V1, as: :v1 do resources &quot;/images&quot;, ImageController resources &quot;/reviews&quot;, ReviewController resources &quot;/users&quot;, UserController end end mix phx.routes tells us that we have the routes we&#39;re looking for. api_v1_image_path GET /api/v1/images HelloWeb.Api.V1.ImageController :index api_v1_image_path GET /api/v1/images/:id/edit HelloWeb.Api.V1.ImageController :edit api_v1_image_path GET /api/v1/images/new HelloWeb.Api.V1.ImageController :new api_v1_image_path GET /api/v1/images/:id HelloWeb.Api.V1.ImageController :show api_v1_image_path POST /api/v1/images HelloWeb.Api.V1.ImageController :create api_v1_image_path PATCH /api/v1/images/:id HelloWeb.Api.V1.ImageController :update PUT /api/v1/images/:id HelloWeb.Api.V1.ImageController :update api_v1_image_path DELETE /api/v1/images/:id HelloWeb.Api.V1.ImageController :delete api_v1_review_path GET /api/v1/reviews HelloWeb.Api.V1.ReviewController :index api_v1_review_path GET /api/v1/reviews/:id/edit HelloWeb.Api.V1.ReviewController :edit api_v1_review_path GET /api/v1/reviews/new HelloWeb.Api.V1.ReviewController :new api_v1_review_path GET /api/v1/reviews/:id HelloWeb.Api.V1.ReviewController :show api_v1_review_path POST /api/v1/reviews HelloWeb.Api.V1.ReviewController :create api_v1_review_path PATCH /api/v1/reviews/:id HelloWeb.Api.V1.ReviewController :update PUT /api/v1/reviews/:id HelloWeb.Api.V1.ReviewController :update api_v1_review_path DELETE /api/v1/reviews/:id HelloWeb.Api.V1.ReviewController :delete api_v1_user_path GET /api/v1/users HelloWeb.Api.V1.UserController :index api_v1_user_path GET /api/v1/users/:id/edit HelloWeb.Api.V1.UserController :edit api_v1_user_path GET /api/v1/users/new HelloWeb.Api.V1.UserController :new api_v1_user_path GET /api/v1/users/:id HelloWeb.Api.V1.UserController :show api_v1_user_path POST /api/v1/users HelloWeb.Api.V1.UserController :create api_v1_user_path PATCH /api/v1/users/:id HelloWeb.Api.V1.UserController :update PUT /api/v1/users/:id HelloWeb.Api.V1.UserController :update api_v1_user_path DELETE /api/v1/users/:id HelloWeb.Api.V1.UserController :delete Interestingly, we can use multiple scopes with the same path as long as we are careful not to duplicate routes. If we do duplicate a route, we&#39;ll get this familiar warning. warning: this clause cannot match because a previous clause at line 16 always matches This router is perfectly fine with two scopes defined for the same path. defmodule HelloWeb.Router do use Phoenix.Router ... scope &quot;/&quot;, HelloWeb do pipe_through :browser resources &quot;/users&quot;, UserController end scope &quot;/&quot;, AnotherAppWeb do pipe_through :browser resources &quot;/posts&quot;, PostController end ... end And when we run mix phx.routes, we see the following output. user_path GET /users HelloWeb.UserController :index user_path GET /users/:id/edit HelloWeb.UserController :edit user_path GET /users/new HelloWeb.UserController :new user_path GET /users/:id HelloWeb.UserController :show user_path POST /users HelloWeb.UserController :create user_path PATCH /users/:id HelloWeb.UserController :update PUT /users/:id HelloWeb.UserController :update user_path DELETE /users/:id HelloWeb.UserController :delete post_path GET /posts AnotherAppWeb.PostController :index post_path GET /posts/:id/edit AnotherAppWeb.PostController :edit post_path GET /posts/new AnotherAppWeb.PostController :new post_path GET /posts/:id AnotherAppWeb.PostController :show post_path POST /posts AnotherAppWeb.PostController :create post_path PATCH /posts/:id AnotherAppWeb.PostController :update PUT /posts/:id AnotherAppWeb.PostController :update post_path DELETE /posts/:id AnotherAppWeb.PostController :delete"},{"ref":"routing.html#pipelines","title":"Routing - Pipelines","type":"extras","doc":"We have come quite a long way in this guide without talking about one of the first lines we saw in the router - pipe_through :browser. It&#39;s time to fix that. Remember in the Overview Guide when we described plugs as being stacked and executable in a pre-determined order, like a pipeline? Now we&#39;re going to take a closer look at how these plug stacks work in the router. Pipelines are simply plugs stacked up together in a specific order and given a name. They allow us to customize behaviors and transformations related to the handling of requests. Phoenix provides us with some default pipelines for a number of common tasks. In turn we can customize them as well as create new pipelines to meet our needs. A newly generated Phoenix application defines two pipelines called :browser and :api. We&#39;ll get to those in a minute, but first we need to talk about the plug stack in the Endpoint plugs. The Endpoint Plugs Endpoints organize all the plugs common to every request, and apply them before dispatching into the router(s) with their underlying :browser, :api, and custom pipelines. The default Endpoint plugs do quite a lot of work. Here they are in order. Plug.Static - serves static assets. Since this plug comes before the logger, serving of static assets is not logged Phoenix.CodeReloader - a plug that enables code reloading for all entries in the web directory. It is configured directly in the Phoenix application Plug.RequestId - generates a unique request id for each request. Plug.Logger - logs incoming requests Plug.Parsers - parses the request body when a known parser is available. By default parsers parse urlencoded, multipart and json (with jason). The request body is left untouched when the request content-type cannot be parsed Plug.MethodOverride - converts the request method to PUT, PATCH or DELETE for POST requests with a valid _method parameter Plug.Head - converts HEAD requests to GET requests and strips the response body Plug.Session - a plug that sets up session management. Note that fetch_session/2 must still be explicitly called before using the session as this plug just sets up how the session is fetched Plug.Router - plugs a router into the request cycle The :browser and :api Pipelines Phoenix defines two other pipelines by default, :browser and :api. The router will invoke these after it matches a route, assuming we have called pipe_through/1 with them in the enclosing scope. As their names suggest, the :browser pipeline prepares for routes which render requests for a browser. The :api pipeline prepares for routes which produce data for an api. The :browser pipeline has five plugs: plug :accepts, [&quot;html&quot;] which defines the request format or formats which will be accepted, :fetch_session, which, naturally, fetches the session data and makes it available in the connection, :fetch_flash which retrieves any flash messages which may have been set, as well as :protect_from_forgery and :put_secure_browser_headers, which protects form posts from cross site forgery. Currently, the :api pipeline only defines plug :accepts, [&quot;json&quot;]. The router invokes a pipeline on a route defined within a scope. If no scope is defined, the router will invoke the pipeline on all the routes in the router. Although the use of nested scopes is discouraged (see above), if we call pipe_through within a nested scope, the router will invoke all pipe_through&#39;s from parent scopes, followed by the nested one. Those are a lot of words bunched up together. Let&#39;s take a look at some examples to untangle their meaning. Here&#39;s another look at the router from a newly generated Phoenix application, this time with the api scope uncommented back in and a route added. defmodule HelloWeb.Router do use HelloWeb, :router pipeline :browser do plug :accepts, [&quot;html&quot;] plug :fetch_session plug :fetch_flash plug :protect_from_forgery plug :put_secure_browser_headers end pipeline :api do plug :accepts, [&quot;json&quot;] end scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index end # Other scopes may use custom stacks. scope &quot;/api&quot;, HelloWeb do pipe_through :api resources &quot;/reviews&quot;, ReviewController end end When the server accepts a request, the request will always first pass through the plugs in our Endpoint, after which it will attempt to match on the path and HTTP verb. Let&#39;s say that the request matches our first route: a GET to /. The router will first pipe that request through the :browser pipeline - which will fetch the session data, fetch the flash, and execute forgery protection - before it dispatches the request to the PageController index action. Conversely, if the request matches any of the routes defined by the resources/2 macro, the router will pipe it through the :api pipeline - which currently does nothing - before it dispatches further to the correct action of the HelloWeb.ReviewController. If we know that our application only renders views for the browser, we can simplify our router quite a bit by removing the api stuff as well as the scopes: defmodule HelloWeb.Router do use HelloWeb, :router pipeline :browser do plug :accepts, [&quot;html&quot;] plug :fetch_session plug :fetch_flash plug :protect_from_forgery plug :put_secure_browser_headers end pipe_through :browser get &quot;/&quot;, HelloWeb.PageController, :index resources &quot;/reviews&quot;, HelloWeb.ReviewController end Removing all scopes forces the router to invoke the :browser pipeline on all routes. Let&#39;s stretch these ideas out a little bit more. What if we need to pipe requests through both :browser and one or more custom pipelines? We simply pipe_through a list of pipelines, and Phoenix will invoke them in order. defmodule HelloWeb.Router do use HelloWeb, :router pipeline :browser do plug :accepts, [&quot;html&quot;] plug :fetch_session plug :fetch_flash plug :protect_from_forgery plug :put_secure_browser_headers end ... scope &quot;/reviews&quot; do pipe_through [:browser, :review_checks, :other_great_stuff] resources &quot;/&quot;, HelloWeb.ReviewController end end Here&#39;s another example with two scopes that have different pipelines: defmodule HelloWeb.Router do use HelloWeb, :router pipeline :browser do plug :accepts, [&quot;html&quot;] plug :fetch_session plug :fetch_flash plug :protect_from_forgery plug :put_secure_browser_headers end ... scope &quot;/&quot;, HelloWeb do pipe_through :browser resources &quot;/posts&quot;, PostController end scope &quot;/reviews&quot;, HelloWeb do pipe_through [:browser, :review_checks] resources &quot;/&quot;, ReviewController end end In general, the scoping rules for pipelines behave as you might expect. In this example, all routes will pipe through the :browser pipeline. However, only the reviews resources routes will pipe through the :review_checks pipeline. Since we declared both pipes pipe_through [:browser, :review_checks] in a list of pipelines, Phoenix will pipe_through each of them as it invokes them in order. Creating New Pipelines Phoenix allows us to create our own custom pipelines anywhere in the router. To do so, we call the pipeline/2 macro with these arguments: an atom for the name of our new pipeline and a block with all the plugs we want in it. defmodule HelloWeb.Router do use HelloWeb, :router pipeline :browser do plug :accepts, [&quot;html&quot;] plug :fetch_session plug :fetch_flash plug :protect_from_forgery plug :put_secure_browser_headers end pipeline :review_checks do plug :ensure_authenticated_user plug :ensure_user_owns_review end scope &quot;/reviews&quot;, HelloWeb do pipe_through :review_checks resources &quot;/&quot;, ReviewController end end"},{"ref":"routing.html#channel-routes","title":"Routing - Channel Routes","type":"extras","doc":"Channels are a very exciting, real-time component of the Phoenix framework. Channels handle incoming and outgoing messages broadcast over a socket for a given topic. Channel routes, then, need to match requests by socket and topic in order to dispatch to the correct channel. (For a more detailed description of channels and their behavior, please see the Channel Guide.) We mount socket handlers in our endpoint at lib/hello_web/endpoint.ex. Socket handlers take care of authentication callbacks and channel routes. defmodule HelloWeb.Endpoint do use Phoenix.Endpoint, otp_app: :hello socket &quot;/socket&quot;, HelloWeb.UserSocket, websocket: true, longpoll: false ... end By default, Phoenix supports both websockets and longpoll when invoking Phoenix.Endpoint.socket/3 in your endpoint. Here we&#39;re specifying that incoming socket connections can be made via a WebSocket connection. Next, we need to open our lib/hello_web/channels/user_socket.ex file and use the channel/3 macro to define our channel routes. The routes will match a topic pattern to a channel to handle events. If we have a channel module called RoomChannel and a topic called &quot;rooms:*&quot;, the code to do this is straightforward. defmodule HelloWeb.UserSocket do use Phoenix.Socket channel &quot;rooms:*&quot;, HelloWeb.RoomChannel ... end Topics are just string identifiers. The form we are using here is a convention which allows us to define topics and subtopics in the same string - &quot;topic:subtopic&quot;. The * is a wildcard character which allows us to match on any subtopic, so &quot;rooms:lobby&quot; and &quot;rooms:kitchen&quot; would both match this route. Each socket can handle requests for multiple channels. channel &quot;rooms:*&quot;, HelloWeb.RoomChannel channel &quot;foods:*&quot;, HelloWeb.FoodChannel We can mount multiple socket handlers in our endpoint: socket &quot;/socket&quot;, HelloWeb.UserSocket socket &quot;/admin-socket&quot;, HelloWeb.AdminSocket"},{"ref":"routing.html#summary","title":"Routing - Summary","type":"extras","doc":"Routing is a big topic, and we have covered a lot of ground here. The important points to take away from this guide are: Routes which begin with an HTTP verb name expand to a single clause of the match function. Routes which begin with &#39;resources&#39; expand to 8 clauses of the match function. Resources may restrict the number of match function clauses by using the only: or except: options. Any of these routes may be nested. Any of these routes may be scoped to a given path. Using the as: option in a scope can reduce duplication. Using the helper option for scoped routes eliminates unreachable paths."},{"ref":"plug.html","title":"Plug","type":"extras","doc":"Plug Plug lives at the heart of Phoenix&#39;s HTTP layer, and Phoenix puts Plug front and center. We interact with plugs at every step of the connection lifecycle, and the core Phoenix components like Endpoints, Routers, and Controllers are all just Plugs internally. Let&#39;s jump in and find out just what makes Plug so special. Plug is a specification for composable modules in between web applications. It is also an abstraction layer for connection adapters of different web servers. The basic idea of Plug is to unify the concept of a &quot;connection&quot; that we operate on. This differs from other HTTP middleware layers such as Rack, where the request and response are separated in the middleware stack. At the simplest level, the Plug specification comes in two flavors: function plugs and module plugs."},{"ref":"plug.html#function-plugs","title":"Plug - Function Plugs","type":"extras","doc":"In order to act as a plug, a function simply needs to accept a connection struct (%Plug.Conn{}) and options. It also needs to return a connection struct. Any function that meets those criteria will do. Here&#39;s an example. def put_headers(conn, key_values) do Enum.reduce key_values, conn, fn {k, v}, conn -&gt; Plug.Conn.put_resp_header(conn, to_string(k), v) end end Pretty simple, right? This is how we use them to compose a series of transformations on our connection in Phoenix: defmodule HelloWeb.MessageController do use HelloWeb, :controller plug :put_headers, %{content_encoding: &quot;gzip&quot;, cache_control: &quot;max-age=3600&quot;} plug :put_layout, &quot;bare.html&quot; ... end By abiding by the plug contract, put_headers/2, put_layout/2, and even action/2 turn an application request into a series of explicit transformations. It doesn&#39;t stop there. To really see how effective Plug&#39;s design is, let&#39;s imagine a scenario where we need to check a series of conditions and then either redirect or halt if a condition fails. Without plug, we would end up with something like this: defmodule HelloWeb.MessageController do use HelloWeb, :controller def show(conn, params) do case authenticate(conn) do {:ok, user} -&gt; case find_message(params[&quot;id&quot;]) do nil -&gt; conn |&gt; put_flash(:info, &quot;That message wasn&#39;t found&quot;) |&gt; redirect(to: &quot;/&quot;) message -&gt; case authorize_message(conn, params[&quot;id&quot;]) do :ok -&gt; render(conn, :show, page: find_message(params[&quot;id&quot;])) :error -&gt; conn |&gt; put_flash(:info, &quot;You can&#39;t access that page&quot;) |&gt; redirect(to: &quot;/&quot;) end end :error -&gt; conn |&gt; put_flash(:info, &quot;You must be logged in&quot;) |&gt; redirect(to: &quot;/&quot;) end end end Notice how just a few steps of authentication and authorization require complicated nesting and duplication? Let&#39;s improve this with a couple of plugs. defmodule HelloWeb.MessageController do use HelloWeb, :controller plug :authenticate plug :fetch_message plug :authorize_message def show(conn, params) do render(conn, :show, page: find_message(params[&quot;id&quot;])) end defp authenticate(conn, _) do case Authenticator.find_user(conn) do {:ok, user} -&gt; assign(conn, :user, user) :error -&gt; conn |&gt; put_flash(:info, &quot;You must be logged in&quot;) |&gt; redirect(to: &quot;/&quot;) |&gt; halt() end end defp fetch_message(conn, _) do case find_message(conn.params[&quot;id&quot;]) do nil -&gt; conn |&gt; put_flash(:info, &quot;That message wasn&#39;t found&quot;) |&gt; redirect(to: &quot;/&quot;) |&gt; halt() message -&gt; assign(conn, :message, message) end end defp authorize_message(conn, _) do if Authorizer.can_access?(conn.assigns[:user], conn.assigns[:message]) do conn else conn |&gt; put_flash(:info, &quot;You can&#39;t access that page&quot;) |&gt; redirect(to: &quot;/&quot;) |&gt; halt() end end end By replacing the nested blocks of code with a flattened series of plug transformations, we are able to achieve the same functionality in a much more composable, clear, and reusable way. Now let&#39;s look at the other flavor plugs come in, module plugs."},{"ref":"plug.html#module-plugs","title":"Plug - Module Plugs","type":"extras","doc":"Module plugs are another type of Plug that let us define a connection transformation in a module. The module only needs to implement two functions: init/1 which initializes any arguments or options to be passed to call/2 call/2 which carries out the connection transformation. call/2 is just a function plug that we saw earlier To see this in action, let&#39;s write a module plug that puts the :locale key and value into the connection assign for downstream use in other plugs, controller actions, and our views. defmodule HelloWeb.Plugs.Locale do import Plug.Conn @locales [&quot;en&quot;, &quot;fr&quot;, &quot;de&quot;] def init(default), do: default def call(%Plug.Conn{params: %{&quot;locale&quot; =&gt; loc}} = conn, _default) when loc in @locales do assign(conn, :locale, loc) end def call(conn, default), do: assign(conn, :locale, default) end defmodule HelloWeb.Router do use HelloWeb, :router pipeline :browser do plug :accepts, [&quot;html&quot;] plug :fetch_session plug :fetch_flash plug :protect_from_forgery plug :put_secure_browser_headers plug HelloWeb.Plugs.Locale, &quot;en&quot; end ... We are able to add this module plug to our browser pipeline via plug HelloWeb.Plugs.Locale, &quot;en&quot;. In the init/1 callback, we pass a default locale to use if none is present in the params. We also use pattern matching to define multiple call/2 function heads to validate the locale in the params, and fall back to &quot;en&quot; if there is no match. That&#39;s all there is to Plug. Phoenix embraces the plug design of composable transformations all the way up and down the stack. This is just the first taste. If we ask ourselves, &quot;Could I put this in a plug?&quot; The answer is usually, &quot;Yes!&quot;"},{"ref":"endpoint.html","title":"Endpoint","type":"extras","doc":"Endpoint Phoenix applications start the HelloWeb.Endpoint as a supervised process. By default, the Endpoint is added to the supervision tree in lib/hello/application.ex as a supervised process. Each request begins and ends its lifecycle inside your application in an endpoint. The endpoint handles starting the web server and transforming requests through several defined plugs before calling the Router. defmodule Hello.Application do use Application def start(_type, _args) do ... children = [ HelloWeb.Endpoint ] opts = [strategy: :one_for_one, name: Hello.Supervisor] Supervisor.start_link(children, opts) end end Endpoint Contents Endpoints gather together common functionality and serve as entrance and exit for all of the HTTP requests to your application. The endpoint holds plugs that are common to all requests coming into your application. Let&#39;s take a look at the endpoint for the application Hello generated in the Up and Running page. defmodule HelloWeb.Endpoint do ... end The first call inside of our Endpoint module is the use Phoenix.Endpoint macro with the otp_app. The otp_app is used for the configuration. This defines several functions on the HelloWeb.Endpoint module, including the start_link function which is called in the supervision tree. use Phoenix.Endpoint, otp_app: :hello Next the endpoint declares a socket on the &quot;/socket&quot; URI. &quot;/socket&quot; requests will be handled by the HelloWeb.UserSocket module which is declared elsewhere in our application. Here we are just declaring that such a connection will exist. socket &quot;/socket&quot;, HelloWeb.UserSocket, websocket: true, longpoll: false Next comes a series of plugs that are relevant to all requests in our application. We can customize some of the features, for example, enabling gzip: true when deploying to production to gzip the static files. Static files are served from priv/static before any part of our request makes it to a router. plug Plug.Static, at: &quot;/&quot;, from: :hello, gzip: false, only: ~w(css fonts images js favicon.ico robots.txt) If code reloading is enabled, a socket will be used to communicate to the browser that the page needs to be reloaded when code is changed on the server. This feature is enabled by default in the development environment. This is configured using config :hello, HelloWeb.Endpoint, code_reloader: true. if code_reloading? do socket &quot;/phoenix/live_reload/socket&quot;, Phoenix.LiveReloader.Socket plug Phoenix.LiveReloader plug Phoenix.CodeReloader end Plug.RequestId generates a unique id for each request and Plug.Telemetry adds instrumentation points so Phoenix can log the request path, status code and request time by default. plug Plug.RequestId plug Plug.Telemetry, event_prefix: [:phoenix, :endpoint] Plug.Session handles the session cookies and session stores. plug Plug.Session, @session_options By default the last plug in the endpoint is the router. The router matches a path to a particular controller action or plug. The router is covered in the Routing Guide. plug HelloWeb.Router The endpoint can be customized to add additional plugs, to allow HTTP basic authentication, CORS, subdomain routing and more. Faults in the different parts of the supervision tree, such as the Ecto Repo, will not immediately impact the main application. The supervisor is therefore able to restart those processes separately after unexpected faults. It is also possible for an application to have multiple endpoints, each with its own supervision tree. There are many functions defined in the endpoint module for path helpers, channel subscriptions and broadcasts, instrumentation, and endpoint configuration. These are all covered in the Endpoint API docs for Phoenix.Endpoint."},{"ref":"endpoint.html#using-ssl","title":"Endpoint - Using SSL","type":"extras","doc":"To prepare an application to serve requests over SSL, we need to add a little bit of configuration and two environment variables. In order for SSL to actually work, we&#39;ll need a key file and certificate file from a certificate authority. The environment variables that we&#39;ll need are paths to those two files. The configuration consists of a new https: key for our endpoint whose value is a keyword list of port, path to the key file, and path to the cert (pem) file. If we add the otp_app: key whose value is the name of our application, Plug will begin to look for them at the root of our application. We can then put those files in our priv directory and set the paths to priv/our_keyfile.key and priv/our_cert.crt. Here&#39;s an example configuration from config/prod.exs. use Mix.Config config :hello, HelloWeb.Endpoint, http: [port: {:system, &quot;PORT&quot;}], url: [host: &quot;example.com&quot;], cache_static_manifest: &quot;priv/static/cache_manifest.json&quot;, https: [ port: 443, cipher_suite: :strong, otp_app: :hello, keyfile: System.get_env(&quot;SOME_APP_SSL_KEY_PATH&quot;), certfile: System.get_env(&quot;SOME_APP_SSL_CERT_PATH&quot;), # OPTIONAL Key for intermediate certificates: cacertfile: System.get_env(&quot;INTERMEDIATE_CERTFILE_PATH&quot;) ] Without the otp_app: key, we need to provide absolute paths to the files wherever they are on the filesystem in order for Plug to find them. Path.expand(&quot;../../../some/path/to/ssl/key.pem&quot;, __DIR__) The options under the https: key are passed to the Plug adapter, typically Plug.Cowboy, which in turn uses Plug.SSL to select the TLS socket options. Please refer to the documentation for Plug.SSL.configure/1 for more information on the available options and their defaults. The Plug HTTPS Guide and the Erlang/OTP ssl documentation also provide valuable information. SSL in Development If you would like to use HTTPS in development, a self-signed certificate can be generated by running: mix phx.gen.cert. This requires Erlang/OTP 20 or later. With your self-signed certificate, your development configuration in config/dev.exs can be updated to run an HTTPS endpoint: config :my_app, MyApp.Endpoint, ... https: [ port: 4001, cipher_suite: :strong, keyfile: &quot;priv/cert/selfsigned_key.pem&quot;, certfile: &quot;priv/cert/selfsigned.pem&quot; ] This can replace your http configuration, or you can run HTTP and HTTPS servers on different ports. Force SSL In many cases, you&#39;ll want to force all incoming requests to use SSL by redirecting HTTP to HTTPS. This can be accomplished by setting the :force_ssl option in your endpoint configuration. It expects a list of options which are forwarded to Plug.SSL. By default it sets the &quot;strict-transport-security&quot; header in HTTPS requests, forcing browsers to always use HTTPS. If an unsafe (HTTP) request is sent, it redirects to the HTTPS version using the :host specified in the :url configuration. For example: config :my_app, MyApp.Endpoint, force_ssl: [rewrite_on: [:x_forwarded_proto]] To dynamically redirect to the host of the current request, set :host in the :force_ssl configuration to nil. config :my_app, MyApp.Endpoint, force_ssl: [rewrite_on: [:x_forwarded_proto], host: nil] In these examples, the rewrite_on: key specifies the HTTP header used by a reverse proxy or load balancer in front of the application to indicate whether the request was received over HTTP or HTTPS. For more information on the implications of offloading TLS to an external element, in particular relating to secure cookies, refer to the Plug HTTPS Guide. Keep in mind that the options passed to Plug.SSL in that document should be set using the force_ssl: endpoint option in a Phoenix application. HSTS HSTS or &quot;strict-transport-security&quot; is a mechanism that allows a website to declare itself as only accessible via a secure connection (HTTPS). It was introduced to prevent man-in-the-middle attacks that strip SSL/TLS. It causes web browsers to redirect from HTTP to HTTPS and refuse to connect unless the connection uses SSL/TLS. With force_ssl: :hsts set the Strict-Transport-Security header is set with a max age that defines the length of time the policy is valid for. Modern web browsers will respond to this by redirecting from HTTP to HTTPS for the standard case but it does have other consequenses. RFC6797 which defines HSTS also specifies that the browser should keep track of the policy of a host and apply it until it expires. It also specifies that traffic on any port other than 80 is assumed to be encrypted as per the policy. This can result in unexpected behaviour if you access your application on localhost, for example https://localhost:4000, as from that point forward and traffic coming from localhost will be expected to be encrypted, except port 80 which will be redirected to port 443. This has the potential to disrupt traffic to any other local servers or proxies that you may be running on your computer. Other applications or proxies on localhost will refuse to work unless the traffic is encrypted. If you do inadvertently turn on HSTS for localhost you may need to reset the cache on your browser before it will accept any HTTP traffic from localhost. For Chrome you need to Empty Cache and Hard Reload which is available from the reload menu that appears when you click and hold the reload icon from the Developer Tools Panel. For Safari you will need to clear your cache, remove the entry from ~/Library/Cookies/HSTS.plist (or delete that file entirely) and restart Safari. Alternately you can set the :expires option on force_ssl to 0 which should expired the entry to turn off HSTS. More information on the options for HSTS are available at Plug.SSL."},{"ref":"controllers.html","title":"Controllers","type":"extras","doc":"Controllers Phoenix controllers act as intermediary modules. Their functions - called actions - are invoked from the router in response to HTTP requests. The actions, in turn, gather all the necessary data and perform all the necessary steps before invoking the view layer to render a template or returning a JSON response. Phoenix controllers also build on the Plug package, and are themselves plugs. Controllers provide the functions to do almost anything we need to in an action. If we do find ourselves looking for something that Phoenix controllers don&#39;t provide; however, we might find what we&#39;re looking for in Plug itself. Please see the Plug Guide or Plug Documentation for more information. A newly generated Phoenix app will have a single controller, the PageController, which can be found at lib/hello_web/controllers/page_controller.ex and looks like this. defmodule HelloWeb.PageController do use HelloWeb, :controller def index(conn, _params) do render(conn, &quot;index.html&quot;) end end The first line below the module definition invokes the __using__/1 macro of the HelloWeb module, which imports some useful modules. The PageController gives us the index action to display the Phoenix welcome page associated with the default route Phoenix defines in the router."},{"ref":"controllers.html#actions","title":"Controllers - Actions","type":"extras","doc":"Controller actions are just functions. We can name them anything we like as long as they follow Elixir&#39;s naming rules. The only requirement we must fulfill is that the action name matches a route defined in the router. For example, in lib/hello_web/router.ex we could change the action name in the default route that Phoenix gives us in a new app from index: get &quot;/&quot;, PageController, :index To test: get &quot;/&quot;, PageController, :test As long as we change the action name in the PageController to test as well, the welcome page will load as before. defmodule HelloWeb.PageController do ... def test(conn, _params) do render(conn, &quot;index.html&quot;) end end While we can name our actions whatever we like, there are conventions for action names which we should follow whenever possible. We went over these in the Routing Guide, but we&#39;ll take another quick look here. index - renders a list of all items of the given resource type show - renders an individual item by id new - renders a form for creating a new item create - receives params for one new item and saves it in a datastore edit - retrieves an individual item by id and displays it in a form for editing update - receives params for one edited item and saves it to a datastore delete - receives an id for an item to be deleted and deletes it from a datastore Each of these actions takes two parameters, which will be provided by Phoenix behind the scenes. The first parameter is always conn, a struct which holds information about the request such as the host, path elements, port, query string, and much more. conn, comes to Phoenix via Elixir&#39;s Plug middleware framework. More detailed info about conn can be found in plug&#39;s documentation. The second parameter is params. Not surprisingly, this is a map which holds any parameters passed along in the HTTP request. It is a good practice to pattern match against params in the function signature to provide data in a simple package we can pass on to rendering. We saw this in the Adding Pages guide when we added a messenger parameter to our show route in lib/hello_web/controllers/hello_controller.ex. defmodule HelloWeb.HelloController do ... def show(conn, %{&quot;messenger&quot; =&gt; messenger}) do render(conn, &quot;show.html&quot;, messenger: messenger) end end In some cases - often in index actions, for instance - we don&#39;t care about parameters because our behavior doesn&#39;t depend on them. In those cases, we don&#39;t use the incoming params, and simply prepend the variable name with an underscore, _params. This will keep the compiler from complaining about the unused variable while still keeping the correct arity. Gathering Data While Phoenix does not ship with its own data access layer, the Elixir project Ecto provides a very nice solution for those using the Postgres relational database. We cover how to use Ecto in a Phoenix project in the Ecto Guide. Databases supported by Ecto are covered in the Usage section of the Ecto README. Of course, there are many other data access options. Ets and Dets are key value data stores built into OTP. OTP also provides a relational database called mnesia with its own query language called QLC. Both Elixir and Erlang also have a number of libraries for working with a wide range of popular data stores. The data world is your oyster, but we won&#39;t be covering these options in these guides."},{"ref":"controllers.html#flash-messages","title":"Controllers - Flash Messages","type":"extras","doc":"There are times when we need to communicate with users during the course of an action. Maybe there was an error updating a schema. Maybe we just want to welcome them back to the application. For this, we have flash messages. The Phoenix.Controller module provides the put_flash/3 and get_flash/2 functions to help us set and retrieve flash messages as a key value pair. Let&#39;s set two flash messages in our HelloWeb.PageController to try this out. To do this we modify the index action as follows: defmodule HelloWeb.PageController do ... def index(conn, _params) do conn |&gt; put_flash(:info, &quot;Welcome to Phoenix, from flash info!&quot;) |&gt; put_flash(:error, &quot;Let&#39;s pretend we have an error.&quot;) |&gt; render(&quot;index.html&quot;) end end The Phoenix.Controller module is not particular about the keys we use. As long as we are internally consistent, all will be well. :info and :error, however, are common. In order to see our flash messages, we need to be able to retrieve them and display them in a template/layout. One way to do the first part is with get_flash/2 which takes conn and the key we care about. It then returns the value for that key. Fortunately, our application layout, lib/hello_web/templates/layout/app.html.eex, already has markup for displaying flash messages. &lt;p class=&quot;alert alert-info&quot; role=&quot;alert&quot;&gt;&lt;%= get_flash(@conn, :info) %&gt;&lt;/p&gt; &lt;p class=&quot;alert alert-danger&quot; role=&quot;alert&quot;&gt;&lt;%= get_flash(@conn, :error) %&gt;&lt;/p&gt; When we reload the Welcome Page, our messages should appear just above &quot;Welcome to Phoenix!&quot; Besides put_flash/3 and get_flash/2, the Phoenix.Controller module has another useful function worth knowing about. clear_flash/1 takes only conn and removes any flash messages which might be stored in the session."},{"ref":"controllers.html#rendering","title":"Controllers - Rendering","type":"extras","doc":"Controllers have several ways of rendering content. The simplest is to render some plain text using the text/2 function which Phoenix provides. Let&#39;s say we have a show action which receives an id from the params map, and all we want to do is return some text with the id. For that, we could do the following. def show(conn, %{&quot;id&quot; =&gt; id}) do text(conn, &quot;Showing id \#{id}&quot;) end Assuming we had a route for get &quot;/our_path/:id&quot; mapped to this show action, going to /our_path/15 in your browser should display Showing id 15 as plain text without any HTML. A step beyond this is rendering pure JSON with the json/2 function. We need to pass it something that the Jason library can decode into JSON, such as a map. (Jason is one of Phoenix&#39;s dependencies.) def show(conn, %{&quot;id&quot; =&gt; id}) do json(conn, %{id: id}) end If we again visit our_path/15 in the browser, we should see a block of JSON with the key id mapped to the number 15. {&quot;id&quot;: &quot;15&quot;} Phoenix controllers can also render HTML without a template. As you may have already guessed, the html/2 function does just that. This time, we implement the show action like this. def show(conn, %{&quot;id&quot; =&gt; id}) do html(conn, &quot;&quot;&quot; &lt;html&gt; &lt;head&gt; &lt;title&gt;Passing an Id&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;You sent in id \#{id}&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; &quot;&quot;&quot;) end Hitting /our_path/15 now renders the HTML string we defined in the show action, with the value 15 interpolated. Note that what we wrote in the action is not an eex template. It&#39;s a multi-line string, so we interpolate the id variable like this \#{id} instead of this &lt;%= id %&gt;. It is worth noting that the text/2, json/2, and html/2 functions require neither a Phoenix view, nor a template to render. The json/2 function is obviously useful for writing APIs, and the other two may come in handy, but rendering a template into a layout with values we pass in is a very common case. For this, Phoenix provides the render/3 function. Interestingly, render/3 is defined in the Phoenix.View module instead of Phoenix.Controller, but it is aliased in Phoenix.Controller for convenience. We have already seen the render function in the Adding Pages Guide. Our show action in lib/hello_web/controllers/hello_controller.ex looked like this. defmodule HelloWeb.HelloController do use HelloWeb, :controller def show(conn, %{&quot;messenger&quot; =&gt; messenger}) do render(conn, &quot;show.html&quot;, messenger: messenger) end end In order for the render/3 function to work correctly, the controller must have the same root name as the individual view. The individual view must also have the same root name as the template directory where the show.html.eex template lives. In other words, the HelloController requires HelloView, and HelloView requires the existence of the lib/hello_web/templates/hello directory, which must contain the show.html.eex template. render/3 will also pass the value which the show action received for messenger from the params hash into the template for interpolation. If we need to pass values into the template when using render, that&#39;s easy. We can pass a dictionary like we&#39;ve seen with messenger: messenger, or we can use Plug.Conn.assign/3, which conveniently returns conn. def index(conn, _params) do conn |&gt; assign(:message, &quot;Welcome Back!&quot;) |&gt; render(&quot;index.html&quot;) end Note: The Phoenix.Controller module imports Plug.Conn, so shortening the call to assign/3 works just fine. We can access this message in our index.html.eex template, or in our layout, with this &lt;%= @message %&gt;. Passing more than one value in to our template is as simple as connecting assign/3 functions together in a pipeline. def index(conn, _params) do conn |&gt; assign(:message, &quot;Welcome Back!&quot;) |&gt; assign(:name, &quot;Dweezil&quot;) |&gt; render(&quot;index.html&quot;) end With this, both @message and @name will be available in the index.html.eex template. What if we want to have a default welcome message that some actions can override? That&#39;s easy, we just use plug and transform conn on its way towards the controller action. plug :assign_welcome_message, &quot;Welcome Back&quot; def index(conn, _params) do conn |&gt; assign(:message, &quot;Welcome Forward&quot;) |&gt; render(&quot;index.html&quot;) end defp assign_welcome_message(conn, msg) do assign(conn, :message, msg) end What if we want to plug assign_welcome_message, but only for some of our actions? Phoenix offers a solution to this by letting us specify which actions a plug should be applied to. If we only wanted plug :assign_welcome_message to work on the index and show actions, we could do this. defmodule HelloWeb.PageController do use HelloWeb, :controller plug :assign_welcome_message, &quot;Hi!&quot; when action in [:index, :show] ... Sending responses directly If none of the rendering options above quite fits our needs, we can compose our own using some of the functions that Plug gives us. Let&#39;s say we want to send a response with a status of &quot;201&quot; and no body whatsoever. We can easily do that with the send_resp/3 function. def index(conn, _params) do conn |&gt; send_resp(201, &quot;&quot;) end Reloading http://localhost:4000 should show us a completely blank page. The network tab of our browser&#39;s developer tools should show a response status of &quot;201&quot;. If we would like to be really specific about the content type, we can use put_resp_content_type/2 in conjunction with send_resp/3. def index(conn, _params) do conn |&gt; put_resp_content_type(&quot;text/plain&quot;) |&gt; send_resp(201, &quot;&quot;) end Using Plug functions in this way, we can craft just the response we need. Rendering does not end with the template, though. By default, the results of the template render will be inserted into a layout, which will also be rendered. Templates and layouts have their own guide, so we won&#39;t spend much time on them here. What we will look at is how to assign a different layout, or none at all, from inside a controller action. Assigning Layouts Layouts are just a special subset of templates. They live in lib/hello_web/templates/layout. Phoenix created one for us when we generated our app. It&#39;s called app.html.eex, and it is the layout into which all templates will be rendered by default. Since layouts are really just templates, they need a view to render them. This is the LayoutView module defined in lib/hello_web/views/layout_view.ex. Since Phoenix generated this view for us, we won&#39;t have to create a new one as long as we put the layouts we want to render inside the lib/hello_web/templates/layout directory. Before we create a new layout, though, let&#39;s do the simplest possible thing and render a template with no layout at all. The Phoenix.Controller module provides the put_layout/2 function for us to switch layouts. This takes conn as its first argument and a string for the basename of the layout we want to render. Another clause of the function will match on the boolean false for the second argument, and that&#39;s how we will render the Phoenix welcome page without a layout. In a freshly generated Phoenix app, edit the index action of the PageController module lib/hello_web/controllers/page_controller.ex to look like this. def index(conn, _params) do conn |&gt; put_layout(false) |&gt; render(&quot;index.html&quot;) end After reloading http://localhost:4000/, we should see a very different page, one with no title, logo image, or css styling at all. Very Important! For function calls in a pipeline, it is critical to use parentheses around the arguments because the pipe operator binds very tightly. This leads to parsing problems and very strange results. If you ever get a stack trace that looks like this, **(FunctionClauseError) no function clause matching in Plug.Conn.get_resp_header/2 Stacktrace (plug) lib/plug/conn.ex:353: Plug.Conn.get_resp_header(false, &quot;content-type&quot;) where your argument replaces conn as the first argument, one of the first things to check is whether there are parentheses in the right places. This is fine. def index(conn, _params) do conn |&gt; put_layout(false) |&gt; render(&quot;index.html&quot;) end Whereas this won&#39;t work. def index(conn, _params) do conn |&gt; put_layout false |&gt; render &quot;index.html&quot; end Now let&#39;s actually create another layout and render the index template into it. As an example, let&#39;s say we had a different layout for the admin section of our application which didn&#39;t have the logo image. To do this, let&#39;s copy the existing app.html.eex to a new file admin.html.eex in the same directory lib/hello_web/templates/layout. Then let&#39;s remove the line in admin.html.eex that displays the logo. &lt;span class=&quot;logo&quot;&gt;&lt;/span&gt; &lt;!-- remove this line --&gt; Then, pass the basename of the new layout into put_layout/2 in our index action in lib/hello_web/controllers/page_controller.ex. def index(conn, _params) do conn |&gt; put_layout(&quot;admin.html&quot;) |&gt; render(&quot;index.html&quot;) end When we load the page, we should be rendering the admin layout without a logo. Overriding Rendering Formats Rendering HTML through a template is fine, but what if we need to change the rendering format on the fly? Let&#39;s say that sometimes we need HTML, sometimes we need plain text, and sometimes we need JSON. Then what? Phoenix allows us to change formats on the fly with the _format query string parameter. To make this happen, Phoenix requires an appropriately named view and an appropriately named template in the correct directory. As an example, let&#39;s take the PageController index action from a newly generated app. Out of the box, this has the right view, PageView, the right templates directory, lib/hello_web/templates/page, and the right template for rendering HTML, index.html.eex. def index(conn, _params) do render(conn, &quot;index.html&quot;) end What it doesn&#39;t have is an alternative template for rendering text. Let&#39;s add one at lib/hello_web/templates/page/index.text.eex. Here is our example index.text.eex template. OMG, this is actually some text. There are just a few more things we need to do to make this work. We need to tell our router that it should accept the text format. We do that by adding text to the list of accepted formats in the :browser pipeline. Let&#39;s open up lib/hello_web/router.ex and change the plug :accepts to include text as well as html like this. defmodule HelloWeb.Router do use HelloWeb, :router pipeline :browser do plug :accepts, [&quot;html&quot;, &quot;text&quot;] plug :fetch_session plug :protect_from_forgery plug :put_secure_browser_headers end ... We also need to tell the controller to render a template with the same format as the one returned by Phoenix.Controller.get_format/1. We do that by substituting the name of the template &quot;index.html&quot; with the atom version :index. def index(conn, _params) do render(conn, :index) end If we go to http://localhost:4000/?_format=text, we will see OMG, this is actually some text. Of course, we can pass data into our template as well. Let&#39;s change our action to take in a message parameter by removing the _ in front of params in the function definition. This time, we&#39;ll use the somewhat less-flexible string version of our text template, just to see that it works as well. def index(conn, params) do render(conn, &quot;index.text&quot;, message: params[&quot;message&quot;]) end And let&#39;s add a bit to our text template. OMG, this is actually some text. &lt;%= @message %&gt; Now if we go to http://localhost:4000/?_format=text&amp;message=CrazyTown, we will see &quot;OMG, this is actually some text. CrazyTown&quot; Setting the Content Type Analogous to the _format query string param, we can render any sort of format we want by modifying the HTTP Content-Type Header and providing the appropriate template. If we wanted to render an xml version of our index action, we might implement the action like this in lib/hello_web/page_controller.ex. def index(conn, _params) do conn |&gt; put_resp_content_type(&quot;text/xml&quot;) |&gt; render(&quot;index.xml&quot;, content: some_xml_content) end We would then need to provide an index.xml.eex template which created valid xml, and we would be done. For a list of valid content mime-types, please see the mime.types documentation from the mime type library. Setting the HTTP Status We can also set the HTTP status code of a response similarly to the way we set the content type. The Plug.Conn module, imported into all controllers, has a put_status/2 function to do this. Plug.Conn.put_status/2 takes conn as the first parameter and as the second parameter either an integer or a &quot;friendly name&quot; used as an atom for the status code we want to set. The list of status code atom representations can be found in Plug.Conn.Status.code/1 documentation. Let&#39;s change the status in our PageController index action. def index(conn, _params) do conn |&gt; put_status(202) |&gt; render(&quot;index.html&quot;) end The status code we provide must be valid - Cowboy, the web server Phoenix runs on, will throw an error on invalid codes. If we look at our development logs (which is to say, the iex session), or use our browser&#39;s web inspection network tool, we will see the status code being set as we reload the page. If the action sends a response - either renders or redirects - changing the code will not change the behavior of the response. If, for example, we set the status to 404 or 500 and then render(&quot;index.html&quot;), we do not get an error page. Similarly, no 300 level code will actually redirect. (It wouldn&#39;t know where to redirect to, even if the code did affect behavior.) The following implementation of the HelloWeb.PageController index action, for example, will not render the default not_found behavior as expected. def index(conn, _params) do conn |&gt; put_status(:not_found) |&gt; render(&quot;index.html&quot;) end The correct way to render the 404 page from HelloWeb.PageController is: def index(conn, _params) do conn |&gt; put_status(:not_found) |&gt; put_view(HelloWeb.ErrorView) |&gt; render(&quot;404.html&quot;) end"},{"ref":"controllers.html#redirection","title":"Controllers - Redirection","type":"extras","doc":"Often, we need to redirect to a new url in the middle of a request. A successful create action, for instance, will usually redirect to the show action for the schema we just created. Alternately, it could redirect to the index action to show all the things of that same type. There are plenty of other cases where redirection is useful as well. Whatever the circumstance, Phoenix controllers provide the handy redirect/2 function to make redirection easy. Phoenix differentiates between redirecting to a path within the application and redirecting to a url - either within our application or external to it. In order to try out redirect/2, let&#39;s create a new route in lib/hello_web/router.ex. defmodule HelloWeb.Router do use HelloWeb, :router ... scope &quot;/&quot;, HelloWeb do ... get &quot;/&quot;, PageController, :index end # New route for redirects scope &quot;/&quot;, HelloWeb do get &quot;/redirect_test&quot;, PageController, :redirect_test, as: :redirect_test end ... end Then we&#39;ll change the index action to do nothing but redirect to our new route. def index(conn, _params) do redirect(conn, to: &quot;/redirect_test&quot;) end Finally, let&#39;s define in the same file the action we redirect to, which simply renders the text Redirect!. def redirect_test(conn, _params) do text(conn, &quot;Redirect!&quot;) end When we reload our Welcome Page, we see that we&#39;ve been redirected to /redirect_test which has rendered the text Redirect!. It works! If we care to, we can open up our developer tools, click on the network tab, and visit our root route again. We see two main requests for this page - a get to / with a status of 302, and a get to /redirect_test with a status of 200. Notice that the redirect function takes conn as well as a string representing a relative path within our application. It can also take conn and a string representing a fully-qualified url. def index(conn, _params) do redirect(conn, external: &quot;https://elixir-lang.org/&quot;) end We can also make use of the path helpers we learned about in the Routing Guide. defmodule HelloWeb.PageController do use HelloWeb, :controller def index(conn, _params) do redirect(conn, to: Routes.redirect_test_path(conn, :redirect_test)) end end Note that we can&#39;t use the url helper here because redirect/2 using the atom :to, expects a path. For example, the following will fail. def index(conn, _params) do redirect(conn, to: Routes.redirect_test_url(conn, :redirect_test)) end If we want to use the url helper to pass a full url to redirect/2, we must use the atom :external. Note that the url does not have to be truly external to our application to use :external, as we see in this example. def index(conn, _params) do redirect(conn, external: Routes.redirect_test_url(conn, :redirect_test)) end"},{"ref":"controllers.html#action-fallback","title":"Controllers - Action Fallback","type":"extras","doc":"Action Fallback allows us to centralize error handling code in plugs which are called when a controller action fails to return a Plug.Conn.t. These plugs receive both the conn which was originally passed to the controller action along with the return value of the action. Let&#39;s say we have a show action which uses with to fetch a blog post and then authorize the current user to view that blog post. In this example we might expect Blog.fetch_post/1 to return {:error, :not_found} if the post is not found and Authorizer.authorize/3 might return {:error, :unauthorized} if the user is unauthorized. We could render the error views for these non-happy-paths directly. defmodule HelloWeb.MyController do use Phoenix.Controller alias Hello.{Authorizer, Blog} alias HelloWeb.ErrorView def show(conn, %{&quot;id&quot; =&gt; id}, current_user) do with {:ok, post} &lt;- Blog.fetch_post(id), :ok &lt;- Authorizer.authorize(current_user, :view, post) do render(conn, &quot;show.json&quot;, post: post) else {:error, :not_found} -&gt; conn |&gt; put_status(:not_found) |&gt; put_view(ErrorView) |&gt; render(:&quot;404&quot;) {:error, :unauthorized} -&gt; conn |&gt; put_status(403) |&gt; put_view(ErrorView) |&gt; render(:&quot;403&quot;) end end end Many times - especially when implementing controllers for an API - error handling in the controllers like this results in a lot of repetition. Instead we can define a plug which knows how to handle these error cases. defmodule HelloWeb.MyFallbackController do use Phoenix.Controller alias HelloWeb.ErrorView def call(conn, {:error, :not_found}) do conn |&gt; put_status(:not_found) |&gt; put_view(ErrorView) |&gt; render(:&quot;404&quot;) end def call(conn, {:error, :unauthorized}) do conn |&gt; put_status(403) |&gt; put_view(ErrorView) |&gt; render(:&quot;403&quot;) end end Then we can reference that plug using action_fallback and simply remove the else block from our with. Our plug will receive the original conn as well as the result of the action and respond appropriately. defmodule HelloWeb.MyController do use Phoenix.Controller alias Hello.{Authorizer, Blog} action_fallback HelloWeb.MyFallbackController def show(conn, %{&quot;id&quot; =&gt; id}, current_user) do with {:ok, post} &lt;- Blog.fetch_post(id), :ok &lt;- Authorizer.authorize(current_user, :view, post) do render(conn, &quot;show.json&quot;, post: post) end end end"},{"ref":"controllers.html#halting-the-plug-pipeline","title":"Controllers - Halting the Plug Pipeline","type":"extras","doc":"As we mentioned - Controllers are plugs.... specifically plugs which are called toward the end of the plug pipeline. At any step of the pipeline we might have cause to stop processing - typically because we&#39;ve redirected or rendered a response. Plug.Conn.t has a :halted key - setting it to true will cause downstream plugs to be skipped. We can do that easily using Plug.Conn.halt/1. Consider a HelloWeb.PostFinder plug. On call, if we find a post related to a given id then we add it to conn.assigns; and if we don&#39;t find the post we respond with a 404 page. defmodule HelloWeb.PostFinder do use Plug import Plug.Conn alias Hello.Blog def init(opts), do: opts def call(conn, _) do case Blog.get_post(conn.params[&quot;id&quot;]) do {:ok, post} -&gt; assign(conn, :post, post) {:error, :notfound} -&gt; conn |&gt; send_resp(404, &quot;Not found&quot;) end end end If we call this plug as part of the plug pipeline any downstream plugs will still be processed. If we want to prevent downstream plugs from being processed in the event of the 404 response we can simply call Plug.Conn.halt/1. ... case Blog.get_post(conn.params[&quot;id&quot;]) do {:ok, post} -&gt; assign(conn, :post, post) {:error, :notfound} -&gt; conn |&gt; send_resp(404, &quot;Not found&quot;) |&gt; halt() end It&#39;s important to note that halt/1 simply sets the :halted key on Plug.Conn.t to true. This is enough to prevent downstream plugs from being invoked but it will not stop the execution of code locally. As such conn |&gt; send_resp(404, &quot;Not found&quot;) |&gt; halt() ... is functionally equivalent to... conn |&gt; halt() |&gt; send_resp(404, &quot;Not found&quot;) It&#39;s also important to note that halting will only stop the plug pipeline from continuing. Function plugs will still execute unless their implementation checks for the :halted value. def post_authorization_plug(%{halted: true} = conn, _), do: conn def post_authorization_plug(conn, _) do ... end"},{"ref":"views.html","title":"Views","type":"extras","doc":"Views Phoenix views have two main jobs. First and foremost, they render templates (this includes layouts). The core function involved in rendering, render/3, is defined in Phoenix itself in the Phoenix.View module. Views also provide functions which take raw data and make it easier for templates to consume. If you are familiar with decorators or the facade pattern, this is similar."},{"ref":"views.html#rendering-templates","title":"Views - Rendering Templates","type":"extras","doc":"Phoenix assumes a strong naming convention from controllers to views to the templates they render. The PageController requires a PageView to render templates in the lib/hello_web/templates/page directory. If we want to, we can change the directory Phoenix considers to be the template root. Phoenix provides a view/0 function in the HelloWeb module defined in lib/hello_web.ex. The first line of view/0 allows us to change our root directory by changing the value assigned to the :root key. A newly generated Phoenix application has three view modules - ErrorView, LayoutView, and PageView - which are all in the, lib/hello_web/views directory. Let&#39;s take a quick look at the LayoutView. defmodule HelloWeb.LayoutView do use HelloWeb, :view end That&#39;s simple enough. There&#39;s only one line, use HelloWeb, :view. This line calls the view/0 function we just saw above. Besides allowing us to change our template root, view/0 exercises the __using__ macro in the Phoenix.View module. It also handles any module imports or aliases our application&#39;s view modules might need. At the top of this guide, we mentioned that views are a place to put functions for use in our templates. Let&#39;s experiment with that a little bit. Let&#39;s open up our application layout template, lib/hello_web/templates/layout/app.html.eex, and change this line, &lt;title&gt;Hello · Phoenix Framework&lt;/title&gt; to call a title/0 function, like this. &lt;title&gt;&lt;%= title() %&gt;&lt;/title&gt; Now let&#39;s add a title/0 function to our LayoutView. defmodule HelloWeb.LayoutView do use HelloWeb, :view def title do &quot;Awesome New Title!&quot; end end When we reload the Welcome to Phoenix page, we should see our new title. The &lt;%= and %&gt; are from the Elixir EEx project. They enclose executable Elixir code within a template. The = tells EEx to print the result. If the = is not there, EEx will still execute the code, but there will be no output. In our example, we are calling the title/0 function from our LayoutView and printing the output into the title tag. Note that we didn&#39;t need to fully qualify title/0 with HelloWeb.LayoutView because our LayoutView actually does the rendering. In fact, &quot;templates&quot; in Phoenix are really just function definitions on their view module. You can try this out by temporarily deleting your lib/hello_web/templates/page/index.html.eex file and adding this function clause to your PageView module in lib/hello_web/views/page_view.ex. defmodule HelloWeb.PageView do use HelloWeb, :view def render(&quot;index.html&quot;, assigns) do &quot;rendering with assigns \#{inspect Map.keys(assigns)}&quot; end end Now if you fire up the server with mix phx.server and visit http://localhost:4000, you should see the following text below your layout header instead of the main template page: rendering with assigns [:conn, :view_module, :view_template] Pretty neat, right? At compile-time, Phoenix precompiles all *.html.eex templates and turns them into render/2 function clauses on their respective view modules. At runtime, all templates are already loaded in memory. There&#39;s no disk reads, complex file caching, or template engine computation involved. This is also why we were able to define functions like title/0 in our LayoutView and they were immediately available inside the layout&#39;s app.html.eex – the call to title/0 was just a local function call! When we use HelloWeb, :view, we get other conveniences as well. Since view/0 aliases HelloWeb.Router.Helpers as Routes (look in lib/hello_web.ex), we can simply call these helpers by using Routes.*_path in templates. Let&#39;s see how that works by changing the template for our Welcome to Phoenix page. Let&#39;s open up the lib/hello_web/templates/page/index.html.eex and locate this stanza. &lt;section class=&quot;phx-hero&quot;&gt; &lt;h1&gt;&lt;%= gettext &quot;Welcome to %{name}!&quot;, name: &quot;Phoenix&quot; %&gt;&lt;/h1&gt; &lt;p&gt;A productive web framework that&lt;br/&gt;does not compromise speed or maintainability.&lt;/p&gt; &lt;/section&gt; Then let&#39;s add a line with a link back to the same page. (The objective is to see how path helpers respond in a template, not to add any functionality.) &lt;section class=&quot;phx-hero&quot;&gt; &lt;h1&gt;&lt;%= gettext &quot;Welcome to %{name}!&quot;, name: &quot;Phoenix&quot; %&gt;&lt;/h1&gt; &lt;p&gt;A productive web framework that&lt;br/&gt;does not compromise speed or maintainability.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;&lt;%= Routes.page_path(@conn, :index) %&gt;&quot;&gt;Link back to this page&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; Now we can reload the page and view source to see what we have. &lt;a href=&quot;/&quot;&gt;Link back to this page&lt;/a&gt; Great, Routes.page_path/2 evaluated to / as we would expect, we just had to use the alias set in Phoenix.View. If you happen to need access to the path helpers outside views, controllers or templates, you can either call them by the full qualified name, e.g. HelloWeb.Router.Helpers.page_path(@conn, :index) or alias it yourself in the calling module, by defining alias HelloWeb.Router.Helpers, as: Routes in the module you want to use, and then calling, e.g., Routes.page_path(@conn, :index). More About Views You might be wondering how views are able to work so closely with templates. The Phoenix.View module gains access to template behavior via the use Phoenix.Template line in its __using__/1 macro. Phoenix.Template provides many convenience methods for working with templates - finding them, extracting their names and paths, and much more. Let&#39;s experiment a little with one of the generated views Phoenix provides us, lib/hello_web/views/page_view.ex. We&#39;ll add a message/0 function to it, like this. defmodule HelloWeb.PageView do use HelloWeb, :view def message do &quot;Hello from the view!&quot; end end Now let&#39;s create a new template to play around with, lib/hello_web/templates/page/test.html.eex. This is the message: &lt;%= message() %&gt; This doesn&#39;t correspond to any action in our controller, but we&#39;ll exercise it in an iex session. At the root of our project, we can run iex -S mix, and then explicitly render our template. iex(1)&gt; Phoenix.View.render(HelloWeb.PageView, &quot;test.html&quot;, %{}) {:safe, [[&quot;&quot; | &quot;This is the message: &quot;] | &quot;Hello from the view!&quot;]} As we can see, we&#39;re calling render/3 with the individual view responsible for our test template, the name of our test template, and an empty map representing any data we might have wanted to pass in. The return value is a tuple beginning with the atom :safe and the resultant io list of the interpolated template. &quot;Safe&quot; here means that Phoenix has escaped the contents of our rendered template. Phoenix defines its own Phoenix.HTML.Safe protocol with implementations for atoms, bitstrings, lists, integers, floats, and tuples to handle this escaping for us as our templates are rendered into strings. What happens if we assign some key value pairs to the third argument of render/3? In order to find out, we need to change the template just a bit. I came from assigns: &lt;%= @message %&gt; This is the message: &lt;%= message() %&gt; Note the @ in the top line. Now if we change our function call, we see a different rendering after recompiling PageView module. iex(2)&gt; r HelloWeb.PageView warning: redefining module HelloWeb.PageView (current version loaded from _build/dev/lib/hello/ebin/Elixir.HelloWeb.PageView.beam) lib/hello_web/views/page_view.ex:1 {:reloaded, HelloWeb.PageView, [HelloWeb.PageView]} iex(3)&gt; Phoenix.View.render(HelloWeb.PageView, &quot;test.html&quot;, message: &quot;Assigns has an @.&quot;) {:safe, [[[[&quot;&quot; | &quot;I came from assigns: &quot;] | &quot;Assigns has an @.&quot;] | &quot;\\nThis is the message: &quot;] | &quot;Hello from the view!&quot;]} Let&#39;s test out the HTML escaping, just for fun. iex(4)&gt; Phoenix.View.render(HelloWeb.PageView, &quot;test.html&quot;, message: &quot;&lt;script&gt;badThings();&lt;/script&gt;&quot;) {:safe, [[[[&quot;&quot; | &quot;I came from assigns: &quot;] | &quot;&amp;lt;script&amp;gt;badThings();&amp;lt;/script&amp;gt;&quot;] | &quot;\\nThis is the message: &quot;] | &quot;Hello from the view!&quot;]} If we need only the rendered string, without the whole tuple, we can use the render_to_iodata/3. iex(5)&gt; Phoenix.View.render_to_iodata(HelloWeb.PageView, &quot;test.html&quot;, message: &quot;Assigns has an @.&quot;) [[[[&quot;&quot; | &quot;I came from assigns: &quot;] | &quot;Assigns has an @.&quot;] | &quot;\\nThis is the message: &quot;] | &quot;Hello from the view!&quot;] A Word About Layouts Layouts are just templates. They have a view, just like other templates. In a newly generated app, this is lib/hello_web/views/layout_view.ex. You may be wondering how the string resulting from a rendered view ends up inside a layout. That&#39;s a great question! If we look at lib/hello_web/templates/layout/app.html.eex, just about in the middle of the &lt;body&gt;, we will see this. &lt;%= render(@view_module, @view_template, assigns) %&gt; This is where the view module and its template from the controller are rendered to a string and placed in the layout."},{"ref":"views.html#the-errorview","title":"Views - The ErrorView","type":"extras","doc":"Phoenix has a view called the ErrorView which lives in lib/hello_web/views/error_view.ex. The purpose of the ErrorView is to handle two of the most common errors - 404 not found and 500 internal error - in a general way, from one centralized location. Let&#39;s see what it looks like. defmodule HelloWeb.ErrorView do use HelloWeb, :view def render(&quot;404.html&quot;, _assigns) do &quot;Page not found&quot; end def render(&quot;500.html&quot;, _assigns) do &quot;Server internal error&quot; end end Before we dive into this, let&#39;s see what the rendered 404 not found message looks like in a browser. In the development environment, Phoenix will debug errors by default, showing us a very informative debugging page. What we want here, however, is to see what page the application would serve in production. In order to do that we need to set debug_errors: false in config/dev.exs. use Mix.Config config :hello, HelloWeb.Endpoint, http: [port: 4000], debug_errors: false, code_reloader: true, . . . After modifying our config file, we need to restart our server in order for this change to take effect. After restarting the server, let&#39;s go to http://localhost:4000/such/a/wrong/path for a running local application and see what we get. Ok, that&#39;s not very exciting. We get the bare string &quot;Page not found&quot;, displayed without any markup or styling. Let&#39;s see if we can use what we already know about views to make this a more interesting error page. The first question is, where does that error string come from? The answer is right in the ErrorView. def render(&quot;404.html&quot;, _assigns) do &quot;Page not found&quot; end Great, so we have a render/2 function that takes a template and an assigns map, which we ignore. Where is this render/2 function being called from? The answer is the render/5 function defined in the Phoenix.Endpoint.RenderErrors module. The whole purpose of this module is to catch errors and render them with a view, in our case, the HelloWeb.ErrorView. Now that we understand how we got here, let&#39;s make a better error page. Phoenix generates an ErrorView for us, but it doesn&#39;t give us a lib/hello_web/templates/error directory. Let&#39;s create one now. Inside our new directory, let&#39;s add a template, 404.html.eex and give it some markup - a mixture of our application layout and a new div with our message to the user. &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt; &lt;meta name=&quot;description&quot; content=&quot;&quot;&gt; &lt;meta name=&quot;author&quot; content=&quot;&quot;&gt; &lt;title&gt;Welcome to Phoenix!&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;/css/app.css&quot;&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;header&quot;&gt; &lt;ul class=&quot;nav nav-pills pull-right&quot;&gt; &lt;li&gt;&lt;a href=&quot;https://hexdocs.pm/phoenix/overview.html&quot;&gt;Get Started&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;span class=&quot;logo&quot;&gt;&lt;/span&gt; &lt;/div&gt; &lt;div class=&quot;phx-hero&quot;&gt; &lt;p&gt;Sorry, the page you are looking for does not exist.&lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;footer&quot;&gt; &lt;p&gt;&lt;a href=&quot;http://phoenixframework.org&quot;&gt;phoenixframework.org&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- /container --&gt; &lt;script src=&quot;/js/app.js&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; Now we can use the render/2 function we saw above when we were experimenting with rendering in the iex session. Since we know that Phoenix will precompile the 404.html.eex template as a render(&quot;404.html&quot;, assigns) function clause, we can delete the clause from our ErrorView. - def render(&quot;404.html&quot;, _assigns) do - &quot;Page not found&quot; - end When we go back to http://localhost:4000/such/a/wrong/path, we should see a much nicer error page. It is worth noting that we did not render our 404.html.eex template through our application layout, even though we want our error page to have the look and feel of the rest of our site. The main reason is that it&#39;s easy to run into edge case issues while handling errors globally. If we want to minimize duplication between our application layout and our 404.html.eex template, we can implement shared templates for our header and footer. Please see the Template Guide for more information. Of course, we can do these same steps with the def render(&quot;500.html&quot;, _assigns) do clause in our ErrorView as well. We can also use the assigns map passed into any render/2 clause in the ErrorView, instead of discarding it, in order to display more information in our templates."},{"ref":"views.html#rendering-json","title":"Views - Rendering JSON","type":"extras","doc":"The view&#39;s job is not only to render HTML templates. Views are about data presentation. Given a bag of data, the view&#39;s purpose is to present that in a meaningful way given some format, be it HTML, JSON, CSV, or others. Many web apps today return JSON to remote clients, and Phoenix views are great for JSON rendering. Phoenix uses Jason to encode Maps to JSON, so all we need to do in our views is format the data we&#39;d like to respond with as a Map, and Phoenix will do the rest. It is possible to respond with JSON back directly from the controller and skip the View. However, if we think about a controller as having the responsibilities of receiving a request and fetching data to be sent back, data manipulation and formatting don&#39;t fall under those responsibilities. A view gives us a module responsible for formatting and manipulating the data. Let&#39;s take our PageController, and see what it might look like when we respond with some static page maps as JSON, instead of HTML. defmodule HelloWeb.PageController do use HelloWeb, :controller def show(conn, _params) do page = %{title: &quot;foo&quot;} render(conn, &quot;show.json&quot;, page: page) end def index(conn, _params) do pages = [%{title: &quot;foo&quot;}, %{title: &quot;bar&quot;}] render(conn, &quot;index.json&quot;, pages: pages) end end Here, we have our show/2 and index/2 actions returning static page data. Instead of passing in &quot;show.html&quot; to render/3 as the template name, we pass &quot;show.json&quot;. This way, we can have views that are responsible for rendering HTML as well as JSON by pattern matching on different file types. defmodule HelloWeb.PageView do use HelloWeb, :view def render(&quot;index.json&quot;, %{pages: pages}) do %{data: render_many(pages, HelloWeb.PageView, &quot;page.json&quot;)} end def render(&quot;show.json&quot;, %{page: page}) do %{data: render_one(page, HelloWeb.PageView, &quot;page.json&quot;)} end def render(&quot;page.json&quot;, %{page: page}) do %{title: page.title} end end In the view we see our render/2 function pattern matching on &quot;index.json&quot;, &quot;show.json&quot;, and &quot;page.json&quot;. In our controller show/2 function, render(conn, &quot;show.json&quot;, page: page) will pattern match on the matching name and extension in the view&#39;s render/2 functions. In other words, render(conn, &quot;index.json&quot;, pages: pages) will call render(&quot;index.json&quot;, %{pages: pages}). The render_many/3 function takes the data we want to respond with (pages), a View, and a string to pattern match on the render/2 function defined on View. It will map over each item in pages, and pass the item to the render/2 function in View matching the file string. render_one/3 follows, the same signature, ultimately using the render/2 matching page.json to specify what each page looks like. The render/2 matching &quot;index.json&quot; will respond with JSON as you would expect: { &quot;data&quot;: [ { &quot;title&quot;: &quot;foo&quot; }, { &quot;title&quot;: &quot;bar&quot; }, ] } And the render/2 matching &quot;show.json&quot;: { &quot;data&quot;: { &quot;title&quot;: &quot;foo&quot; } } It&#39;s useful to build our views like this so they can be composable. Imagine a situation where our Page has a has_many relationship with Author, and depending on the request, we may want to send back author data with the page. We can easily accomplish this with a new render/2: defmodule HelloWeb.PageView do use HelloWeb, :view alias HelloWeb.AuthorView def render(&quot;page_with_authors.json&quot;, %{page: page}) do %{title: page.title, authors: render_many(page.authors, AuthorView, &quot;author.json&quot;)} end def render(&quot;page.json&quot;, %{page: page}) do %{title: page.title} end end The name used in assigns is determined from the view. For example the PageView will use %{page: page} and the AuthorView will use %{author: author}. This can be overridden with the as option. Let&#39;s assume that the author view uses %{writer: writer} instead of %{author: author}: def render(&quot;page_with_authors.json&quot;, %{page: page}) do %{title: page.title, authors: render_many(page.authors, AuthorView, &quot;author.json&quot;, as: :writer)} end"},{"ref":"templates.html","title":"Templates","type":"extras","doc":"Templates Templates are what they sound like they should be: files into which we pass data to form complete HTTP responses. For a web application these responses would typically be full HTML documents. For an API, they would most often be JSON or possibly XML. The majority of the code in template files is often markup, but there will also be sections of Elixir code for Phoenix to compile and evaluate. The fact that Phoenix templates are pre-compiled makes them extremely fast. EEx is the default template system in Phoenix, and it is quite similar to ERB in Ruby. It is actually part of Elixir itself, and Phoenix uses EEx templates to create files like the router and the main application view while generating a new application. As we learned in the View Guide, by default, templates live in the lib/hello_web/templates directory, organized into directories named after a view. Each directory has its own view module to render the templates in it. Examples We&#39;ve already seen several ways in which templates are used, notably in the Adding Pages Guide and the Views Guide. We may cover some of the same territory here, but we will certainly add some new information. hello_web.ex Phoenix generates a lib/hello_web.ex file that serves as place to group common imports and aliases. All declarations here within the view block apply to all your templates. Let&#39;s make some additions to our application so we can experiment a little. First, let&#39;s define a new route in lib/hello_web/router.ex. defmodule HelloWeb.Router do ... scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index get &quot;/test&quot;, PageController, :test end # Other scopes may use custom stacks. # scope &quot;/api&quot;, Hello do # pipe_through :api # end end Now, let&#39;s define the controller action we specified in the route. We&#39;ll add a test/2 action in the lib/hello_web/controllers/page_controller.ex file. defmodule HelloWeb.PageController do ... def test(conn, _params) do render(conn, &quot;test.html&quot;) end end We&#39;re going to create a function that tells us which controller and action are handling our request. To do that, we need to import the action_name/1 and controller_module/1 functions from Phoenix.Controller in lib/hello_web.ex. def view do quote do use Phoenix.View, root: &quot;lib/hello_web/templates&quot;, namespace: HelloWeb # Import convenience functions from controllers import Phoenix.Controller, only: [get_flash: 1, get_flash: 2, view_module: 1, action_name: 1, controller_module: 1] ... end end Next, let&#39;s define a handler_info/1 function at the bottom of the lib/hello_web/views/page_view.ex which makes use of the controller_module/1 and action_name/1 functions we just imported. We&#39;ll also define a connection_keys/1 function that we&#39;ll use in a moment. defmodule HelloWeb.PageView do use HelloWeb, :view def handler_info(conn) do &quot;Request Handled By: \#{controller_module(conn)}.\#{action_name(conn)}&quot; end def connection_keys(conn) do conn |&gt; Map.from_struct() |&gt; Map.keys() end end We have a route. We created a new controller action. We have made modifications to the main application view. Now all we need is a new template to display the string we get from handler_info/1. Let&#39;s create a new one at lib/hello_web/templates/page/test.html.eex. &lt;div class=&quot;phx-hero&quot;&gt; &lt;p&gt;&lt;%= handler_info(@conn) %&gt;&lt;/p&gt; &lt;/div&gt; Notice that @conn is available to us in the template for free via the assigns map. If we visit localhost:4000/test, we will see that our page is brought to us by Elixir.HelloWeb.PageController.test. We can define functions in any individual view in lib/hello_web/views. Functions defined in an individual view will only be available to templates which that view renders. For example, functions like our handler_info above, will only be available to templates in lib/hello_web/templates/page. Displaying Lists So far, we&#39;ve only displayed singular values in our templates - strings here, and integers in other guides. How would we approach displaying all the elements of a list? The answer is that we can use Elixir&#39;s list comprehensions. Now that we have a function, visible to our template, that returns a list of keys in the conn struct, all we need to do is modify our lib/hello_web/templates/page/test.html.eex template a bit to display them. We can add a header and a list comprehension like this. &lt;div class=&quot;phx-hero&quot;&gt; &lt;p&gt;&lt;%= handler_info(@conn) %&gt;&lt;/p&gt; &lt;h3&gt;Keys for the conn Struct&lt;/h3&gt; &lt;%= for key &lt;- connection_keys(@conn) do %&gt; &lt;p&gt;&lt;%= key %&gt;&lt;/p&gt; &lt;% end %&gt; &lt;/div&gt; We use the list of keys returned by the connection_keys function as the source list to iterate over. Note that we need the = in both &lt;%= - one for the top line of the list comprehension and the other to display the key. Without them, nothing would actually be displayed. When we visit localhost:4000/test again, we see all the keys displayed. Render templates within templates In our list comprehension example above, the part that actually displays the values is quite simple. &lt;p&gt;&lt;%= key %&gt;&lt;/p&gt; We are probably fine with leaving this in place. Quite often, however, this display code is somewhat more complex, and putting it in the middle of a list comprehension makes our templates harder to read. The simple solution is to use another template! Templates are just function calls, so like regular code, composing your greater template by small, purpose-built functions can lead to clearer design. This is simply a continuation of the rendering chain we have already seen. Layouts are templates into which regular templates are rendered. Regular templates may have other templates rendered into them. Let&#39;s turn this display snippet into its own template. Let&#39;s create a new template file at lib/hello_web/templates/page/key.html.eex, like this. &lt;p&gt;&lt;%= @key %&gt;&lt;/p&gt; We need to change key to @key here because this is a new template, not part of a list comprehension. The way we pass data into a template is by the assigns map, and the way we get the values out of the assigns map is by referencing the keys with a preceding @. @ is actually a macro that translates @key to Map.get(assigns, :key). Now that we have a template, we simply render it within our list comprehension in the test.html.eex template. &lt;div class=&quot;phx-hero&quot;&gt; &lt;p&gt;&lt;%= handler_info(@conn) %&gt;&lt;/p&gt; &lt;h3&gt;Keys for the conn Struct&lt;/h3&gt; &lt;%= for key &lt;- connection_keys(@conn) do %&gt; &lt;%= render(&quot;key.html&quot;, key: key) %&gt; &lt;% end %&gt; &lt;/div&gt; Let&#39;s take a look at localhost:4000/test again. The page should look exactly as it did before. Shared Templates Across Views Often, we find that small pieces of data need to be rendered the same way in different parts of the application. It&#39;s a good practice to move these templates into their own shared directory to indicate that they ought to be available anywhere in the app. Let&#39;s move our template into a shared view. key.html.eex is currently rendered by the HelloWeb.PageView module, but we use a render call which assumes that the current schema is what we want to render with. We could make that explicit, and re-write it like this: &lt;div class=&quot;phx-hero&quot;&gt; ... &lt;%= for key &lt;- connection_keys(@conn) do %&gt; &lt;%= render(HelloWeb.PageView, &quot;key.html&quot;, key: key) %&gt; &lt;% end %&gt; &lt;/div&gt; Since we want this to live in a new lib/hello_web/templates/shared directory, we need a new individual view to render templates in that directory, lib/hello_web/views/shared_view.ex. defmodule HelloWeb.SharedView do use HelloWeb, :view end Now we can move key.html.eex from the lib/hello_web/templates/page directory into the lib/hello_web/templates/shared directory. Once that happens, we can change the render call in lib/hello_web/templates/page/test.html.eex to use the new HelloWeb.SharedView. &lt;%= for key &lt;- connection_keys(@conn) do %&gt; &lt;%= render(HelloWeb.SharedView, &quot;key.html&quot;, key: key) %&gt; &lt;% end %&gt; Going back to localhost:4000/test again. The page should look exactly as it did before."},{"ref":"channels.html","title":"Channels","type":"extras","doc":"Channels Channels are an exciting part of Phoenix that enable soft real-time communication with and between millions of connected clients. Some possible use cases include: Chat rooms and APIs for messaging apps Breaking news, like &quot;a goal was scored&quot; or &quot;an earthquake is coming&quot; Tracking trains, trucks, or race participants on a map Events in multiplayer games Monitoring sensors and controlling lights Notifying a browser that a page&#39;s CSS or JavaScript has changed (this is handy in development) Conceptually, Channels are pretty simple. Clients connect and subscribe to one or more topics, whether that&#39;s public_chat or updates:user1. Any message sent on a topic, whether from the server or from a client, is sent to all clients subscribed to that topic (including the sender, if it&#39;s subscribed), like this: +----------------+ +--Topic X--&gt;| Mobile Client | | +----------------+ +-------------------+ | +----------------+ | | | +----------------+ | Browser Client |--Topic X--&gt;| Phoenix Server(s) |--+--Topic X--&gt;| Desktop Client | +----------------+ | | | +----------------+ +-------------------+ | | +----------------+ +--Topic X--&gt;| IoT Client | +----------------+ Channels can support any kind of client: a browser, native app, smart watch, embedded device, or anything else that can connect to a network. All the client needs is a suitable library; see the Client Libraries section below. Each client library communicates using one of the &quot;transports&quot; that Channels understand. Currently, that&#39;s either Websockets or long polling, but other transports may be added in the future. Unlike stateless HTTP connections, Channels support long-lived connections, each backed by a lightweight BEAM process, working in parallel and maintaining its own state. This architecture scales well; Phoenix Channels can support millions of subscribers with reasonable latency on a single box, passing hundreds of thousands of messages per second. And that capacity can be multiplied by adding more nodes to the cluster."},{"ref":"channels.html#the-moving-parts","title":"Channels - The Moving Parts","type":"extras","doc":"Although Channels are simple to use from a client perspective, there are a number of components involved in routing messages to clients across a cluster of servers. Let&#39;s take a look at them. Overview To start communicating, a client connects to a node (a Phoenix server) using a transport (eg, Websockets or long polling) and joins one or more channels using that single network connection. One channel server process is created per client, per topic. The appropriate socket handler initializes a %Phoenix.Socket for the channel server (possibly after authenticating the client). The channel server then holds onto the %Phoenix.Socket{} and can maintain any state it needs within its socket.assigns. Once the connection is established, each incoming message from a client is routed, based on its topic, to the correct channel server. If the channel server asks to broadcast a message, that message is sent to the local PubSub, which sends it out to any clients connected to the same server and subscribed to that topic. If there are other nodes in the cluster, the local PubSub also forwards the message to their PubSubs, which send it out to their own subscribers. Because only one message has to be sent per additional node, the performance cost of adding nodes is negligible, while each new node supports many more subscribers. The message flow looks something like this: Channel +-------------------------+ +--------+ route | Sending Client, Topic 1 | | Local | +-----------&gt;| Channel.Server |-----&gt;| PubSub |--+ +----------------+ | +-------------------------+ +--------+ | | Sending Client |-Transport--+ | | +----------------+ +-------------------------+ | | | Sending Client, Topic 2 | | | | Channel.Server | | | +-------------------------+ | | | | +-------------------------+ | | +----------------+ | Browser Client, Topic 1 | | | | Browser Client |&lt;-------Transport--------| Channel.Server |&lt;----------+ | +----------------+ +-------------------------+ | | | | +-------------------------+ | +----------------+ | Phone Client, Topic 1 | | | Phone Client |&lt;-------Transport--------| Channel.Server |&lt;-+ | +----------------+ +-------------------------+ | +--------+ | | | Remote | | +-------------------------+ +---| PubSub |&lt;-+ +----------------+ | Watch Client, Topic 1 | | +--------+ | | Watch Client |&lt;-------Transport--------| Channel.Server |&lt;-+ | +----------------+ +-------------------------+ | | | +-------------------------+ +--------+ | +----------------+ | IoT Client, Topic 1 | | Remote | | | IoT Client |&lt;-------Transport--------| Channel.Server |&lt;-----| PubSub |&lt;-+ +----------------+ +-------------------------+ +--------+ Endpoint In your Phoenix app&#39;s Endpoint module, a socket declaration specifies which socket handler will receive connections on a given URL. socket &quot;/socket&quot;, HelloWeb.UserSocket, websocket: true, longpoll: false Phoenix comes with two default transports: websocket and longpoll. You can configure them directly via the socket declaration. Socket Handlers Socket handlers, such as HelloWeb.UserSocket in the example above, are called when Phoenix is setting up a channel connection. Connections to a given URL will all use the same socket handler, based on your endpoint configuration. But that handler can be used for setting up connections on any number of topics. Within the handler, you can authenticate and identify a socket connection and set default socket assigns. Channel Routes Channel routes are defined in socket handlers, such as HelloWeb.UserSocket in the example above. They match on the topic string and dispatch matching requests to the given Channel module. The star character * acts as a wildcard matcher, so in the following example route, requests for room:lobby and room:123 would both be dispatched to the RoomChannel. channel &quot;room:*&quot;, HelloWeb.RoomChannel Channels Channels handle events from clients, so they are similar to Controllers, but there are two key differences. Channel events can go both directions - incoming and outgoing. Channel connections also persist beyond a single request/response cycle. Channels are the highest level abstraction for realtime communication components in Phoenix. Each Channel will implement one or more clauses of each of these four callback functions - join/3, terminate/2, handle_in/3, and handle_out/3. Topics Topics are string identifiers - names that the various layers use in order to make sure messages end up in the right place. As we saw above, topics can use wildcards. This allows for a useful &quot;topic:subtopic&quot; convention. Often, you&#39;ll compose topics using record IDs from your application layer, such as &quot;users:123&quot;. Messages The Phoenix.Socket.Message module defines a struct with the following keys which denotes a valid message. From the Phoenix.Socket.Message docs. topic - The string topic or &quot;topic:subtopic&quot; pair namespace, such as &quot;messages&quot; or &quot;messages:123&quot; event - The string event name, for example &quot;phx_join&quot; payload - The message payload ref - The unique string ref PubSub Typically, we don&#39;t directly use the Phoenix PubSub layer when developing Phoenix applications. Rather, it&#39;s used internally by Phoenix itself. But we may need to configure it. PubSub consists of the Phoenix.PubSub module and a variety of modules for different adapters and their GenServers. These modules contain functions which are the nuts and bolts of organizing Channel communication - subscribing to topics, unsubscribing from topics, and broadcasting messages on a topic. The PubSub system also takes care of getting messages from one node to another, so that it can be sent to all subscribers across the cluster. By default, this is done using Phoenix.PubSub.PG2, which uses native BEAM messaging. If your deployment environment does not support distributed Elixir or direct communication between servers, Phoenix also ships with a Redis Adapter that uses Redis to exchange PubSub data. Please see the Phoenix.PubSub docs for more information. Client Libraries Any networked device can connect to Phoenix Channels as long as it has a client library. The following libraries exist today, and new ones are always welcome. Official Phoenix ships with a JavaScript client that is available when generating a new Phoenix project. The documentation for the JavaScript module is available at https://hexdocs.pm/phoenix/js/; the code is in phoenix.js. 3rd Party Swift (iOS) SwiftPhoenix Java (Android) JavaPhoenixChannels C# PhoenixSharp dn-phoenix Elixir phoenix_gen_socket_client GDScript (Godot Game Engine) [GodotPhoenixChannels)(https://github.com/alfredbaudisch/GodotPhoenixChannels)"},{"ref":"channels.html#tying-it-all-together","title":"Channels - Tying it all together","type":"extras","doc":"Let&#39;s tie all these ideas together by building a simple chat application. After generating a new Phoenix application we&#39;ll see that the endpoint is already set up for us in lib/hello_web/endpoint.ex: defmodule HelloWeb.Endpoint do use Phoenix.Endpoint, otp_app: :hello socket &quot;/socket&quot;, HelloWeb.UserSocket ... end In lib/hello_web/channels/user_socket.ex, the HelloWeb.UserSocket we pointed to in our endpoint has already been created when we generated our application. We need to make sure messages get routed to the correct channel. To do that, we&#39;ll uncomment the &quot;room:*&quot; channel definition: defmodule HelloWeb.UserSocket do use Phoenix.Socket ## Channels channel &quot;room:*&quot;, HelloWeb.RoomChannel ... Now, whenever a client sends a message whose topic starts with &quot;room:&quot;, it will be routed to our RoomChannel. Next, we&#39;ll define a HelloWeb.RoomChannel module to manage our chat room messages. Joining Channels The first priority of your channels is to authorize clients to join a given topic. For authorization, we must implement join/3 in lib/hello_web/channels/room_channel.ex. defmodule HelloWeb.RoomChannel do use Phoenix.Channel def join(&quot;room:lobby&quot;, _message, socket) do {:ok, socket} end def join(&quot;room:&quot; &lt;&gt; _private_room_id, _params, _socket) do {:error, %{reason: &quot;unauthorized&quot;}} end end For our chat app, we&#39;ll allow anyone to join the &quot;room:lobby&quot; topic, but any other room will be considered private and special authorization, say from a database, will be required. (We won&#39;t worry about private chat rooms for this exercise, but feel free to explore after we finish.) To authorize the socket to join a topic, we return {:ok, socket} or {:ok, reply, socket}. To deny access, we return {:error, reply}. More information about authorization with tokens can be found in the Phoenix.Token documentation. With our channel in place, let&#39;s get the client and server talking. Phoenix projects come with webpack by default, unless disabled with the --no-webpack option when you run mix phx.new. The assets/js/socket.js defines a simple client based on the socket implementation that ships with Phoenix. We can use that library to connect to our socket and join our channel, we just need to set our room name to &quot;room:lobby&quot; in that file. // assets/js/socket.js // ... socket.connect() // Now that you are connected, you can join channels with a topic: let channel = socket.channel(&quot;room:lobby&quot;, {}) channel.join() .receive(&quot;ok&quot;, resp =&gt; { console.log(&quot;Joined successfully&quot;, resp) }) .receive(&quot;error&quot;, resp =&gt; { console.log(&quot;Unable to join&quot;, resp) }) export default socket After that, we need to make sure assets/js/socket.js gets imported into our application JavaScript file. To do that, uncomment the last line in assets/js/app.js. // ... import socket from &quot;./socket&quot; Save the file and your browser should auto refresh, thanks to the Phoenix live reloader. If everything worked, we should see &quot;Joined successfully&quot; in the browser&#39;s JavaScript console. Our client and server are now talking over a persistent connection. Now let&#39;s make it useful by enabling chat. In lib/hello_web/templates/page/index.html.eex, we&#39;ll replace the existing code with a container to hold our chat messages, and an input field to send them: &lt;div id=&quot;messages&quot;&gt;&lt;/div&gt; &lt;input id=&quot;chat-input&quot; type=&quot;text&quot;&gt;&lt;/input&gt; Now let&#39;s add a couple of event listeners to assets/js/socket.js: // ... let channel = socket.channel(&quot;room:lobby&quot;, {}) let chatInput = document.querySelector(&quot;#chat-input&quot;) let messagesContainer = document.querySelector(&quot;#messages&quot;) chatInput.addEventListener(&quot;keypress&quot;, event =&gt; { if(event.keyCode === 13){ channel.push(&quot;new_msg&quot;, {body: chatInput.value}) chatInput.value = &quot;&quot; } }) channel.join() .receive(&quot;ok&quot;, resp =&gt; { console.log(&quot;Joined successfully&quot;, resp) }) .receive(&quot;error&quot;, resp =&gt; { console.log(&quot;Unable to join&quot;, resp) }) export default socket All we had to do is detect that enter was pressed and then push an event over the channel with the message body. We named the event &quot;new_msg&quot;. With this in place, let&#39;s handle the other piece of a chat application where we listen for new messages and append them to our messages container. // ... let channel = socket.channel(&quot;room:lobby&quot;, {}) let chatInput = document.querySelector(&quot;#chat-input&quot;) let messagesContainer = document.querySelector(&quot;#messages&quot;) chatInput.addEventListener(&quot;keypress&quot;, event =&gt; { if(event.keyCode === 13){ channel.push(&quot;new_msg&quot;, {body: chatInput.value}) chatInput.value = &quot;&quot; } }) channel.on(&quot;new_msg&quot;, payload =&gt; { let messageItem = document.createElement(&quot;li&quot;) messageItem.innerText = `[${Date()}] ${payload.body}` messagesContainer.appendChild(messageItem) }) channel.join() .receive(&quot;ok&quot;, resp =&gt; { console.log(&quot;Joined successfully&quot;, resp) }) .receive(&quot;error&quot;, resp =&gt; { console.log(&quot;Unable to join&quot;, resp) }) export default socket We listen for the &quot;new_msg&quot; event using channel.on, and then append the message body to the DOM. Now let&#39;s handle the incoming and outgoing events on the server to complete the picture. Incoming Events We handle incoming events with handle_in/3. We can pattern match on the event names, like &quot;new_msg&quot;, and then grab the payload that the client passed over the channel. For our chat application, we simply need to notify all other room:lobby subscribers of the new message with broadcast!/3. defmodule HelloWeb.RoomChannel do use Phoenix.Channel def join(&quot;room:lobby&quot;, _message, socket) do {:ok, socket} end def join(&quot;room:&quot; &lt;&gt; _private_room_id, _params, _socket) do {:error, %{reason: &quot;unauthorized&quot;}} end def handle_in(&quot;new_msg&quot;, %{&quot;body&quot; =&gt; body}, socket) do broadcast!(socket, &quot;new_msg&quot;, %{body: body}) {:noreply, socket} end end broadcast!/3 will notify all joined clients on this socket&#39;s topic and invoke their handle_out/3 callbacks. handle_out/3 isn&#39;t a required callback, but it allows us to customize and filter broadcasts before they reach each client. By default, handle_out/3 is implemented for us and simply pushes the message on to the client, just like our definition. We included it here because hooking into outgoing events allows for powerful message customization and filtering. Let&#39;s see how. Intercepting Outgoing Events We won&#39;t implement this for our application, but imagine our chat app allowed users to ignore messages about new users joining a room. We could implement that behavior like this where we explicitly tell Phoenix which outgoing event we want to intercept and then define a handle_out/3 callback for those events. (Of course, this assumes that we have a Accounts context with an ignoring_user?/2 function, and that we pass a user in via the assigns map). It is important to note that the handle_out/3 callback will be called for every recipient of a message, so more expensive operations like hitting the database should be considered carefully before being included in handle_out/3. intercept [&quot;user_joined&quot;] def handle_out(&quot;user_joined&quot;, msg, socket) do if Accounts.ignoring_user?(socket.assigns[:user], msg.user_id) do {:noreply, socket} else push(socket, &quot;user_joined&quot;, msg) {:noreply, socket} end end That&#39;s all there is to our basic chat app. Fire up multiple browser tabs and you should see your messages being pushed and broadcasted to all windows! Socket Assigns Similar to connection structs, %Plug.Conn{}, it is possible to assign values to a channel socket. Phoenix.Socket.assign/3 is conveniently imported into a channel module as assign/3: socket = assign(socket, :user, msg[&quot;user&quot;]) Sockets store assigned values as a map in socket.assigns. Using Token Authentication When we connect, we&#39;ll often need to authenticate the client. Fortunately, this is a 4-step process with Phoenix.Token. Step 1 - Assign a Token in the Connection Let&#39;s say we have an authentication plug in our app called OurAuth. When OurAuth authenticates a user, it sets a value for the :current_user key in conn.assigns. Since the current_user exists, we can simply assign the user&#39;s token in the connection for use in the layout. We can wrap that behavior up in a private function plug, put_user_token/2. This could also be put in its own module as well. To make this all work, we just add OurAuth and put_user_token/2 to the browser pipeline. pipeline :browser do ... plug OurAuth plug :put_user_token end defp put_user_token(conn, _) do if current_user = conn.assigns[:current_user] do token = Phoenix.Token.sign(conn, &quot;user socket&quot;, current_user.id) assign(conn, :user_token, token) else conn end end Now our conn.assigns contains the current_user and user_token. Step 2 - Pass the Token to the JavaScript Next we need to pass this token to JavaScript. We can do so inside a script tag in web/templates/layout/app.html.eex right above the app.js script, as follows: &lt;script&gt;window.userToken = &quot;&lt;%= assigns[:user_token] %&gt;&quot;;&lt;/script&gt; &lt;script src=&quot;&lt;%= Routes.static_path(@conn, &quot;/js/app.js&quot;) %&gt;&quot;&gt;&lt;/script&gt; Step 3 - Pass the Token to the Socket Constructor and Verify We also need to pass the :params to the socket constructor and verify the user token in the connect/3 function. To do so, edit web/channels/user_socket.ex, as follows: def connect(%{&quot;token&quot; =&gt; token}, socket, _connect_info) do # max_age: 1209600 is equivalent to two weeks in seconds case Phoenix.Token.verify(socket, &quot;user socket&quot;, token, max_age: 1209600) do {:ok, user_id} -&gt; {:ok, assign(socket, :current_user, user_id)} {:error, reason} -&gt; :error end end In our JavaScript, we can use the token set previously when to pass the token when constructing the Socket: let socket = new Socket(&quot;/socket&quot;, {params: {token: window.userToken}}) We used Phoenix.Token.verify/4 to verify the user token provided by the client. Phoenix.Token.verify/4 returns either {:ok, user_id} or {:error, reason}. We can pattern match on that return in a case statement. With a verified token, we set the user&#39;s id as the value to :current_user in the socket. Otherwise, we return :error. Step 4 - Connect to the socket in JavaScript With authentication set up, we can connect to sockets and channels from JavaScript. let socket = new Socket(&quot;/socket&quot;, {params: {token: window.userToken}}) socket.connect() Now that we are connected, we can join channels with a topic: let channel = socket.channel(&quot;topic:subtopic&quot;, {}) channel.join() .receive(&quot;ok&quot;, resp =&gt; { console.log(&quot;Joined successfully&quot;, resp) }) .receive(&quot;error&quot;, resp =&gt; { console.log(&quot;Unable to join&quot;, resp) }) export default socket Note that token authentication is preferable since it&#39;s transport agnostic and well-suited for long running-connections like channels, as opposed to using sessions or authentication approaches. Fault Tolerance and Reliability Guarantees Servers restart, networks split, and clients lose connectivity. In order to design robust systems, we need to understand how Phoenix responds to these events and what guarantees it offers. Handling Reconnection Clients subscribe to topics, and Phoenix stores those subscriptions in an in-memory ETS table. If a channel crashes, the clients will need to reconnect to the topics they had previously subscribed to. Fortunately, the Phoenix JavaScript client knows how to do this. The server will notify all the clients of the crash. This will trigger each client&#39;s Channel.onError callback. The clients will attempt to reconnect to the server using an exponential back off strategy. Once they reconnect, they&#39;ll attempt to rejoin the topics they had previously subscribed to. If they are successful, they&#39;ll start receiving messages from those topics as before. Resending Client Messages Channel clients queue outgoing messages into a PushBuffer, and send them to the server when there is a connection. If no connection is available, the client holds on to the messages until it can establish a new connection. With no connection, the client will hold the messages in memory until it establishes a connection, or until it receives a timeout event. The default timeout is set to 5000 milliseconds. The client won&#39;t persist the messages in the browser&#39;s local storage, so if the browser tab closes, the messages will be gone. Resending Server Messages Phoenix uses an at-most-once strategy when sending messages to clients. If the client is offline and misses the message, Phoenix won&#39;t resend it. Phoenix doesn&#39;t persist messages on the server. If the server restarts, unsent messages will be gone. If our application needs stronger guarantees around message delivery, we&#39;ll need to write that code ourselves. Common approaches involve persisting messages on the server and having clients request missing messages. For an example, see Chris McCord&#39;s Phoenix training: client code and server code. Presence Phoenix ships with a way of handling online users that is built on top of Phoenix.PubSub and Phoenix channels. The usage of presence is covered in the presence guide. Example Application To see an example of the application we just built, checkout the project phoenix_chat_example. You can also see a live demo at http://phoenixchat.herokuapp.com/."},{"ref":"presence.html","title":"Presence","type":"extras","doc":"Presence Phoenix Presence is a feature which allows you to register process information on a topic and replicate it transparently across a cluster. It&#39;s a combination of both a server-side and client-side library which makes it simple to implement. A simple use-case would be showing which users are currently online in an application. Phoenix Presence is special for a number of reasons. It has no single point of failure, no single source of truth, relies entirely on the standard library with no operational dependencies and self heals. This is all handled with a conflict-free replicated data type (CRDT) protocol. To get started with Presence we&#39;ll first need to generate a presence module. We can do this with the mix phx.gen.presence task: $ mix phx.gen.presence * creating lib/hello_web/channels/presence.ex Add your new module to your supervision tree, in lib/hello/application.ex: children = [ ... HelloWeb.Presence, ] You&#39;re all set! See the Phoenix.Presence docs for more details: http://hexdocs.pm/phoenix/Phoenix.Presence.html If we open up the lib/hello_web/channels/presence.ex file, we will see the following line: use Phoenix.Presence, otp_app: :hello, pubsub_server: Hello.PubSub This sets up the module for presence, defining the functions we require for tracking presences. As mentioned in the generator task, we should add this module to our supervision tree in application.ex: children = [ ... HelloWeb.Presence, ] Next we will create a channel that Presence can communicate on. For this example we will create a RoomChannel (see the channels guide for more details on this): $ mix phx.gen.channel Room * creating lib/hello_web/channels/room_channel.ex * creating test/hello_web/channels/room_channel_test.exs Add the channel to your `lib/hello_web/channels/user_socket.ex` handler, for example: channel &quot;room:lobby&quot;, HelloWeb.RoomChannel and register it in lib/hello_web/channels/user_socket.ex: defmodule HelloWeb.UserSocket do use Phoenix.Socket channel &quot;room:lobby&quot;, HelloWeb.RoomChannel end We also need to change our connect function to take a user_id from the params and assign it on the socket. In production you may want to use Phoenix.Token if you have real users that are authenticated. def connect(params, socket, _connect_info) do {:ok, assign(socket, :user_id, params[&quot;user_id&quot;])} end Next, we will create the channel that we&#39;ll communicate presence over. After a user joins we can push the list of presences down the channel and then track the connection. We can also provide a map of additional information to track. Note that we provide the user_id from the connection in order to uniquely identify the client. You can use whatever identifier you like, but you&#39;ll see how this is provided to the socket in the client-side example below. To learn more about channels, read the channel documentation in the guide. defmodule HelloWeb.RoomChannel do use Phoenix.Channel alias HelloWeb.Presence def join(&quot;room:lobby&quot;, _params, socket) do send(self(), :after_join) {:ok, socket} end def handle_info(:after_join, socket) do push(socket, &quot;presence_state&quot;, Presence.list(socket)) {:ok, _} = Presence.track(socket, socket.assigns.user_id, %{ online_at: inspect(System.system_time(:second)) }) {:noreply, socket} end end Finally we can use the client-side Presence library included in phoenix.js to manage the state and presence diffs that come down the socket. It listens for the &quot;presence_state&quot; and &quot;presence_diff&quot; events and provides a simple callback for you to handle the events as they happen, with the onSync callback. The onSync callback allows you to easily react to presence state changes, which most often results in re-rendering an updated list of active users. You can use the list method is to format and return each individual presence based on the needs of your application. To iterate users, we use the presences.list() function which accepts a callback. The callback will be called for each presence item with 2 arguments, the presence id and a list of metas (one for each presence for that presence id). We use this to display the users and the number of devices they are online with. We can see presence working by adding the following to assets/js/app.js: import {Socket, Presence} from &quot;phoenix&quot; let socket = new Socket(&quot;/socket&quot;, { params: {user_id: window.location.search.split(&quot;=&quot;)[1]} }) let channel = socket.channel(&quot;room:lobby&quot;, {}) let presence = new Presence(channel) function renderOnlineUsers(presence) { let response = &quot;&quot; presence.list((id, {metas: [first, ...rest]}) =&gt; { let count = rest.length + 1 response += `&lt;br&gt;${id} (count: ${count})&lt;/br&gt;` }) document.querySelector(&quot;main[role=main]&quot;).innerHTML = response } socket.connect() presence.onSync(() =&gt; renderOnlineUsers(presence)) channel.join() We can ensure this is working by opening 3 browser tabs. If we navigate to http://localhost:4000/?name=Alice on two browser tabs and http://localhost:4000/?name=Bob then we should see: Alice (count: 2) Bob (count: 1) If we close one of the Alice tabs, then the count should decrease to 1. If we close another tab, the user should disappear from the list entirely."},{"ref":"ecto.html","title":"Ecto","type":"extras","doc":"Ecto Most web applications today need some form of data validation and persistence. In the Elixir ecosystem, we have Ecto to enable this. Before we jump into building database-backed web features, we&#39;re going to focus on the finer details of Ecto to give a solid base to build our web features on top of. Let&#39;s get started! Ecto has out of the box support for the following databases: PostgreSQL (via postgrex) MySQL (via myxql) Newly generated Phoenix projects include Ecto with the PostgreSQL adapter by default (you can pass the --no-ecto flag to exclude this). For a thorough, general guide for Ecto, check out the Ecto getting started guide. For an overview of all Ecto specific mix tasks for Phoenix, see the mix tasks guide. This guide assumes that we have generated our new application with Ecto integration and that we will be using PostgreSQL. For instructions on switching to MySQL, please see the Using MySQL section. The default Postgres configuration has a superuser account with username &#39;postgres&#39; and the password &#39;postgres&#39;. If you take a look at the file config/dev.exs, you&#39;ll see that Phoenix works off this assumption. If you don&#39;t have this account already setup on your machine, you can connect to your postgres instance by typing psql and then entering the following commands: CREATE USER postgres; ALTER USER postgres PASSWORD &#39;postgres&#39;; ALTER USER postgres WITH SUPERUSER; \\q Now that we have Ecto and Postgres installed and configured, the easiest way to use Ecto is to generate an Ecto schema through the phx.gen.schema task. Ecto schemas are a way for us to specify how Elixir data types map to and from external sources, such as database tables. Let&#39;s generate a User schema with name, email, bio, and number_of_pets fields. $ mix phx.gen.schema User users name:string email:string \\ bio:string number_of_pets:integer * creating ./lib/hello/user.ex * creating priv/repo/migrations/20170523151118_create_users.exs Remember to update your repository by running migrations: $ mix ecto.migrate A couple of files were generated with this task. First, we have a user.ex file, containing our Ecto schema with our schema definition of the fields we passed to the task. Next, a migration file was generated inside priv/repo/migrations which will create our database table that our schema maps to. With our files in place, let&#39;s follow the instructions and run our migration. If the repo hasn&#39;t been created yet, run the mix ecto.create task. Next we can run: $ mix ecto.migrate Compiling 1 file (.ex) Generated hello app [info] == Running Hello.Repo.Migrations.CreateUsers.change/0 forward [info] create table users [info] == Migrated in 0.0s Mix assumes that we are in the development environment unless we tell it otherwise with MIX_ENV=another_environment mix some_task. Our Ecto task will get its environment from Mix, and that&#39;s how we get the correct suffix to our database name. If we log in to our database server, and connect to our hello_dev database, we should see our users table. Ecto assumes that we want an integer column called id as our primary key, so we should see a sequence generated for that as well. $ psql -U postgres Type &quot;help&quot; for help. postgres=# \\connect hello_dev You are now connected to database &quot;hello_dev&quot; as user &quot;postgres&quot;. hello_dev=# \\d List of relations Schema | Name | Type | Owner --------+-------------------+----------+---------- public | schema_migrations | table | postgres public | users | table | postgres public | users_id_seq | sequence | postgres (3 rows) hello_dev=# \\q If we take a look at the migration generated by phx.gen.schema in priv/repo/migrations, we&#39;ll see that it will add the columns we specified. It will also add timestamp columns for inserted_at and updated_at which come from the timestamps/0 function. defmodule Hello.Repo.Migrations.CreateUsers do use Ecto.Migration def change do create table(:users) do add :name, :string add :email, :string add :bio, :string add :number_of_pets, :integer timestamps() end end end And here&#39;s what that translates to in the actual users table. hello_dev=# \\d users Table &quot;public.users&quot; Column | Type | Modifiers ---------------+-----------------------------+---------------------------------------------------- id | integer | not null default nextval(&#39;users_id_seq&#39;::regclass) name | character varying(255) | email | character varying(255) | bio | character varying(255) | number_of_pets | integer | inserted_at | timestamp without time zone | not null updated_at | timestamp without time zone | not null Indexes: &quot;users_pkey&quot; PRIMARY KEY, btree (id) Notice that we do get an id column as our primary key by default, even though it isn&#39;t listed as a field in our migration."},{"ref":"ecto.html#the-repo","title":"Ecto - The Repo","type":"extras","doc":"Our Hello.Repo module is the foundation we need to work with databases in a Phoenix application. Phoenix generated it for us in lib/hello/repo.ex, and this is what it looks like. defmodule Hello.Repo do use Ecto.Repo, otp_app: :hello, adapter: Ecto.Adapters.Postgres end It begins by configuring our otp_app name and repo module. Then it sets the adapter – Postgres, in our case. It also sets our login credentials. Of course, you can change these to match your actual credentials if they are different. Our repo has three main tasks - to bring in all the common query functions from Ecto.Repo, to set the otp_app name equal to our application name, and to configure our database adapter. We&#39;ll talk more about how to use the Repo in a bit. When phx.new generated our application, it included some basic repo configuration as well. Let&#39;s look at config/dev.exs. ... # Configure your database config :hello, Hello.Repo, username: &quot;postgres&quot;, password: &quot;postgres&quot;, database: &quot;hello_dev&quot;, hostname: &quot;localhost&quot;, pool_size: 10 ... We also have similar configuration in config/test.exs and config/prod.secret.exs which can also be changed to match your actual credentials."},{"ref":"ecto.html#the-schema","title":"Ecto - The Schema","type":"extras","doc":"Ecto schemas are responsible for mapping Elixir values to external data sources, as well as mapping external data back into Elixir data-structures. We can also define relationships to other schemas in our applications. For example, our User schema might have many Post&#39;s, and each Post would belong to a User. Ecto also handles data validation and type casting with changesets, which we&#39;ll discuss in a moment. Here&#39;s the User schema that Phoenix generated for us. defmodule Hello.User do use Ecto.Schema import Ecto.Changeset alias Hello.User schema &quot;users&quot; do field :bio, :string field :email, :string field :name, :string field :number_of_pets, :integer timestamps() end @doc false def changeset(%User{} = user, attrs) do user |&gt; cast(attrs, [:name, :email, :bio, :number_of_pets]) |&gt; validate_required([:name, :email, :bio, :number_of_pets]) end end Ecto schemas at their core are simply Elixir structs. Our schema block is what tells Ecto how to cast our %User{} struct fields to and from the external users table. Often, the ability to simply cast data to and from the database isn&#39;t enough and extra data validation is required. This is where Ecto Changesets come in. Let&#39;s dive in!"},{"ref":"ecto.html#changesets-and-validations","title":"Ecto - Changesets and Validations","type":"extras","doc":"Changesets define a pipeline of transformations our data needs to undergo before it will be ready for our application to use. These transformations might include type-casting, user input validation, and filtering out any extraneous parameters. Often we&#39;ll use changesets to validate user input before writing it to the database. Ecto Repos are also changeset-aware, which allows them not only to refuse invalid data, but also perform the minimal database updates possible by inspecting the changeset to know which fields have changed. Let&#39;s take a closer look at our default changeset function. def changeset(%User{} = user, attrs) do user |&gt; cast(attrs, [:name, :email, :bio, :number_of_pets]) |&gt; validate_required([:name, :email, :bio, :number_of_pets]) end Right now, we have two transformations in our pipeline. In the first call, we invoke Ecto.Changeset&#39;s cast/3, passing in our external parameters and marking which fields are required for validation. cast/3 first takes a struct, then the parameters (the proposed updates), and then the final field is the list of columns to be updated. cast/3 also will only take fields that exist in the schema. Next, validate_required/3 checks that this list of fields is present in the changeset that cast/3 returns. By default with the generator, all fields are required. We can verify this functionality in iex. Let&#39;s fire up our application inside iex by running iex -S mix. In order to minimize typing and make this easier to read, let&#39;s alias our Hello.User struct. $ iex -S mix iex&gt; alias Hello.User Hello.User Next, let&#39;s build a changeset from our schema with an empty User struct, and an empty map of parameters. iex&gt; changeset = User.changeset(%User{}, %{}) #Ecto.Changeset&lt;action: nil, changes: %{}, errors: [name: {&quot;can&#39;t be blank&quot;, [validation: :required]}, email: {&quot;can&#39;t be blank&quot;, [validation: :required]}, bio: {&quot;can&#39;t be blank&quot;, [validation: :required]}, number_of_pets: {&quot;can&#39;t be blank&quot;, [validation: :required]}], data: #Hello.User&lt;&gt;, valid?: false&gt; Once we have a changeset, we can check it if it is valid. iex&gt; changeset.valid? false Since this one is not valid, we can ask it what the errors are. iex&gt; changeset.errors [name: {&quot;can&#39;t be blank&quot;, [validation: :required]}, email: {&quot;can&#39;t be blank&quot;, [validation: :required]}, bio: {&quot;can&#39;t be blank&quot;, [validation: :required]}, number_of_pets: {&quot;can&#39;t be blank&quot;, [validation: :required]}] Now, let&#39;s make number_of_pets optional. In order to do this, we simply remove it from the list. |&gt; validate_required([:name, :email, :bio]) Now casting the changeset should tell us that only name, email, and bio can&#39;t be blank. We can test that by running recompile() inside iex and then rebuilding our changeset. iex&gt; recompile() Compiling 1 file (.ex) :ok iex&gt; changeset = User.changeset(%User{}, %{}) #Ecto.Changeset&lt;action: nil, changes: %{}, errors: [name: {&quot;can&#39;t be blank&quot;, [validation: :required]}, email: {&quot;can&#39;t be blank&quot;, [validation: :required]}, bio: {&quot;can&#39;t be blank&quot;, [validation: :required]}], data: #Hello.User&lt;&gt;, valid?: false&gt; iex&gt; changeset.errors [name: {&quot;can&#39;t be blank&quot;, [validation: :required]}, email: {&quot;can&#39;t be blank&quot;, [validation: :required]}, bio: {&quot;can&#39;t be blank&quot;, [validation: :required]}] What happens if we pass a key/value pair that is in neither defined in the schema nor required? Inside our existing IEx shell, let&#39;s create a params map with valid values plus an extra random_key: &quot;random value&quot;. iex&gt; params = %{name: &quot;Joe Example&quot;, email: &quot;joe@example.com&quot;, bio: &quot;An example to all&quot;, number_of_pets: 5, random_key: &quot;random value&quot;} %{email: &quot;joe@example.com&quot;, name: &quot;Joe Example&quot;, bio: &quot;An example to all&quot;, number_of_pets: 5, random_key: &quot;random value&quot;} Next, let&#39;s use our new params map to create another changeset. iex&gt; changeset = User.changeset(%User{}, params) #Ecto.Changeset&lt;action: nil, changes: %{bio: &quot;An example to all&quot;, email: &quot;joe@example.com&quot;, name: &quot;Joe Example&quot;, number_of_pets: 5}, errors: [], data: #Hello.User&lt;&gt;, valid?: true&gt; Our new changeset is valid. iex&gt; changeset.valid? true We can also check the changeset&#39;s changes - the map we get after all of the transformations are complete. iex(9)&gt; changeset.changes %{bio: &quot;An example to all&quot;, email: &quot;joe@example.com&quot;, name: &quot;Joe Example&quot;, number_of_pets: 5} Notice that our random_key and random_value have been removed from the final changeset. Changesets allow us to cast external data, such as user input on a web form or data from a CSV file into valid data into our system. Invalid parameters will be stripped and bad data that is unable to be cast according to our schema will be highlighted in the changeset errors. We can validate more than just whether a field is required or not. Let&#39;s take a look at some finer-grained validations. What if we had a requirement that all biographies in our system must be at least two characters long? We can do this easily by adding another transformation to the pipeline in our changeset which validates the length of the bio field. def changeset(%User{} = user, attrs) do user |&gt; cast(attrs, [:name, :email, :bio, :number_of_pets]) |&gt; validate_required([:name, :email, :bio, :number_of_pets]) |&gt; validate_length(:bio, min: 2) end Now, if we try to cast data containing a value of &quot;A&quot; for our user&#39;s bio, we should see the failed validation in the changeset&#39;s errors. iex&gt; changeset = User.changeset(%User{}, %{bio: &quot;A&quot;}) iex&gt; changeset.errors[:bio] {&quot;should be at least %{count} character(s)&quot;, [count: 2, validation: :length, min: 2]} If we also have a requirement for the maximum length that a bio can have, we can simply add another validation. def changeset(%User{} = user, attrs) do user |&gt; cast(attrs, [:name, :email, :bio, :number_of_pets]) |&gt; validate_required([:name, :email, :bio, :number_of_pets]) |&gt; validate_length(:bio, min: 2) |&gt; validate_length(:bio, max: 140) end Let&#39;s say we want to perform at least some rudimentary format validation on the email field. All we want to check for is the presence of the &quot;@&quot;. The validate_format/3 function is just what we need. def changeset(%User{} = user, attrs) do user |&gt; cast(attrs, [:name, :email, :bio, :number_of_pets]) |&gt; validate_required([:name, :email, :bio, :number_of_pets]) |&gt; validate_length(:bio, min: 2) |&gt; validate_length(:bio, max: 140) |&gt; validate_format(:email, ~r/@/) end If we try to cast a user with an email of &quot;example.com&quot;, we should see an error message like the following. iex&gt; changeset = User.changeset(%User{}, %{email: &quot;example.com&quot;}) iex&gt; changeset.errors[:email] {&quot;has invalid format&quot;, [validation: :format]} There are many more validations and transformations we can perform in a changeset. Please see the Ecto Changeset documentation for more information."},{"ref":"ecto.html#data-persistence","title":"Ecto - Data Persistence","type":"extras","doc":"We&#39;ve talked a lot about migrations and data-storage, but we haven&#39;t yet persisted any of our schemas or changesets. We briefly looked at our repo module in lib/hello/repo.ex earlier, now it&#39;s time to put it to use. Ecto Repos are the interface into a storage system, be it a Database like PostgreSQL or an external service like a RESTful API. The Repo module&#39;s purpose is to take care of the finer details of persistence and data querying for us. As the caller, we only care about fetching and persisting data. The Repo takes care of the underlying Database adapter communication, connection pooling, and error translation for database constraint violations. Let&#39;s head back over to IEx with iex -S mix, and insert a couple of users into the database. iex&gt; alias Hello.{Repo, User} [Hello.Repo, Hello.User] iex&gt; Repo.insert(%User{email: &quot;user1@example.com&quot;}) [debug] QUERY OK db=4.6ms INSERT INTO &quot;users&quot; (&quot;email&quot;,&quot;inserted_at&quot;,&quot;updated_at&quot;) VALUES ($1,$2,$3) RETURNING &quot;id&quot; [&quot;user1@example.com&quot;, {{2017, 5, 23}, {19, 6, 4, 822044}}, {{2017, 5, 23}, {19, 6, 4, 822055}}] {:ok, %Hello.User{__meta__: #Ecto.Schema.Metadata&lt;:loaded, &quot;users&quot;&gt;, bio: nil, email: &quot;user1@example.com&quot;, id: 3, inserted_at: ~N[2017-05-23 19:06:04.822044], name: nil, number_of_pets: nil, updated_at: ~N[2017-05-23 19:06:04.822055]}} iex&gt; Repo.insert(%User{email: &quot;user2@example.com&quot;}) [debug] QUERY OK db=5.1ms INSERT INTO &quot;users&quot; (&quot;email&quot;,&quot;inserted_at&quot;,&quot;updated_at&quot;) VALUES ($1,$2,$3) RETURNING &quot;id&quot; [&quot;user2@example.com&quot;, {{2017, 5, 23}, {19, 6, 8, 452545}}, {{2017, 5, 23}, {19, 6, 8, 452556}}] {:ok, %Hello.User{__meta__: #Ecto.Schema.Metadata&lt;:loaded, &quot;users&quot;&gt;, bio: nil, email: &quot;user2@example.com&quot;, id: 4, inserted_at: ~N[2017-05-23 19:06:08.452545], name: nil, number_of_pets: nil, updated_at: ~N[2017-05-23 19:06:08.452556]}} We started by aliasing our User and Repo modules for easy access. Next, we called Repo.insert/1 and passed a user struct. Since we&#39;re in the dev environment, we can see the debug logs for the query our Repo performed when inserting the underlying %User{} data. We received a 2-tuple back with {:ok, %User{}}, which lets us know the insertion was successful. With a couple of users inserted, let&#39;s fetch them back out of the repo. iex&gt; Repo.all(User) [debug] QUERY OK source=&quot;users&quot; db=2.7ms SELECT u0.&quot;id&quot;, u0.&quot;bio&quot;, u0.&quot;email&quot;, u0.&quot;name&quot;, u0.&quot;number_of_pets&quot;, u0.&quot;inserted_at&quot;, u0.&quot;updated_at&quot; FROM &quot;users&quot; AS u0 [] [%Hello.User{__meta__: #Ecto.Schema.Metadata&lt;:loaded, &quot;users&quot;&gt;, bio: nil, email: &quot;user1@example.com&quot;, id: 3, inserted_at: ~N[2017-05-23 19:06:04.822044], name: nil, number_of_pets: nil, updated_at: ~N[2017-05-23 19:06:04.822055]}, %Hello.User{__meta__: #Ecto.Schema.Metadata&lt;:loaded, &quot;users&quot;&gt;, bio: nil, email: &quot;user2@example.com&quot;, id: 4, inserted_at: ~N[2017-05-23 19:06:08.452545], name: nil, number_of_pets: nil, updated_at: ~N[2017-05-23 19:06:08.452556]}] That was easy! Repo.all/1 takes a data source, our User schema in this case, and translates that to an underlying SQL query against our database. After it fetches the data, the Repo then uses our Ecto schema to map the database values back into Elixir data-structures according to our User schema. We&#39;re not just limited to basic querying – Ecto includes a full-fledged query DSL for advanced SQL generation. In addition to a natural Elixir DSL, Ecto&#39;s query engine gives us multiple great features, such as SQL injection protection and compile-time optimization of queries. Let&#39;s try it out. iex&gt; import Ecto.Query Ecto.Query iex&gt; Repo.all(from u in User, select: u.email) [debug] QUERY OK source=&quot;users&quot; db=2.4ms SELECT u0.&quot;email&quot; FROM &quot;users&quot; AS u0 [] [&quot;user1@example.com&quot;, &quot;user2@example.com&quot;] First, we imported Ecto.Query, which imports the from macro of Ecto&#39;s Query DSL. Next, we built a query which selects all the email addresses in our users table. Let&#39;s try another example. iex)&gt; Repo.one(from u in User, where: ilike(u.email, &quot;%1%&quot;), select: count(u.id)) [debug] QUERY OK source=&quot;users&quot; db=1.6ms SELECT count(u0.&quot;id&quot;) FROM &quot;users&quot; AS u0 WHERE (u0.&quot;email&quot; ILIKE &#39;%1%&#39;) [] 1 Now we&#39;re starting to get a taste of Ecto&#39;s rich querying capabilities. We used Repo.one/1 to fetch the count of all users with an email address containing &quot;1&quot;, and received the expected count in return. This just scratches the surface of Ecto&#39;s query interface, and much more is supported such as sub-querying, interval queries, and advanced select statements. For example, let&#39;s build a query to fetch a map of all user id&#39;s to their email addresses. iex&gt; Repo.all(from u in User, select: %{u.id =&gt; u.email}) [debug] QUERY OK source=&quot;users&quot; db=0.9ms SELECT u0.&quot;id&quot;, u0.&quot;email&quot; FROM &quot;users&quot; AS u0 [] [%{3 =&gt; &quot;user1@example.com&quot;}, %{4 =&gt; &quot;user2@example.com&quot;}] That little query packed a big punch. It both fetched all user emails from the database and efficiently built a map of the results in one go. You should browse the Ecto.Query documentation to see the breadth of supported query features. In addition to inserts, we can also perform updates and deletes with Repo.update/1 and Repo.delete/1 to update or delete a single schema. Ecto also supports bulk persistence with the Repo.insert_all, Repo.update_all, and Repo.delete_all functions. There is quite a bit more that Ecto can do and we&#39;ve only barely scratched the surface. With a solid Ecto foundation in place, we&#39;re now ready to continue building our app and integrate the web facing application with our backend persistence. Along the way, we&#39;ll expand our Ecto knowledge and learn how to properly isolate our web interface from the underlying details of our system. Please take a look at the Ecto documentation for the rest of the story. In our context guide, we&#39;ll find out how to wrap up our Ecto access and business logic behind modules that group related functionality. We&#39;ll see how Phoenix helps us design maintainable applications, and we&#39;ll find out about other neat Ecto features along the way."},{"ref":"ecto.html#using-mysql","title":"Ecto - Using MySQL","type":"extras","doc":"Phoenix applications are configured to use PostgreSQL by default, but what if we want to use MySQL instead? In this guide, we&#39;ll walk through changing that default whether we are about to create a new application, or whether we have an existing one configured for PostgreSQL. If we are about to create a new application, configuring our application to use MySQL is easy. We can simply pass the --database mysql flag to phx.new and everything will be configured correctly. $ mix phx.new hello_phoenix --database mysql This will set up all the correct dependencies and configuration for us automatically. Once we install those dependencies with mix deps.get, we&#39;ll be ready to begin working with Ecto in our application. If we have an existing application, all we need to do is switch adapters and make some small configuration changes. To switch adapters, we need to remove the Postgrex dependency and add a new one for Mariaex instead. Let&#39;s open up our mix.exs file and do that now. defmodule HelloPhoenix.MixProject do use Mix.Project . . . # Specifies your project dependencies. # # Type [`mix help deps`](https://hexdocs.pm/mix/Mix.Tasks.Deps.html) for examples and options. defp deps do [ {:phoenix, &quot;~&gt; 1.4.0&quot;}, {:phoenix_pubsub, &quot;~&gt; 1.1&quot;}, {:phoenix_ecto, &quot;~&gt; 4.0&quot;}, {:ecto_sql, &quot;~&gt; 3.1&quot;}, {:myxql, &quot;&gt;= 0.0.0&quot;}, {:phoenix_html, &quot;~&gt; 2.11&quot;}, {:phoenix_live_reload, &quot;~&gt; 1.2&quot;, only: :dev}, {:gettext, &quot;~&gt; 0.11&quot;}, {:plug_cowboy, &quot;~&gt; 2.0&quot;} ] end end Next, we need to configure our new adapter. Let&#39;s open up our config/dev.exs file and do that. config :hello_phoenix, HelloPhoenix.Repo, username: &quot;root&quot;, password: &quot;&quot;, database: &quot;hello_phoenix_dev&quot; If we have an existing configuration block for our HelloPhoenix.Repo, we can simply change the values to match our new ones. We also need to configure the correct values in the config/test.exs and config/prod.secret.exs files as well. The last change is to open up lib/hello_phoenix/repo.ex and make sure to set the :adapter to Ecto.Adapters.MyXQL. Now all we need to do is fetch our new dependency, and we&#39;ll be ready to go. $ mix do deps.get, compile With our new adapter installed and configured, we&#39;re ready to create our database. $ mix ecto.create The database for HelloPhoenix.repo has been created. We&#39;re also ready to run any migrations, or do anything else with Ecto that we might choose. $ mix ecto.migrate [info] == Running HelloPhoenix.Repo.Migrations.CreateUser.change/0 forward [info] create table users [info] == Migrated in 0.2s"},{"ref":"contexts.html","title":"Contexts","type":"extras","doc":"Contexts So far, we&#39;ve built pages, wired up controller actions through our routers, and learned how Ecto allows data to be validated and persisted. Now it&#39;s time to tie it all together by writing web-facing features that interact with our greater Elixir application. When building a Phoenix project, we are first and foremost building an Elixir application. Phoenix&#39;s job is to provide a web interface into our Elixir application. Naturally, we compose our applications with modules and functions, but simply defining a module with a few functions isn&#39;t enough when designing an application. It&#39;s vital to think about your application design when writing code. Let&#39;s find out how. How to read this guide: Using the context generators is a great way for beginners and intermediate Elixir programmers alike to get up and running quickly while thoughtfully designing their applications. This guide focuses on those readers. On the other hand, experienced developers may get more mileage from nuanced discussions around application design. For those readers, we include a frequently asked questions (FAQ) section at the end of the guide which brings different perspectives to some design decisions made throughout the guide. Beginners can safely skip the FAQ sections and return later when they&#39;re ready to dig deeper."},{"ref":"contexts.html#thinking-about-design","title":"Contexts - Thinking about design","type":"extras","doc":"Contexts are dedicated modules that expose and group related functionality. For example, anytime you call Elixir&#39;s standard library, be it Logger.info/1 or Stream.map/2, you are accessing different contexts. Internally, Elixir&#39;s logger is made of multiple modules, but we never interact with those modules directly. We call the Logger module the context, exactly because it exposes and groups all of the logging functionality. Phoenix projects are structured like Elixir and any other Elixir project – we split our code into contexts. A context will group related functionality, such as posts and comments, often encapsulating patterns such as data access and data validation. By using contexts, we decouple and isolate our systems into manageable, independent parts. Let&#39;s use these ideas to build out our web application. Our goal is to build a user system as well as a basic content management system for adding and editing page content. Let&#39;s get started! Adding an Accounts Context User accounts are often wide-reaching across a platform so it&#39;s important to think upfront about writing a well-defined interface. With that in mind, our goal is to build an accounts API that handles creating, updating, and deleting user accounts, as well as authenticating user credentials. We&#39;ll start off with basic features, but as we add authentication later, we&#39;ll see how starting with a solid foundation allows us to grow our application naturally as we add functionality. Phoenix includes the phx.gen.html, phx.gen.json, and phx.gen.context generators that apply the ideas of isolating functionality in our applications into contexts. These generators are a great way to hit the ground running while Phoenix nudges you in the right direction to grow your application. Let&#39;s put these tools to use for our new user accounts context. In order to run the context generators, we need to come up with a module name that groups the related functionality that we&#39;re building. In the Ecto guide, we saw how we can use Changesets and Repos to validate and persist user schemas, but we didn&#39;t integrate this with our application at large. In fact, we didn&#39;t think about where a &quot;user&quot; in our application should live at all. Let&#39;s take a step back and think about the different parts of our system. We know that we&#39;ll have users of our product. Along with users comes things like account login credentials and user registration. An Accounts context in our system is a natural place for our user functionality to live. Naming things is hard. If you&#39;re stuck when trying to come up with a context name when the grouped functionality in your system isn&#39;t yet clear, you can simply use the plural form of the resource you&#39;re creating. For example, a Users context for managing users. As you grow your application and the parts of your system become clear, you can simply rename the context to a more refined name at a later time. Before we use the generators, we need to undo the changes we made in the Ecto guide, so we can give our user schema a proper home. Run these commands to undo our previous work: $ rm lib/hello/user.ex $ rm priv/repo/migrations/*_create_users.exs Next, let&#39;s reset our database so we also discard the table we have just removed: $ mix ecto.reset Generated hello app The database for Hello.Repo has been dropped The database for Hello.Repo has been created 14:38:37.418 [info] Already up Now we&#39;re ready to create our accounts context. We&#39;ll use the phx.gen.html task which creates a context module that wraps up Ecto access for creating, updating, and deleting users, along with web files like controllers and templates for the web interface into our context. Run the following command at your project root: $ mix phx.gen.html Accounts User users name:string \\ username:string:unique * creating lib/hello_web/controllers/user_controller.ex * creating lib/hello_web/templates/user/edit.html.eex * creating lib/hello_web/templates/user/form.html.eex * creating lib/hello_web/templates/user/index.html.eex * creating lib/hello_web/templates/user/new.html.eex * creating lib/hello_web/templates/user/show.html.eex * creating lib/hello_web/views/user_view.ex * creating test/hello_web/controllers/user_controller_test.exs * creating lib/hello/accounts/user.ex * creating priv/repo/migrations/20170629175236_create_users.exs * creating lib/hello/accounts.ex * injecting lib/hello/accounts.ex * creating test/hello/accounts_test.exs * injecting test/hello/accounts_test.exs Add the resource to your browser scope in lib/hello_web/router.ex: resources &quot;/users&quot;, UserController Remember to update your repository by running migrations: $ mix ecto.migrate Phoenix generated the web files as expected in lib/hello_web/. We can also see our context files were generated inside a lib/hello/accounts.ex file and our user schema in the directory of the same name. Note the difference between lib/hello and lib/hello_web. We have an Accounts module to serve as the public API for account functionality, as well as an Accounts.User struct, which is an Ecto schema for casting and validating user account data. Phoenix also provided web and context tests for us, which we&#39;ll look at later. For now, let&#39;s follow the instructions and add the route according to the console instructions, in lib/hello_web/router.ex: scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index + resources &quot;/users&quot;, UserController end With the new route in place, Phoenix reminds us to update our repo by running mix ecto.migrate. Let&#39;s do that now: $ mix ecto.migrate [info] == Running Hello.Repo.Migrations.CreateUsers.change/0 forward [info] create table users [info] create index users_username_index [info] == Migrated in 0.0s Before we jump into the generated code, let&#39;s start the server with mix phx.server and visit http://localhost:4000/users. Let&#39;s follow the &quot;New User&quot; link and click the &quot;Submit&quot; button without providing any input. We should be greeted with the following output: Oops, something went wrong! Please check the errors below. When we submit the form, we can see all the validation errors inline with the inputs. Nice! Out of the box, the context generator included the schema fields in our form template and we can see our default validations for required inputs are in effect. Let&#39;s enter some example user data and resubmit the form: User created successfully. Show User Name: Chris McCord Username: chrismccord If we follow the &quot;Back&quot; link, we get a list of all users, which should contain the one we just created. Likewise, we can update this record or delete it. Now that we&#39;ve seen how it works in the browser, it&#39;s time to take a look at the generated code."},{"ref":"contexts.html#starting-with-generators","title":"Contexts - Starting With Generators","type":"extras","doc":"That little phx.gen.html command packed a surprising punch. We got a lot of functionality out-of-the-box for creating, updating, and deleting users. This is far from a full-featured app, but remember, generators are first and foremost learning tools and a starting point for you to begin building real features. Code generation can&#39;t solve all your problems, but it will teach you the ins and outs of Phoenix and nudge you towards the proper mind-set when designing your application. Let&#39;s first check out the UserController that was generated in lib/hello_web/controllers/user_controller.ex: defmodule HelloWeb.UserController do use HelloWeb, :controller alias Hello.Accounts alias Hello.Accounts.User def index(conn, _params) do users = Accounts.list_users() render(conn, &quot;index.html&quot;, users: users) end def new(conn, _params) do changeset = Accounts.change_user(%User{}) render(conn, &quot;new.html&quot;, changeset: changeset) end def create(conn, %{&quot;user&quot; =&gt; user_params}) do case Accounts.create_user(user_params) do {:ok, user} -&gt; conn |&gt; put_flash(:info, &quot;User created successfully.&quot;) |&gt; redirect(to: Routes.user_path(conn, :show, user)) {:error, %Ecto.Changeset{} = changeset} -&gt; render(conn, &quot;new.html&quot;, changeset: changeset) end end ... end We&#39;ve seen how controllers work in our controller guide, so the code probably isn&#39;t too surprising. What is worth noticing is how our controller calls into the Accounts context. We can see that the index action fetches a list of users with Accounts.list_users/0, and how users are persisted in the create action with Accounts.create_user/1. We haven&#39;t yet looked at the accounts context, so we don&#39;t yet know how user fetching and creation is happening under the hood – but that&#39;s the point. Our Phoenix controller is the web interface into our greater application. It shouldn&#39;t be concerned with the details of how users are fetched from the database or persisted into storage. We only care about telling our application to perform some work for us. This is great because our business logic and storage details are decoupled from the web layer of our application. If we move to a full-text storage engine later for fetching users instead of a SQL query, our controller doesn&#39;t need to be changed. Likewise, we can reuse our context code from any other interface in our application, be it a channel, mix task, or long-running process importing CSV data. In the case of our create action, when we successfully create a user, we use Phoenix.Controller.put_flash/3 to show a success message, and then we redirect to the user_path&#39;s show page. Conversely, if Accounts.create_user/1 fails, we render our &quot;new.html&quot; template and pass along the Ecto changeset for the template to lift error messages from. Next, let&#39;s dig deeper and check out our Accounts context in lib/hello/accounts.ex: defmodule Hello.Accounts do @moduledoc &quot;&quot;&quot; The Accounts context. &quot;&quot;&quot; import Ecto.Query, warn: false alias Hello.Repo alias Hello.Accounts.User @doc &quot;&quot;&quot; Returns the list of users. ## Examples iex&gt; list_users() [%User{}, ...] &quot;&quot;&quot; def list_users do Repo.all(User) end ... end This module will be the public API for all account functionality in our system. For example, in addition to user account management, we may also handle user login credentials, account preferences, and password reset generation. If we look at the list_users/0 function, we can see the private details of user fetching. And it&#39;s super simple. We have a call to Repo.all(User). We saw how Ecto repo queries worked in the Ecto guide, so this call should look familiar. Our list_users function is a generalized function specifying the intent of our code – namely to list users. The details of that intent where we use our Repo to fetch the users from our PostgreSQL database is hidden from our callers. This is a common theme we&#39;ll see re-iterated as we use the Phoenix generators. Phoenix will push us to think about where we have different responsibilities in our application, and then to wrap up those different areas behind well-named modules and functions that make the intent of our code clear, while encapsulating the details. Now we know how data is fetched, but how are users persisted? Let&#39;s take a look at the Accounts.create_user/1 function: @doc &quot;&quot;&quot; Creates a user. ## Examples iex&gt; create_user(%{field: value}) {:ok, %User{}} iex&gt; create_user(%{field: bad_value}) {:error, %Ecto.Changeset{}} &quot;&quot;&quot; def create_user(attrs \\\\ %{}) do %User{} |&gt; User.changeset(attrs) |&gt; Repo.insert() end There&#39;s more documentation than code here, but a couple of things are important to highlight. First, we can see again that our Ecto Repo is used under the hood for database access. You probably also noticed the call to User.changeset/2. We talked about changesets before, and now we see them in action in our context. If we open up the User schema in lib/hello/accounts/user.ex, it will look immediately familiar: defmodule Hello.Accounts.User do use Ecto.Schema import Ecto.Changeset alias Hello.Accounts.User schema &quot;users&quot; do field :name, :string field :username, :string timestamps() end @doc false def changeset(%User{} = user, attrs) do user |&gt; cast(attrs, [:name, :username]) |&gt; validate_required([:name, :username]) |&gt; unique_constraint(:username) end end This is just what we saw before when we ran the mix phx.gen.schema task, except here we see a @doc false above our changeset/2 function. This tells us that while this function is publicly callable, it&#39;s not part of the public context API. Callers that build changesets do so via the context API. For example, Accounts.create_user/1 calls into our User.changeset/2 to build the changeset from user input. Callers, such as our controller actions, do not access User.changeset/2 directly. All interaction with our user changesets is done through the public Accounts context."},{"ref":"contexts.html#in-context-relationships","title":"Contexts - In-context Relationships","type":"extras","doc":"Our basic user account features are nice, but let&#39;s take it up a notch by supporting user login credentials. We won&#39;t implement a complete authentication system, but we&#39;ll give ourselves a good start to grow such a system from. Many authentication solutions couple the user credentials to an account in a one-to-one fashion, but this often causes issues. For example, supporting different login methods, such as social login or recovery email addresses, will cause major code changes. Let&#39;s set up a credentials association that will allow us to start off tracking a single credential per account, but easily support more features later. For now, user credentials will contain only email information. Our first order of business is to decide where credentials live in the application. We have our Accounts context, which manages user accounts. User credentials is a natural fit here. Phoenix is also smart enough to generate code inside an existing context, which makes adding new resources to a context a breeze. Run the following command at your project root: Sometimes it may be tricky to determine if two resources belong to the same context or not. In those cases, prefer distinct contexts per resource and refactor later if necessary. Otherwise you can easily end-up with large contexts of loosely related entities. In other words: if you are unsure, you should prefer explicit modules (contexts) between resources. $ mix phx.gen.context Accounts Credential credentials \\ email:string:unique user_id:references:users * creating lib/hello/accounts/credential.ex * creating priv/repo/migrations/20170629180555_create_credentials.exs * injecting lib/hello/accounts.ex * injecting test/hello/accounts_test.exs Remember to update your repository by running migrations: $ mix ecto.migrate This time around, we used the phx.gen.context task, which is just like phx.gen.html, except it doesn&#39;t generate the web files for us. Since we already have controllers and templates for managing users, we can integrate the new credential features into our existing web form. We can see from the output that Phoenix generated an accounts/credential.ex file for our Accounts.Credential schema, as well as a migration. Notably, phoenix said it was * injecting code into the existing accounts.ex context file and test file. Since our Accounts module already exists, Phoenix knows to inject our code here. Before we run our migrations, we need to make one change to the generated migration to enforce data integrity of user account credentials. In our case, we want a user&#39;s credentials to be deleted when the parent user is removed. Make the following change to your *_create_credentials.exs migration file in priv/repo/migrations/: def change do create table(:credentials) do add :email, :string - add :user_id, references(:users, on_delete: :nothing) + add :user_id, references(:users, on_delete: :delete_all), + null: false timestamps() end create unique_index(:credentials, [:email]) create index(:credentials, [:user_id]) end We changed the :on_delete option from :nothing to :delete_all, which will generate a foreign key constraint that will delete all credentials for a given user when the user is removed from the database. Likewise, we also passed null: false to disallow creating credentials without an existing user. By using a database constraint, we enforce data integrity at the database level, rather than relying on ad-hoc and error-prone application logic. Next, let&#39;s migrate up our database as Phoenix instructed: $ mix ecto.migrate mix ecto.migrate Compiling 2 files (.ex) Generated hello app [info] == Running Hello.Repo.Migrations.CreateCredentials.change/0 forward [info] create table credentials [info] create index credentials_email_index [info] create index credentials_user_id_index [info] == Migrated in 0.0s Before we integrate credentials in the web layer, we need to let our context know how to associate users and credentials. First, open up lib/hello/accounts/user.ex and add the following association: + alias Hello.Accounts.Credential schema &quot;users&quot; do field :name, :string field :username, :string + has_one :credential, Credential timestamps() end We used Ecto.Schema&#39;s has_one macro to let Ecto know how to associate our parent User to a child Credential. Next, let&#39;s add the relationships in the opposite direction in accounts/credential.ex: + alias Hello.Accounts.User schema &quot;credentials&quot; do field :email, :string - field :user_id, :id + belongs_to :user, User timestamps() end We used the belongs_to macro to map our child relationship to the parent User. With our schema associations set up, let&#39;s open up accounts.ex and make the following changes to the generated list_users and get_user! functions: def list_users do User |&gt; Repo.all() |&gt; Repo.preload(:credential) end def get_user!(id) do User |&gt; Repo.get!(id) |&gt; Repo.preload(:credential) end We rewrote the list_users/0 and get_user!/1 to preload the credential association whenever we fetch users. The Repo preload functionality fetches a schema&#39;s association data from the database, then places it inside the schema. When operating on a collection, such as our query in list_users, Ecto can efficiently preload the associations in a single query. This allows us to represent our %Accounts.User{} structs as always containing credentials without the caller having to worry about fetching the extra data. Next, let&#39;s expose our new feature to the web by adding the credentials input to our user form. Open up lib/hello_web/templates/user/form.html.eex and key in the new credential form group above the submit button: ... + &lt;div class=&quot;form-group&quot;&gt; + &lt;%= inputs_for f, :credential, fn cf -&gt; %&gt; + &lt;%= label cf, :email %&gt; + &lt;%= text_input cf, :email %&gt; + &lt;%= error_tag cf, :email %&gt; + &lt;% end %&gt; + &lt;/div&gt; &lt;%= submit &quot;Submit&quot; %&gt; We used Phoenix.HTML&#39;s inputs_for function to add an associations nested fields within the parent form. Within the nested inputs, we rendered our credential&#39;s email field and included the label and error_tag helpers just like our other inputs. Next, let&#39;s show the user&#39;s email address in the user show template. Add the following code to lib/hello_web/templates/user/show.html.eex: ... + &lt;li&gt; + &lt;strong&gt;Email:&lt;/strong&gt; + &lt;%= @user.credential.email %&gt; + &lt;/li&gt; &lt;/ul&gt; Now if we visit http://localhost:4000/users/new, we&#39;ll see the new email input, but if you try to save a user, you&#39;ll find that the email field is ignored. No validations are run telling you it was blank and the data was not saved, and at the end you&#39;ll get an exception (UndefinedFunctionError) function nil.email/0 is undefined or private. What gives? We used Ecto&#39;s belongs_to and has_one associations to wire-up how our data is related at the context level, but remember this is decoupled from our web-facing user input. To associate user input to our schema associations, we need to handle it the way we&#39;ve handled other user input so far – in changesets. Remove the alias for Credential added by the generator and modify your alias Hello.Accounts.User, create_user/1 and update_user/2 functions in your Accounts context to build a changeset which knows how to cast user input with nested credential information: - alias Hello.Accounts.User + alias Hello.Accounts.{User, Credential} ... def update_user(%User{} = user, attrs) do user |&gt; User.changeset(attrs) + |&gt; Ecto.Changeset.cast_assoc(:credential, with: &amp;Credential.changeset/2) |&gt; Repo.update() end def create_user(attrs \\\\ %{}) do %User{} |&gt; User.changeset(attrs) + |&gt; Ecto.Changeset.cast_assoc(:credential, with: &amp;Credential.changeset/2) |&gt; Repo.insert() end ... - alias Hello.Accounts.Credential We updated the functions to pipe our user changeset into Ecto.Changeset.cast_assoc/3. Ecto&#39;s cast_assoc/3 allows us to tell the changeset how to cast user input to a schema relation. We also used the :with option to tell Ecto to use our Credential.changeset/2 function to cast the data. This way, any validations we perform in Credential.changeset/2 will be applied when saving the User changeset. Finally, if you visit http://localhost:4000/users/new and attempt to save an empty email address, you&#39;ll see the proper validation error message. If you enter valid information, the data will be casted and persisted properly. Show User Name: Chris McCord Username: chrismccord Email: chris@example.com It&#39;s not much to look at yet, but it works! We added relationships within our context complete with data integrity enforced by the database. Not bad. Let&#39;s keep building!"},{"ref":"contexts.html#adding-account-functions","title":"Contexts - Adding Account functions","type":"extras","doc":"As we&#39;ve seen, your context modules are dedicated modules that expose and group related functionality. Phoenix generates generic functions, such as list_users and update_user, but they only serve as a basis for you to grow your business logic and application from. To begin extending our Accounts context with real features, let&#39;s address an obvious issue of our application – we can create users with credentials in our system, but they have no way of signing in with those credentials. Building a complete user authentication system is beyond the scope of this guide, but let&#39;s get started with a basic email-only sign-in page that allows us to track a current user&#39;s session. This will let us focus on extending our Accounts context while giving you a good start to grow a complete authentication solution from. To start, let&#39;s think of a function name that describes what we want to accomplish. To authenticate a user by email address, we&#39;ll need a way to lookup that user and verify their entered credentials are valid. We can do this by exposing a single function on our Accounts context. &gt; user = Accounts.authenticate_by_email_password(email, password) That looks nice. A descriptive name that exposes the intent of our code is best. This function makes it crystal clear what purpose it serves, while allowing our caller to remain blissfully unaware of the internal details. Make the following additions to your lib/hello/accounts.ex file: def authenticate_by_email_password(email, _password) do query = from u in User, inner_join: c in assoc(u, :credential), where: c.email == ^email case Repo.one(query) do %User{} = user -&gt; {:ok, user} nil -&gt; {:error, :unauthorized} end end We defined an authenticate_by_email_password/2 function, which discards the password field for now, but you could integrate tools like guardian or comeonin as you continue building your application. All we need to do in our function is find the user with matching credentials and return the %Accounts.User{} struct in a :ok tuple, or an {:error, :unauthorized} value to let the caller know their authentication attempt has failed. Now that we can authenticate a user from our context, let&#39;s add a login page to our web layer. First create a new controller in lib/hello_web/controllers/session_controller.ex: defmodule HelloWeb.SessionController do use HelloWeb, :controller alias Hello.Accounts def new(conn, _) do render(conn, &quot;new.html&quot;) end def create(conn, %{&quot;user&quot; =&gt; %{&quot;email&quot; =&gt; email, &quot;password&quot; =&gt; password}}) do case Accounts.authenticate_by_email_password(email, password) do {:ok, user} -&gt; conn |&gt; put_flash(:info, &quot;Welcome back!&quot;) |&gt; put_session(:user_id, user.id) |&gt; configure_session(renew: true) |&gt; redirect(to: &quot;/&quot;) {:error, :unauthorized} -&gt; conn |&gt; put_flash(:error, &quot;Bad email/password combination&quot;) |&gt; redirect(to: Routes.session_path(conn, :new)) end end def delete(conn, _) do conn |&gt; configure_session(drop: true) |&gt; redirect(to: &quot;/&quot;) end end We defined a SessionController to handle users signing in and out of the application. Our new action is responsible for simply rendering a &quot;new session&quot; form, which posts out to the create action of our controller. In create, we pattern match the form fields and call into our Accounts.authenticate_by_email_password/2 that we just defined. If successful, we use Plug.Conn.put_session/3 to place the authenticated user&#39;s ID in the session, and redirect to the home page with a successful welcome message. We also called configure_session(conn, renew: true) before redirecting to avoid session fixation attacks. If authentication fails, we add a flash error message, and redirect to the sign-in page for the user to try again. To finish the controller, we support a delete action which simply calls Plug.Conn.configure_session/2 to drop the session and redirect to the home page. Next, let&#39;s wire up our session routes in lib/hello_web/router.ex: scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index resources &quot;/users&quot;, UserController + resources &quot;/sessions&quot;, SessionController, only: [:new, :create, :delete], singleton: true end We used resources to generate a set of routes under the &quot;/session&quot; path. This is what we&#39;ve done for other routes, except this time we also passed the :only option to limit which routes are generated, since we only need to support :new, :create, and :delete actions. We also used the singleton: true option, which defines all the RESTful routes, but does not require a resource ID to be passed along in the URL. We don&#39;t need an ID in the URL because our actions are always scoped to the &quot;current&quot; user in the system. The ID is always in the session. Before we finish our router, let&#39;s add an authentication plug to the router that will allow us to lock down certain routes after a user has used our new session controller to sign-in. Add the following function to lib/hello_web/router.ex: defp authenticate_user(conn, _) do case get_session(conn, :user_id) do nil -&gt; conn |&gt; Phoenix.Controller.put_flash(:error, &quot;Login required&quot;) |&gt; Phoenix.Controller.redirect(to: &quot;/&quot;) |&gt; halt() user_id -&gt; assign(conn, :current_user, Hello.Accounts.get_user!(user_id)) end end We defined an authenticate_user/2 plug in the router which simply uses Plug.Conn.get_session/2 to check for a :user_id in the session. If we find one, it means a user has previously authenticated, and we call into Hello.Accounts.get_user!/1 to place our :current_user into the connection assigns. If we don&#39;t have a session, we add a flash error message, redirect to the homepage, and we use Plug.Conn.halt/1 to halt further plugs downstream from being invoked. We won&#39;t use this new plug quite yet, but it will be ready and waiting as we add authenticated routes in just a moment. Lastly, we need SessionView to render a template for our login form. Create a new file in lib/hello_web/views/session_view.ex: defmodule HelloWeb.SessionView do use HelloWeb, :view end Next, add a new template in lib/hello_web/templates/session/new.html.eex: &lt;h1&gt;Sign in&lt;/h1&gt; &lt;%= form_for @conn, Routes.session_path(@conn, :create), [method: :post, as: :user], fn f -&gt; %&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;%= text_input f, :email, placeholder: &quot;Email&quot; %&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;%= password_input f, :password, placeholder: &quot;Password&quot; %&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;%= submit &quot;Login&quot; %&gt; &lt;/div&gt; &lt;% end %&gt; &lt;%= form_for @conn, Routes.session_path(@conn, :delete), [method: :delete, as: :user], fn _ -&gt; %&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;%= submit &quot;logout&quot; %&gt; &lt;/div&gt; &lt;% end %&gt; To keep things simple, we added both our sign-in and sign-out forms in this template. For our sign-in form, we pass the @conn directly to form_for, pointing our form action at session_path(@conn, :create). We also pass the as: :user option which tells Phoenix to wrap the form parameters inside a &quot;user&quot; key. Next, we used the text_input and password_input functions to send up an &quot;email&quot; and &quot;password&quot; parameter. For logging out, we simply defined a form that sends the DELETE HTTP method to server&#39;s session delete path. Now if you visit the sign-in page at http://localhost:4000/sessions/new and enter a bad email address, you should be greeted with your flash message. Entering a valid email address will redirect to the home page with a success flash notice. With authentication in place, we&#39;re in good shape to begin building out our next features."},{"ref":"contexts.html#cross-context-dependencies","title":"Contexts - Cross-context dependencies","type":"extras","doc":"Now that we have the beginnings of user account and credential features, let&#39;s begin to work on the other main features of our application – managing page content. We want to support a content management system (CMS) where authors can create and edit pages of the site. While we could extend our Accounts context with CMS features, if we step back and think about the isolation of our application, we can see it doesn&#39;t fit. An accounts system shouldn&#39;t care at all about a CMS system. The responsibilities of our Accounts context is to manage users and their credentials, not handle page content changes. There&#39;s a clear need here for a separate context to handle these responsibilities. Let&#39;s call it CMS. Let&#39;s create a CMS context to handle basic CMS duties. Before we write code, let&#39;s imagine we have the following CMS feature requirements: Page creation and updates Pages belong to Authors who are responsible for publishing changes Author information should appear with the page, and include information such as author bio and role within the CMS, such as &quot;editor&quot;, &quot;writer&quot;, or &quot;intern&quot;. From the description, it&#39;s clear we need a Page resource for storing page information. What about our author information? While we could extend our existing Accounts.User schema to include information such as bio and role, that would violate the responsibilities we&#39;ve set up for our contexts. Why should our Account system now be aware of author information? Worse, with a field like &quot;role&quot;, the CMS role in the system will likely conflict or be confused with other account roles for our application. There&#39;s a better way. Applications with &quot;users&quot; are naturally heavily user driven. After all, our software is typically designed to be used by human end-users one way or another. Instead of extending our Accounts.User struct to track every field and responsibility of our entire platform, it&#39;s better to keep those responsibilities with the modules who own that functionality. In our case, we can create a CMS.Author struct that holds author specific fields as it relates to a CMS. Now we can place fields like &quot;role&quot; and &quot;bio&quot; here, where they naturally live. Likewise, we also gain specialized datastructures in our application that are suited to the domain that we are operating in, rather than a single %User{} in the system that has to be everything to everyone. With our plan set, let&#39;s get to work. Run the following command to generate our new context: $ mix phx.gen.html CMS Page pages title:string body:text \\ views:integer --web CMS * creating lib/hello_web/controllers/cms/page_controller.ex * creating lib/hello_web/templates/cms/page/edit.html.eex * creating lib/hello_web/templates/cms/page/form.html.eex * creating lib/hello_web/templates/cms/page/index.html.eex * creating lib/hello_web/templates/cms/page/new.html.eex * creating lib/hello_web/templates/cms/page/show.html.eex * creating lib/hello_web/views/cms/page_view.ex * creating test/hello_web/controllers/cms/page_controller_test.exs * creating lib/hello/cms/page.ex * creating priv/repo/migrations/20170629195946_create_pages.exs * creating lib/hello/cms.ex * injecting lib/hello/cms.ex * creating test/hello/cms/cms_test.exs * injecting test/hello/cms/cms_test.exs Add the resource to your CMS :browser scope in lib/hello_web/router.ex: scope &quot;/cms&quot;, HelloWeb.CMS, as: :cms do pipe_through :browser ... resources &quot;/pages&quot;, PageController end Remember to update your repository by running migrations: $ mix ecto.migrate The views attribute on the pages will not be updated directly by the user, so let&#39;s remove it from the generated form. Open lib/hello_web/templates/cms/page/form.html.eex and remove this part: - &lt;%= label f, :views %&gt; - &lt;%= number_input f, :views %&gt; - &lt;%= error_tag f, :views %&gt; Also, change lib/hello/cms/page.ex to remove :views from the permitted params: def changeset(%Page{} = page, attrs) do page - |&gt; cast(attrs, [:title, :body, :views]) - |&gt; validate_required([:title, :body, :views]) + |&gt; cast(attrs, [:title, :body]) + |&gt; validate_required([:title, :body]) end Finally, open up the new file in priv/repo/migrations to ensure the views attribute will have a default value: create table(:pages) do add :title, :string add :body, :text - add :views, :integer + add :views, :integer, default: 0 timestamps() end This time we passed the --web option to the generator. This tells Phoenix what namespace to use for the web modules, such as controllers and views. This is useful when you have conflicting resources in the system, such as our existing PageController, as well as a way to naturally namespace paths and functionality of different features, like a CMS system. Phoenix instructed us to add a new scope to the router for a &quot;/cms&quot; path prefix. Let&#39;s copy paste the following into our lib/hello_web/router.ex, but we&#39;ll make one modification to the pipe_through macro: scope &quot;/cms&quot;, HelloWeb.CMS, as: :cms do pipe_through [:browser, :authenticate_user] resources &quot;/pages&quot;, PageController end We added the :authenticate_user plug to require a signed-in user for all routes within this CMS scope. With our routes in place, we can migrate up the database: $ mix ecto.migrate Compiling 12 files (.ex) Generated hello app [info] == Running Hello.Repo.Migrations.CreatePages.change/0 forward [info] create table pages [info] == Migrated in 0.0s Now, let&#39;s fire up the server with mix phx.server and visit http://localhost:4000/cms/pages. If we haven&#39;t logged in yet, we&#39;ll be redirected to the home page with a flash error message telling us to sign in. Let&#39;s sign in at http://localhost:4000/sessions/new, then re-visit http://localhost:4000/cms/pages. Now that we&#39;re authenticated, we should see a familiar resource listing for pages, with a New Page link. Before we create any pages, we need page authors. Let&#39;s run the phx.gen.context generator to generate an Author schema along with injected context functions: $ mix phx.gen.context CMS Author authors bio:text role:string \\ genre:string user_id:references:users:unique * creating lib/hello/cms/author.ex * creating priv/repo/migrations/20170629200937_create_authors.exs * injecting lib/hello/cms.ex * injecting test/hello/cms/cms_test.exs Remember to update your repository by running migrations: $ mix ecto.migrate We used the context generator to inject code, just like when we generated our credentials code. We added fields for the author bio, their role in the content management system, the genre the author writes in, and lastly a foreign key to a user in our accounts system. Since our accounts context is still the authority on end-users in our application, we will depend on it for our CMS authors. That said, any information specific to authors will stay in the authors schema. We could also decorate our Author with user account information by using virtual fields and never expose the User structure. This would ensure consumers of the CMS API are protected from changes in the User context. Before we migrate our database, we need to handle data integrity once again in the newly generated *_create_authors.exs migration. Open up the new file in priv/repo/migrations and make the following change to the foreign key constraint: def change do create table(:authors) do add :bio, :text add :role, :string add :genre, :string - add :user_id, references(:users, on_delete: :nothing) + add :user_id, references(:users, on_delete: :delete_all), + null: false timestamps() end create unique_index(:authors, [:user_id]) end We used the :delete_all strategy again to enforce data integrity. This way, when a user is deleted from the application through Accounts.delete_user/1), we don&#39;t have to rely on application code in our Accounts context to worry about cleaning up the CMS author records. This keeps our application code decoupled and the data integrity enforcement where it belongs – in the database. Before we continue, we have a final migration to generate. Now that we have an authors table, we can associate pages and authors. Let&#39;s add an author_id field to the pages table. Run the following command to generate a new migration: $ mix ecto.gen.migration add_author_id_to_pages * creating priv/repo/migrations * creating priv/repo/migrations/20170629202117_add_author_id_to_pages.exs Now open up the new *_add_author_id_to_pages.exs file in priv/repo/migrations and key this in: def change do alter table(:pages) do add :author_id, references(:authors, on_delete: :delete_all), null: false end create index(:pages, [:author_id]) end We used the alter macro to add a new author_id field to the pages table, with a foreign key to our authors table. We also used the on_delete: :delete_all option again to prune any pages when a parent author is deleted from the application. Now let&#39;s migrate up: $ mix ecto.migrate [info] == Running Hello.Repo.Migrations.CreateAuthors.change/0 forward [info] create table authors [info] create index authors_user_id_index [info] == Migrated in 0.0s [info] == Running Hello.Repo.Migrations.AddAuthorIdToPages.change/0 forward [info] == Migrated in 0.0s With our database ready, let&#39;s integrate authors and posts in the CMS system."},{"ref":"contexts.html#cross-context-data","title":"Contexts - Cross-context data","type":"extras","doc":"Dependencies in your software are often unavoidable, but we can do our best to limit them where possible and lessen the maintenance burden when a dependency is necessary. So far, we&#39;ve done a great job isolating the two main contexts of our application from each other, but now we have a necessary dependency to handle. Our Author resource serves to keep the responsibilities of representing an author inside the CMS, but ultimately for an author to exist at all, an end-user represented by an Accounts.User must be present. Given this, our CMS context will have a data dependency on the Accounts context. With that in mind, we have two options. One is to expose APIs on the Accounts contexts that allows us to efficiently fetch user data for use in the CMS system, or we can use database joins to fetch the dependent data. Both are valid options given your tradeoffs and application size, but joining data from the database when you have a hard data dependency is just fine for a large class of applications. If you decide to break out coupled contexts into entirely separate applications and databases at a later time, you still gain the benefits of isolation. This is because your public context APIs will likely remain unchanged. Now that we know where our data dependencies exist, let&#39;s add our schema associations so we can tie pages to authors and authors to users. Make the following changes to lib/hello/cms/page.ex: + alias Hello.CMS.Author schema &quot;pages&quot; do field :body, :string field :title, :string field :views, :integer + belongs_to :author, Author timestamps() end We added a belongs_to relationships between pages and their authors. Next, let&#39;s add the association in the other direction in lib/hello/cms/author.ex: + alias Hello.CMS.Page schema &quot;authors&quot; do field :bio, :string field :genre, :string field :role, :string - field :user_id, :id + has_many :pages, Page + belongs_to :user, Hello.Accounts.User timestamps() end We added the has_many association for author pages, and then introduced our data dependency on the Accounts context by wiring up the belongs_to association to our Accounts.User schema. With our associations in place, let&#39;s update our CMS context to require an author when creating or updating a page. We&#39;ll start off with data fetching changes. Open up your CMS context in lib/hello/cms.ex and replace the list_pages/0, get_page!/1, and get_author!/1 functions with the following definitions: alias Hello.CMS.{Page, Author} alias Hello.Accounts def list_pages do Page |&gt; Repo.all() |&gt; Repo.preload(author: [user: :credential]) end def get_page!(id) do Page |&gt; Repo.get!(id) |&gt; Repo.preload(author: [user: :credential]) end def get_author!(id) do Author |&gt; Repo.get!(id) |&gt; Repo.preload(user: :credential) end We started by rewriting the list_pages/0 function to preload the associated author, user, and credential data from the database. Next, we rewrote get_page!/1 and get_author!/1 to also preload the necessary data. With our data access functions in place, let&#39;s turn our focus towards persistence. We can fetch authors alongside pages, but we haven&#39;t yet allowed authors to be persisted when we create or edit pages. Let&#39;s fix that. Open up lib/hello/cms.ex and make the following changes: def create_page(%Author{} = author, attrs \\\\ %{}) do %Page{} |&gt; Page.changeset(attrs) |&gt; Ecto.Changeset.put_change(:author_id, author.id) |&gt; Repo.insert() end def ensure_author_exists(%Accounts.User{} = user) do %Author{user_id: user.id} |&gt; Ecto.Changeset.change() |&gt; Ecto.Changeset.unique_constraint(:user_id) |&gt; Repo.insert() |&gt; handle_existing_author() end defp handle_existing_author({:ok, author}), do: author defp handle_existing_author({:error, changeset}) do Repo.get_by!(Author, user_id: changeset.data.user_id) end There&#39;s a bit of a code here, so let&#39;s break it down. First, we rewrote the create_page function to require a CMS.Author struct, which represents the author publishing the post. We then take our changeset and pass it to Ecto.Changeset.put_change/2 to place the author_id association in the changeset. Next, we use Repo.insert to insert the new page into the database, containing our associated author_id. Our CMS system requires an author to exist for any end-user before they publish posts, so we added an ensure_author_exists function to programmatically allow authors to be created. Our new function accepts an Accounts.User struct and either finds the existing author in the application with that user.id, or creates a new author for the user. Our authors table has a unique constraint on the user_id foreign key, so we are protected from a race condition allowing duplicate authors. That said, we still need to protect ourselves from racing the insert of another user. To accomplish this, we use a purpose-built changeset with Ecto.Changeset.change/1 which accepts a new Author struct with our user_id. The changeset&#39;s only purpose is to convert a unique constraint violation into an error we can handle. After attempting to insert the new author with Repo.insert/1, we pipe to handle_existing_author/1 which matches on the success and error cases. For the success case, we are done and simply return the created author, otherwise we use Repo.get_by! to fetch the author for the user_id that already exists. That wraps up our CMS changes. Now, let&#39;s update our web layer to support our additions. Before we update our individual CMS controller actions, we need to make a couple of additions to the CMS.PageController plug pipeline. First, we must ensure an author exists for end-users accessing the CMS, and we need to authorize access to page owners. Open up your generated lib/hello_web/controllers/cms/page_controller.ex and make the following additions: plug :require_existing_author plug :authorize_page when action in [:edit, :update, :delete] ... defp require_existing_author(conn, _) do author = CMS.ensure_author_exists(conn.assigns.current_user) assign(conn, :current_author, author) end defp authorize_page(conn, _) do page = CMS.get_page!(conn.params[&quot;id&quot;]) if conn.assigns.current_author.id == page.author_id do assign(conn, :page, page) else conn |&gt; put_flash(:error, &quot;You can&#39;t modify that page&quot;) |&gt; redirect(to: Routes.cms_page_path(conn, :index)) |&gt; halt() end end We added two new plugs to our CMS.PageController. The first plug, :require_existing_author, runs for every action in this controller. The require_existing_author/2 plug calls into our CMS.ensure_author_exists/1 and passes in the current_user from the connection assigns. After finding or creating the author, we use Plug.Conn.assign/3 to place a :current_author key into the assigns for use downstream. Next, we added an :authorize_page plug that makes use of plug&#39;s guard clause feature where we can limit the plug to only certain actions. The definition for our authorize_page/2 plug first fetches the page from the connection params, then does an authorization check against the current_author. If our current author&#39;s ID matches the fetched page ID, we have verified the page&#39;s owner is accessing the page and we simply assign the page into the connection assigns to be used in the controller action. If our authorization fails, we add a flash error message, redirect to the page index screen, and then call Plug.Conn.halt/1 to prevent the plug pipeline from continuing and invoking the controller action. With our new plugs in place, we can now modify our create, edit, update, and delete actions to make use of the new values in the connection assigns: - def edit(conn, %{&quot;id&quot; =&gt; id}) do + def edit(conn, _) do - page = CMS.get_page!(id) - changeset = CMS.change_page(page) + changeset = CMS.change_page(conn.assigns.page) - render(conn, &quot;edit.html&quot;, page: page, changeset: changeset) + render(conn, &quot;edit.html&quot;, changeset: changeset) end def create(conn, %{&quot;page&quot; =&gt; page_params}) do - case CMS.create_page(page_params) do + case CMS.create_page(conn.assigns.current_author, page_params) do {:ok, page} -&gt; conn |&gt; put_flash(:info, &quot;Page created successfully.&quot;) |&gt; redirect(to: Routes.cms_page_path(conn, :show, page)) {:error, %Ecto.Changeset{} = changeset} -&gt; render(conn, &quot;new.html&quot;, changeset: changeset) end end - def update(conn, %{&quot;id&quot; =&gt; id, &quot;page&quot; =&gt; page_params}) do + def update(conn, %{&quot;page&quot; =&gt; page_params}) do - page = CMS.get_page!(id) - case CMS.update_page(page, page_params) do + case CMS.update_page(conn.assigns.page, page_params) do {:ok, page} -&gt; conn |&gt; put_flash(:info, &quot;Page updated successfully.&quot;) |&gt; redirect(to: Routes.cms_page_path(conn, :show, page)) {:error, %Ecto.Changeset{} = changeset} -&gt; - render(conn, &quot;edit.html&quot;, page: page, changeset: changeset) + render(conn, &quot;edit.html&quot;, changeset: changeset) end end - def delete(conn, %{&quot;id&quot; =&gt; id}) do + def delete(conn, _) do - page = CMS.get_page!(id) - {:ok, _page} = CMS.delete_page(page) + {:ok, _page} = CMS.delete_page(conn.assigns.page) conn |&gt; put_flash(:info, &quot;Page deleted successfully.&quot;) |&gt; redirect(to: Routes.cms_page_path(conn, :index)) end We modified the create action to grab our current_author from the connection assigns, which was placed there by our require_existing_author plug. We then passed our current author into CMS.create_page where it will be used to associate the author to the new page. Next, we changed the update action to pass the conn.assigns.page into CMS.update_page/2, rather than fetching it directly in the action. Since our authorize_page plug already fetched the page and placed it into the assigns, we can simply reference it here in the action. Similarly, we updated the delete action to pass the conn.assigns.page into the CMS rather than fetching the page in the action. To complete the web changes, let&#39;s display the author when showing a page. First, open up lib/hello_web/views/cms/page_view.ex and add a helper function to handle formatting the author&#39;s name: defmodule HelloWeb.CMS.PageView do use HelloWeb, :view alias Hello.CMS def author_name(%CMS.Page{author: author}) do author.user.name end end Next, let&#39;s open up lib/hello_web/templates/cms/page/show.html.eex and make use of our new function: + &lt;li&gt; + &lt;strong&gt;Author:&lt;/strong&gt; + &lt;%= author_name(@page) %&gt; + &lt;/li&gt; &lt;/ul&gt; Now, fire up your server with mix phx.server and try it out. Visit http://localhost:4000/cms/pages/new and save a new page. Page created successfully. Show Page Title: Home Body: Welcome to Phoenix! Views: 0 Author: Chris And it works! We now have two isolated contexts responsible for user accounts and content management. We coupled the content management system to accounts where necessary, while keeping each system isolated wherever possible. This gives us a great base to grow our application from."},{"ref":"contexts.html#adding-cms-functions","title":"Contexts - Adding CMS functions","type":"extras","doc":"Just like we extended our Accounts context with new application-specific functions like Accounts.authenticate_by_email_password/2, let&#39;s extend our generated CMS context with new functionality. For any CMS system, the ability to track how many times a page has been viewed is essential for popularity ranks. While we could try to use the existing CMS.update_page function, along the lines of CMS.update_page(user, page, %{views: page.views + 1}), this would not only be prone to race conditions, but it would also require the caller to know too much about our CMS system. To see why the race condition exists, let&#39;s walk through the possible execution of events: Intuitively, you would assume the following events: User 1 loads the page with count of 13 User 1 saves the page with count of 14 User 2 loads the page with count of 14 User 2 loads the page with count of 15 While in practice this would happen: User 1 loads the page with count of 13 User 2 loads the page with count of 13 User 1 saves the page with count of 14 User 2 saves the page with count of 14 The race conditions would make this an unreliable way to update the existing table since multiple callers may be updating out of date view values. There&#39;s a better way. Again, let&#39;s think of a function name that describes what we want to accomplish. &gt; page = CMS.inc_page_views(page) That looks great. Our callers will have no confusion over what this function does and we can wrap up the increment in an atomic operation to prevent race conditions. Open up your CMS context (lib/hello/cms.ex), and add this new function: def inc_page_views(%Page{} = page) do {1, [%Page{views: views}]} = from(p in Page, where: p.id == ^page.id, select: [:views]) |&gt; Repo.update_all(inc: [views: 1]) put_in(page.views, views) end We built a query for fetching the current page given its ID which we pass to Repo.update_all. Ecto&#39;s Repo.update_all allows us to perform batch updates against the database, and is perfect for atomically updating values, such as incrementing our views count. The result of the repo operation returns the number of updated records, along with the selected schema values specified by the select option. When we receive the new page views, we use put_in(page.views, views) to place the new view count within the page. With our context function in place, let&#39;s make use of it in our CMS page controller. Update your show action in lib/hello_web/controllers/cms/page_controller.ex to call our new function: def show(conn, %{&quot;id&quot; =&gt; id}) do page = id |&gt; CMS.get_page!() |&gt; CMS.inc_page_views() render(conn, &quot;show.html&quot;, page: page) end We modified our show action to pipe our fetched page into CMS.inc_page_views/1, which will return the updated page. Then we rendered our template just as before. Let&#39;s try it out. Refresh one of your pages a few times and watch the view count increase. We can also see our atomic update in action in the ecto debug logs: [debug] QUERY OK source=&quot;pages&quot; db=3.1ms UPDATE &quot;pages&quot; AS p0 SET &quot;views&quot; = p0.&quot;views&quot; + $1 WHERE (p0.&quot;id&quot; = $2) RETURNING p0.&quot;views&quot; [1, 3] Good work! As we&#39;ve seen, designing with contexts gives you a solid foundation to grow your application from. Using discrete, well-defined APIs that expose the intent of your system allows you to write more maintainable applications with reusable code."},{"ref":"contexts.html#faq","title":"Contexts - FAQ","type":"extras","doc":"Returning Ecto structures from context APIs As we explored the context API, you might have wondered: If one of the goals of our context is to encapsulate Ecto Repo access, why does create_user/1 return an Ecto.Changeset struct when we fail to create a user? The answer is we&#39;ve decided to expose %Ecto.Changeset{} as a public data-structure in our application. We saw before how changesets allow us to track field changes, perform validations, and generate error messages. Its use here is decoupled from the private Repo access and Ecto changeset API internals. We&#39;re exposing a data structure that the caller understands which contains the rich information like field errors. Conveniently for us, the phoenix_ecto project implements the necessary Phoenix.Param and Phoenix.HTML.FormData protocols which know how to handle %Ecto.Changeset{}&#39;s for things like form generation and error messages. You can also think about it as being as if you had defined your own %Accounts.Changes{} struct for the same purpose and implemented the Phoenix protocols for the web-layer integration. Strategies for cross-context workflows Our CMS context supports lazily creating authors in the system when a user decides to publish page content. This makes sense for our use case because not all users of our system will be CMS authors. But what if our use case were for when all users of our app are indeed authors? If we require a CMS.Author to exist every time an Accounts.User is created, we have to think carefully where to place this dependency. We know our CMS context depends on the Accounts context, but it&#39;s important to avoid cyclic dependencies across our contexts. For example, imagine we changed our Accounts.create_user function to: def create_user(attrs) do %User{} |&gt; User.changeset(attrs) |&gt; Ecto.Changeset.cast_assoc(:credential, with: &amp;Credential.changeset/2) |&gt; Ecto.Changeset.put_assoc(:author, %Author{...}) |&gt; Repo.insert() end This may accomplish what we want, but now we need to wire up the schema relationships in the Accounts context to the CMS author. Worse, we have now taken our isolated Accounts context and required it to know about a content management system. This isn&#39;t what we want for isolated responsibilities in our application. There&#39;s a better way to handle these requirements. If you find yourself in similar situations where you feel your use case is requiring you to create circular dependencies across contexts, it&#39;s a sign you need a new context in the system to handle these application requirements. In our case, what we really want is an interface that handles all requirements when a user is created or registers in our application. To handle this, we could create a UserRegistration context, which calls into both the Accounts and CMS APIs to create a user, then associate a CMS author. Not only would this allow our Accounts to remain as isolated as possible, it gives us a clear, obvious API to handle UserRegistration needs in the system. If you take this approach, you can also use tools like Ecto.Multi to handle transactions across different context operations without deeply coupling the internal database calls. Part of our UserRegistration API could look something like this: defmodule Hello.UserRegistration do alias Ecto.Multi alias Hello.{Accounts, CMS} def register_user(params) do Multi.new() |&gt; Multi.run(:user, fn _repo, _ -&gt; Accounts.create_user(params) end) |&gt; Multi.run(:author, fn _repo, %{user: user} -&gt; {:ok, CMS.ensure_author_exists(user)} end) |&gt; Repo.transaction() end end We can take advantage of Ecto.Multi to create a pipeline of operations that can be run inside a transaction of our Repo. If any given operation fails, the transaction will be rolled back and an error will be returned containing which operation failed, as well as the changes up to that point. In our register_user/1 example, we specified two operations, one that calls into Accounts.create_user/1 and another that passes the newly created user to CMS.ensure_author_exists/1. The final step of our function is to invoke the operations with Repo.transaction/1. The UserRegistration setup is likely simpler to implement than the dynamic author system we built – we decided to take the harder path exactly because those are decisions developers take on their applications every day."},{"ref":"phoenix_mix_tasks.html","title":"Mix Tasks","type":"extras","doc":"Mix Tasks There are currently a number of built-in Phoenix-specific and ecto-specific mix tasks available to us within a newly-generated application. We can also create our own application specific tasks. Note to learn more about mix read the Introduction to Mix."},{"ref":"phoenix_mix_tasks.html#phoenix-specific-mix-tasks","title":"Mix Tasks - Phoenix Specific Mix Tasks","type":"extras","doc":"➜ mix help | grep -i phx mix local.phx # Updates the Phoenix project generator locally mix phx # Prints Phoenix help information mix phx.digest # Digests and compresses static files mix phx.digest.clean # Removes old versions of static assets. mix phx.gen.cert # Generates a self-signed certificate for HTTPS testing mix phx.gen.channel # Generates a Phoenix channel mix phx.gen.context # Generates a context with functions around an Ecto schema mix phx.gen.embedded # Generates an embedded Ecto schema file mix phx.gen.html # Generates controller, views, and context for an HTML resource mix phx.gen.json # Generates controller, views, and context for a JSON resource mix phx.gen.presence # Generates a Presence tracker mix phx.gen.schema # Generates an Ecto schema and migration file mix phx.gen.secret # Generates a secret mix phx.new # Creates a new Phoenix application mix phx.new.ecto # Creates a new Ecto project within an umbrella project mix phx.new.web # Creates a new Phoenix web project within an umbrella project mix phx.routes # Prints all routes mix phx.server # Starts applications and their servers We have seen all of these at one point or another in the guides, but having all the information about them in one place seems like a good idea. And here we are. mix phx.new This is how we tell Phoenix the framework to generate a new Phoenix application for us. We saw it early on in the Up and Running Guide. Before we begin, we should note that Phoenix uses Ecto for database access and webpack for asset management by default. We can pass --no-ecto to opt out of Ecto and --no-webpack to opt out of webpack. Note: If we do use webpack, we need to install its dependencies before we start our application. mix phx.new will ask to do this for us. Otherwise, we can install them with npm install. If we don&#39;t install them, the app will throw errors and may not serve our assets properly. We need to pass a name for our application to mix phx.new. Conventionally, we use all lower-case letters with underscores. $ mix phx.new task_tester * creating task_tester/.gitignore . . . We can also use either a relative or absolute path. This relative path works. $ mix phx.new ../task_tester * creating ../task_tester/.gitignore . . . This absolute path works as well. $ mix phx.new /Users/me/work/task_tester * creating /Users/me/work/task_tester/.gitignore . . . The mix phx.new task will also ask us if we want to install our dependencies. (Please see the note above about webpack dependencies.) Fetch and install dependencies? [Yn] y * cd assets &amp;&amp; npm install &amp;&amp; node node_modules/webpack/bin/webpack.js --mode development * running mix deps.get Once all of our dependencies are installed, mix phx.new will tell us what our next steps are. We are all set! Run your Phoenix application: $ cd task_tester $ mix phx.server You can also run it inside IEx (Interactive Elixir) as: $ iex -S mix phx.server By default mix phx.new will assume we want to use ecto for our contexts. If we don&#39;t want to use ecto in our application, we can use the --no-ecto flag. $ mix phx.new task_tester --no-ecto * creating task_tester/.gitignore . . . With the --no-ecto flag, Phoenix will not make either ecto or postgrex a dependency of our application, and it will not create a repo.ex file. By default, Phoenix will name our OTP application after the name we pass into mix phx.new. If we want, we can specify a different OTP application name with the --app flag. $ mix phx.new task_tester --app hello * creating task_tester/config/config.exs * creating task_tester/config/dev.exs * creating task_tester/config/prod.exs * creating task_tester/config/prod.secret.exs * creating task_tester/config/test.exs * creating task_tester/lib/hello/application.ex * creating task_tester/lib/hello.ex * creating task_tester/lib/hello_web/channels/user_socket.ex * creating task_tester/lib/hello_web/views/error_helpers.ex * creating task_tester/lib/hello_web/views/error_view.ex * creating task_tester/lib/hello_web/endpoint.ex * creating task_tester/lib/hello_web/router.ex * creating task_tester/lib/hello_web.ex * creating task_tester/mix.exs . . . If we look in the resulting mix.exs file, we will see that our project app name is hello. defmodule Hello.MixProject do use Mix.Project def project do [app: :hello, version: &quot;0.1.0&quot;, . . . A quick check will show that all of our module names are qualified with Hello. defmodule HelloWeb.PageController do use HelloWeb, :controller . . . We can also see that files related to the application as a whole - eg. files in lib/ and the test seed file - have hello in their names. * creating task_tester/lib/hello.ex * creating task_tester/lib/hello_web/endpoint.ex * creating task_tester/lib/hello/repo.ex If we only want to change the qualifying prefix for module names, we can do that with the --module flag. It&#39;s important to note that the value of the --module must look like a valid module name with proper capitalization. The task will throw an error if it doesn&#39;t. $ mix phx.new task_tester --module Hello * creating task_tester/config/config.exs * creating task_tester/config/dev.exs * creating task_tester/config/prod.exs * creating task_tester/config/prod.secret.exs * creating task_tester/config/test.exs * creating task_tester/lib/task_tester/application.ex * creating task_tester/lib/task_tester.ex * creating task_tester/lib/task_tester_web/channels/user_socket.ex * creating task_tester/lib/task_tester_web/views/error_helpers.ex * creating task_tester/lib/task_tester_web/views/error_view.ex * creating task_tester/lib/task_tester_web/endpoint.ex * creating task_tester/lib/task_tester_web/router.ex * creating task_tester/lib/task_tester_web.ex * creating task_tester/mix.exs * creating task_tester/README.md * creating task_tester/.gitignore * creating task_tester/test/support/channel_case.ex * creating task_tester/test/support/conn_case.ex * creating task_tester/test/test_helper.exs * creating task_tester/test/task_tester_web/views/error_view_test.exs * creating task_tester/lib/task_tester_web/gettext.ex * creating task_tester/priv/gettext/en/LC_MESSAGES/errors.po * creating task_tester/priv/gettext/errors.pot * creating task_tester/lib/task_tester/repo.ex Notice that none of the files have hello in their names. All filenames related to the application name are task_tester. If we look at the project app name in mix.exs, we see that it is task_tester, but all the module qualifying names begin with Hello. defmodule Hello.MixProject do use Mix.Project def project do [app: :task_tester, . . . mix phx.gen.html Phoenix now offers the ability to generate all the code to stand up a complete HTML resource - ecto migration, ecto context, controller with all the necessary actions, view, and templates. This can be a tremendous timesaver. Let&#39;s take a look at how to make this happen. The mix phx.gen.html task takes a number of arguments, the module name of the context, the module name of the schema, the resource name, and a list of column_name:type attributes. The module name we pass in must conform to the Elixir rules of module naming, following proper capitalization. $ mix phx.gen.html Blog Post posts body:string word_count:integer * creating lib/hello_web/controllers/post_controller.ex * creating lib/hello_web/templates/post/edit.html.eex * creating lib/hello_web/templates/post/form.html.eex * creating lib/hello_web/templates/post/index.html.eex * creating lib/hello_web/templates/post/new.html.eex * creating lib/hello_web/templates/post/show.html.eex * creating lib/hello_web/views/post_view.ex * creating test/hello_web/controllers/post_controller_test.exs * creating lib/hello/blog/post.ex * creating priv/repo/migrations/20170906150129_create_posts.exs * creating lib/hello/blog.ex * injecting lib/hello/blog.ex * creating test/hello/blog/blog_test.exs * injecting test/hello/blog/blog_test.exs When mix phx.gen.html is done creating files, it helpfully tells us that we need to add a line to our router file as well as run our ecto migrations. Add the resource to your browser scope in lib/hello_web/router.ex: resources &quot;/posts&quot;, PostController Remember to update your repository by running migrations: $ mix ecto.migrate Important: If we don&#39;t do this, we will see the following warnings in our logs, and our application will error when trying to execute the function. $ mix phx.server Compiling 17 files (.ex) warning: function HelloWeb.Router.Helpers.post_path/3 is undefined or private lib/hello_web/controllers/post_controller.ex:22: If we don&#39;t want to create a context or schema for our resource we can use the --no-context flag. Note that this still requires a context module name as a parameter. $ mix phx.gen.html Blog Post posts body:string word_count:integer --no-context * creating lib/hello_web/controllers/post_controller.ex * creating lib/hello_web/templates/post/edit.html.eex * creating lib/hello_web/templates/post/form.html.eex * creating lib/hello_web/templates/post/index.html.eex * creating lib/hello_web/templates/post/new.html.eex * creating lib/hello_web/templates/post/show.html.eex * creating lib/hello_web/views/post_view.ex * creating test/hello_web/controllers/post_controller_test.exs It will tell us we need to add a line to our router file, but since we skipped the context, it won&#39;t mention anything about ecto.migrate. Add the resource to your browser scope in lib/hello_web/router.ex: resources &quot;/posts&quot;, PostController Important: If we don&#39;t do this, we&#39;ll get the following warning in our logs and the application will error when attempting to load the page: $ mix phx.server Compiling 15 files (.ex) warning: function HelloWeb.Router.Helpers.post_path/3 is undefined or private lib/hello_web/templates/post/edit.html.eex:3 Similarly - if we want a context created without a schema for our resource we can use the --no-schema flag. $ mix phx.gen.html Blog Post posts body:string word_count:integer --no-schema * creating lib/hello_web/controllers/post_controller.ex * creating lib/hello_web/templates/post/edit.html.eex * creating lib/hello_web/templates/post/form.html.eex * creating lib/hello_web/templates/post/index.html.eex * creating lib/hello_web/templates/post/new.html.eex * creating lib/hello_web/templates/post/show.html.eex * creating lib/hello_web/views/post_view.ex * creating test/hello_web/controllers/post_controller_test.exs * creating lib/hello/blog.ex * injecting lib/hello/blog.ex * creating test/hello/blog/blog_test.exs * injecting test/hello/blog/blog_test.exs It will tell us we need to add a line to our router file, but since we skipped the schema, it won&#39;t mention anything about ecto.migrate. Add the resource to your browser scope in lib/hello_web/router.ex: resources &quot;/posts&quot;, PostController Important: If we don&#39;t do this, we&#39;ll get the following warning in our logs and the application will error when attempting to load the page: $ mix phx.server Compiling 15 files (.ex) warning: function HelloWeb.Router.Helpers.post_path/3 is undefined or private lib/hello_web/templates/post/edit.html.eex:3 mix phx.gen.json Phoenix also offers the ability to generate all the code to stand up a complete JSON resource - ecto migration, ecto schema, controller with all the necessary actions and view. This command will not create any template for the app. The mix phx.gen.json task takes a number of arguments, the module name of the context, the module name of the schema, the resource name, and a list of column_name:type attributes. The module name we pass in must conform to the Elixir rules of module naming, following proper capitalization. $ mix phx.gen.json Blog Post posts title:string content:string * creating lib/hello_web/controllers/post_controller.ex * creating lib/hello_web/views/post_view.ex * creating test/hello_web/controllers/post_controller_test.exs * creating lib/hello_web/views/changeset_view.ex * creating lib/hello_web/controllers/fallback_controller.ex * creating lib/hello/blog/post.ex * creating priv/repo/migrations/20170906153323_create_posts.exs * creating lib/hello/blog.ex * injecting lib/hello/blog.ex * creating test/hello/blog/blog_test.exs * injecting test/hello/blog/blog_test.exs When mix phx.gen.json is done creating files, it helpfully tells us that we need to add a line to our router file as well as run our ecto migrations. Add the resource to your :api scope in lib/hello_web/router.ex: resources &quot;/posts&quot;, PostController, except: [:new, :edit] Remember to update your repository by running migrations: $ mix ecto.migrate Important: If we don&#39;t do this, we&#39;ll get the following warning in our logs and the application will error when attempting to load the page: $ mix phx.server Compiling 19 files (.ex) warning: function HelloWeb.Router.Helpers.post_path/3 is undefined or private lib/hello_web/controllers/post_controller.ex:18 If we don&#39;t want to create a context or schema for our resource we can use the --no-context flag. Note that this still requires a context module name as a parameter. $ mix phx.gen.json Blog Post posts title:string content:string --no-context * creating lib/hello_web/controllers/post_controller.ex * creating lib/hello_web/views/post_view.ex * creating test/hello_web/controllers/post_controller_test.exs * creating lib/hello_web/views/changeset_view.ex * creating lib/hello_web/controllers/fallback_controller.ex It will tell us we need to add a line to our router file, but since we skipped the context, it won&#39;t mention anything about ecto.migrate. Add the resource to your :api scope in lib/hello_web/router.ex: resources &quot;/posts&quot;, PostController, except: [:new, :edit] Important: If we don&#39;t do this, our application won&#39;t compile, and we&#39;ll get an error. $ mix phx.server Compiling 17 files (.ex) == Compilation error in file lib/hello_web/controllers/post_controller.ex == ** (CompileError) lib/hello_web/controllers/post_controller.ex:15: Hello.Blog.Post.__struct__/0 is undefined, cannot expand struct Hello.Blog.Post (stdlib) lists.erl:1354: :lists.mapfoldl/3 (stdlib) lists.erl:1355: :lists.mapfoldl/3 (stdlib) lists.erl:1354: :lists.mapfoldl/3 lib/hello_web/controllers/post_controller.ex:14: (module) (stdlib) erl_eval.erl:670: :erl_eval.do_apply/6 Similarly - if we want a context created without a schema for our resource we can use the --no-schema flag. $ mix phx.gen.json Blog Post posts title:string content:string --no-schema * creating lib/hello_web/controllers/post_controller.ex * creating lib/hello_web/views/post_view.ex * creating test/hello_web/controllers/post_controller_test.exs * creating lib/hello_web/views/changeset_view.ex * creating lib/hello_web/controllers/fallback_controller.ex * creating lib/hello/blog.ex * injecting lib/hello/blog.ex * creating test/hello/blog/blog_test.exs * injecting test/hello/blog/blog_test.exs It will tell us we need to add a line to our router file, but since we skipped the context, it won&#39;t mention anything about ecto.migrate. Add the resource to your browser scope in lib/hello_web/router.ex: resources &quot;/posts&quot;, PostController Important: If we don&#39;t do this, our application won&#39;t compile, and we&#39;ll get an error. $ mix phx.server Compiling 18 files (.ex) == Compilation error in file lib/hello/blog.ex == ** (CompileError) lib/hello/blog.ex:65: Hello.Blog.Post.__struct__/0 is undefined, cannot expand struct Hello.Blog.Post lib/hello/blog.ex:65: (module) (stdlib) erl_eval.erl:670: :erl_eval.do_apply/6 (elixir) lib/kernel/parallel_compiler.ex:121: anonymous fn/4 in Kernel.ParallelCompiler.spawn_compilers/1 mix phx.gen.context If we don&#39;t need a complete HTML/JSON resource and instead are only interested in a context, we can use the mix phx.gen.context task. It will generate a context, a schema, a migration and a test case. The mix phx.gen.context task takes a number of arguments, the module name of the context, the module name of the schema, the resource name, and a list of column_name:type attributes. $ mix phx.gen.context Accounts User users name:string age:integer * creating lib/hello/accounts/user.ex * creating priv/repo/migrations/20170906161158_create_users.exs * creating lib/hello/accounts.ex * injecting lib/hello/accounts.ex * creating test/hello/accounts/accounts_test.exs * injecting test/hello/accounts/accounts_test.exs Note: If we need to namespace our resource we can simply namespace the first argument of the generator. * creating lib/hello/admin/accounts/user.ex * creating priv/repo/migrations/20170906161246_create_users.exs * creating lib/hello/admin/accounts.ex * injecting lib/hello/admin/accounts.ex * creating test/hello/admin/accounts/accounts_test.exs * injecting test/hello/admin/accounts/accounts_test.exs mix phx.gen.schema If we don&#39;t need a complete HTML/JSON resource and are not interested in generating or altering a context we can use the mix phx.gen.schema task. It will generate a schema, and a migration. The mix phx.gen.schema task takes a number of arguments, the module name of the schema (which may be namespaced), the resource name, and a list of column_name:type attributes. $ mix phx.gen.schema Accounts.Credential credentials email:string:unique user_id:references:users * creating lib/hello/accounts/credential.ex * creating priv/repo/migrations/20170906162013_create_credentials.exs mix phx.gen.channel This task will generate a basic Phoenix channel as well a test case for it. It takes the module name for the channel as argument: $ mix phx.gen.channel Room * creating lib/hello_web/channels/room_channel.ex * creating test/hello_web/channels/room_channel_test.exs When mix phx.gen.channel is done, it helpfully tells us that we need to add a channel route to our router file. Add the channel to your `lib/hello_web/channels/user_socket.ex` handler, for example: channel &quot;rooms:lobby&quot;, HelloWeb.RoomChannel mix phx.gen.presence This task will generate a Presence tracker. The module name can be passed as an argument, Presence is used if no module name is passed. $ mix phx.gen.presence Presence $ lib/hello_web/channels/presence.ex mix phx.routes This task has a single purpose, to show us all the routes defined for a given router. We saw it used extensively in the Routing Guide. If we don&#39;t specify a router for this task, it will default to the router Phoenix generated for us. $ mix phx.routes page_path GET / TaskTester.PageController.index/2 We can also specify an individual router if we have more than one for our application. $ mix phx.routes TaskTesterWeb.Router page_path GET / TaskTesterWeb.PageController.index/2 mix phx.server This is the task we use to get our application running. It takes no arguments at all. If we pass any in, they will be silently ignored. $ mix phx.server [info] Running TaskTesterWeb.Endpoint with Cowboy on port 4000 (http) It silently ignores our DoesNotExist argument. $ mix phx.server DoesNotExist [info] Running TaskTesterWeb.Endpoint with Cowboy on port 4000 (http) If we would like to start our application and also have an iex session open to it, we can run the mix task within iex like this, iex -S mix phx.server. $ iex -S mix phx.server Erlang/OTP 17 [erts-6.4] [source] [64-bit] [smp:8:8] [async-threads:10] [hipe] [kernel-poll:false] [dtrace] [info] Running TaskTesterWeb.Endpoint with Cowboy on port 4000 (http) Interactive Elixir (1.0.4) - press Ctrl+C to exit (type h() ENTER for help) iex(1)&gt; mix phx.digest This task does two things, it creates a digest for our static assets and then compresses them. &quot;Digest&quot; here refers to an MD5 digest of the contents of an asset which gets added to the filename of that asset. This creates a sort of &quot;fingerprint&quot; for it. If the digest doesn&#39;t change, browsers and CDNs will use a cached version. If it does change, they will re-fetch the new version. Before we run this task let&#39;s inspect the contents of two directories in our hello application. First priv/static which should look similar to this: ├── images │ └── phoenix.png ├── robots.txt And then assets/ which should look similar to this: ├── css │ └── app.css ├── js │ └── app.js ├── vendor │ └── phoenix.js All of these files are our static assets. Now let&#39;s run the mix phx.digest task. $ mix phx.digest Check your digested files at &#39;priv/static&#39;. We can now do as the task suggests and inspect the contents of priv/static directory. We&#39;ll see that all files from assets/ have been copied over to priv/static and also each file now has a couple of versions. Those versions are: the original file a compressed file with gzip a file containing the original file name and its digest a compressed file containing the file name and its digest We can optionally determine which files should be gzipped by using the :gzippable_exts option in the config file: config :phoenix, :gzippable_exts, ~w(.js .css) Note: We can specify a different output folder where mix phx.digest will put processed files. The first argument is the path where the static files are located. $ mix phx.digest priv/static -o www/public Check your digested files at &#39;www/public&#39;."},{"ref":"phoenix_mix_tasks.html#ecto-specific-mix-tasks","title":"Mix Tasks - Ecto Specific Mix Tasks","type":"extras","doc":"Newly generated Phoenix applications now include ecto and postgrex as dependencies by default (which is to say, unless we use mix phx.new with the --no-ecto flag). With those dependencies come mix tasks to take care of common ecto operations. Let&#39;s see which tasks we get out of the box. $ mix help | grep -i ecto mix ecto.create # Create the storage for the repo mix ecto.drop # Drop the storage for the repo mix ecto.gen.migration # Generate a new migration for the repo mix ecto.gen.repo # Generates a new repository mix ecto.migrate # Runs migrations up on a repo mix ecto.rollback # Reverts migrations down on a repo Note: We can run any of the tasks above with the --no-start flag to execute the task without starting the application. mix ecto.create This task will create the database specified in our repo. By default it will look for the repo named after our application (the one generated with our app unless we opted out of ecto), but we can pass in another repo if we want. Here&#39;s what it looks like in action. $ mix ecto.create The database for Hello.Repo has been created. If we happen to have another repo called OurCustom.Repo that we want to create the database for, we can run this. $ mix ecto.create -r OurCustom.Repo The database for OurCustom.Repo has been created. There are a few things that can go wrong with ecto.create. If our Postgres database doesn&#39;t have a &quot;postgres&quot; role (user), we&#39;ll get an error like this one. $ mix ecto.create ** (Mix) The database for Hello.Repo couldn&#39;t be created, reason given: psql: FATAL: role &quot;postgres&quot; does not exist We can fix this by creating the &quot;postgres&quot; role in the psql console with the permissions needed to log in and create a database. =# CREATE ROLE postgres LOGIN CREATEDB; CREATE ROLE If the &quot;postgres&quot; role does not have permission to log in to the application, we&#39;ll get this error. $ mix ecto.create ** (Mix) The database for Hello.Repo couldn&#39;t be created, reason given: psql: FATAL: role &quot;postgres&quot; is not permitted to log in To fix this, we need to change the permissions on our &quot;postgres&quot; user to allow login. =# ALTER ROLE postgres LOGIN; ALTER ROLE If the &quot;postgres&quot; role does not have permission to create a database, we&#39;ll get this error. $ mix ecto.create ** (Mix) The database for Hello.Repo couldn&#39;t be created, reason given: ERROR: permission denied to create database To fix this, we need to change the permissions on our &quot;postgres&quot; user in the psql console to allow database creation. =# ALTER ROLE postgres CREATEDB; ALTER ROLE If the &quot;postgres&quot; role is using a password different from the default &quot;postgres&quot;, we&#39;ll get this error. $ mix ecto.create ** (Mix) The database for Hello.Repo couldn&#39;t be created, reason given: psql: FATAL: password authentication failed for user &quot;postgres&quot; To fix this, we can change the password in the environment specific configuration file. For the development environment the password used can be found at the bottom of the config/dev.exs file. ecto.drop This task will drop the database specified in our repo. By default it will look for the repo named after our application (the one generated with our app unless we opted out of ecto). It will not prompt us to check if we&#39;re sure we want to drop the db, so do exercise caution. $ mix ecto.drop The database for Hello.Repo has been dropped. If we happen to have another repo that we want to drop the database for, we can specify it with the -r flag. $ mix ecto.drop -r OurCustom.Repo The database for OurCustom.Repo has been dropped. mix ecto.gen.repo Many applications require more than one data store. For each data store, we&#39;ll need a new repo, and we can generate them automatically with ecto.gen.repo. If we name our repo OurCustom.Repo, this task will create it here lib/our_custom/repo.ex. $ mix ecto.gen.repo -r OurCustom.Repo * creating lib/our_custom * creating lib/our_custom/repo.ex * updating config/config.exs Don&#39;t forget to add your new repo to your supervision tree (typically in lib/hello.ex): worker(OurCustom.Repo, []) Notice that this task has updated config/config.exs. If we take a look, we&#39;ll see this extra configuration block for our new repo. . . . config :hello, OurCustom.Repo, database: &quot;hello_repo&quot;, username: &quot;user&quot;, password: &quot;pass&quot;, hostname: &quot;localhost&quot; . . . Of course, we&#39;ll need to change the login credentials to match what our database expects. We&#39;ll also need to change the config for other environments. We certainly should follow the instructions and add our new repo to our supervision tree. In our Hello application, we would open up lib/hello.ex, and add our repo as a worker to the children list. . . . children = [ # Start the Ecto repository Hello.Repo, # Start the endpoint when the application starts HelloWeb.Endpoint, # Starts a worker by calling: Hello.Worker.start_link(arg) # {Hello.Worker, arg}, # Here you could define other workers and supervisors as children OurCustom.Repo ] . . . mix ecto.gen.migration Migrations are a programmatic, repeatable way to affect changes to a database schema. Migrations are also just modules, and we can create them with the ecto.gen.migration task. Let&#39;s walk through the steps to create a migration for a new comments table. We simply need to invoke the task with a snake_case version of the module name that we want. Preferably, the name will describe what we want the migration to do. mix ecto.gen.migration add_comments_table * creating priv/repo/migrations * creating priv/repo/migrations/20150318001628_add_comments_table.exs Notice that the migration&#39;s filename begins with a string representation of the date and time the file was created. Let&#39;s take a look at the file ecto.gen.migration has generated for us at priv/repo/migrations/20150318001628_add_comments_table.exs. defmodule Hello.Repo.Migrations.AddCommentsTable do use Ecto.Migration def change do end end Notice that there is a single function change/0 which will handle both forward migrations and rollbacks. We&#39;ll define the schema changes that we want using ecto&#39;s handy dsl, and ecto will figure out what to do depending on whether we are rolling forward or rolling back. Very nice indeed. What we want to do is create a comments table with a body column, a word_count column, and timestamp columns for inserted_at and updated_at. . . . def change do create table(:comments) do add :body, :string add :word_count, :integer timestamps() end end . . . Again, we can run this task with the -r flag and another repo if we need to. $ mix ecto.gen.migration -r OurCustom.Repo add_users * creating priv/repo/migrations * creating priv/repo/migrations/20150318172927_add_users.exs For more information on how to modify your database schema please refer to the ecto&#39;s migration dsl ecto migration docs. For example, to alter an existing schema see the documentation on ecto’s alter/2 function. That&#39;s it! We&#39;re ready to run our migration. mix ecto.migrate Once we have our migration module ready, we can simply run mix ecto.migrate to have our changes applied to the database. $ mix ecto.migrate [info] == Running Hello.Repo.Migrations.AddCommentsTable.change/0 forward [info] create table comments [info] == Migrated in 0.1s When we first run ecto.migrate, it will create a table for us called schema_migrations. This will keep track of all the migrations which we run by storing the timestamp portion of the migration&#39;s filename. Here&#39;s what the schema_migrations table looks like. hello_dev=# select * from schema_migrations; version | inserted_at ----------------+--------------------- 20150317170448 | 2015-03-17 21:07:26 20150318001628 | 2015-03-18 01:45:00 (2 rows) When we roll back a migration, ecto.rollback will remove the record representing this migration from schema_migrations. By default, ecto.migrate will execute all pending migrations. We can exercise more control over which migrations we run by specifying some options when we run the task. We can specify the number of pending migrations we would like to run with the -n or --step options. $ mix ecto.migrate -n 2 [info] == Running Hello.Repo.Migrations.CreatePost.change/0 forward [info] create table posts [info] == Migrated in 0.0s [info] == Running Hello.Repo.Migrations.AddCommentsTable.change/0 forward [info] create table comments [info] == Migrated in 0.0s The --step option will behave the same way. mix ecto.migrate --step 2 We can also specify an individual migration we would like to run with the -v option. mix ecto.migrate -v 20150317170448 The --to option will behave the same way. mix ecto.migrate --to 20150317170448 mix ecto.rollback The ecto.rollback task will reverse the last migration we have run, undoing the schema changes. ecto.migrate and ecto.rollback are mirror images of each other. $ mix ecto.rollback [info] == Running Hello.Repo.Migrations.AddCommentsTable.change/0 backward [info] drop table comments [info] == Migrated in 0.0s ecto.rollback will handle the same options as ecto.migrate, so -n, --step, -v, and --to will behave as they do for ecto.migrate."},{"ref":"phoenix_mix_tasks.html#creating-our-own-mix-tasks","title":"Mix Tasks - Creating Our Own Mix Tasks","type":"extras","doc":"As we&#39;ve seen throughout this guide, both mix itself and the dependencies we bring in to our application provide a number of really useful tasks for free. Since neither of these could possibly anticipate all our individual application&#39;s needs, mix allows us to create our own custom tasks. That&#39;s exactly what we are going to do now. The first thing we need to do is create a mix/tasks directory inside of lib. This is where any of our application specific mix tasks will go. $ mkdir -p lib/mix/tasks Inside that directory, let&#39;s create a new file, hello.greeting.ex, that looks like this. defmodule Mix.Tasks.Hello.Greeting do use Mix.Task @shortdoc &quot;Sends a greeting to us from Hello Phoenix&quot; @moduledoc &quot;&quot;&quot; This is where we would put any long form documentation or doctests. &quot;&quot;&quot; def run(_args) do Mix.shell().info(&quot;Greetings from the Hello Phoenix Application!&quot;) end # We can define other functions as needed here. end Let&#39;s take a quick look at the moving parts involved in a working mix task. The first thing we need to do is name our module. In order to properly namespace it, we begin with Mix.Tasks. We&#39;d like to invoke this as mix hello.greeting, so we complete the module name with Hello.Greeting. The use Mix.Task line clearly brings in functionality from mix that makes this module behave as a mix task. The @shortdoc module attribute holds a string which will describe our task when users invoke mix help. @moduledoc serves the same function that it does in any module. It&#39;s where we can put long-form documentation and doctests, if we have any. The run/1 function is the critical heart of any mix task. It&#39;s the function that does all the work when users invoke our task. In ours, all we do is send a greeting from our app, but we can implement our run/1 function to do whatever we need it to. Note that Mix.shell().info/1 is the preferred way to print text back out to the user. Of course, our task is just a module, so we can define other private functions as needed to support our run/1 function. Now that we have our task module defined, our next step is to compile the application. $ mix compile Compiled lib/tasks/hello.greeting.ex Generated hello.app Now our new task should be visible to mix help. $ mix help | grep hello mix hello.greeting # Sends a greeting to us from Hello Phoenix Notice that mix help displays the text we put into the @shortdoc along with the name of our task. So far, so good, but does it work? $ mix hello.greeting Greetings from the Hello Phoenix Application! Indeed it does. If you want to make your new mix task to use your application&#39;s infrastructure, you need to make sure the application is started when mix task is being executed. This is particularly useful if you need to access your database from within the mix task. Thankfully, mix makes it really easy for us: . . . def run(_args) do Mix.Task.run(&quot;app.start&quot;) Mix.shell().info(&quot;Now I have access to Repo and other goodies!&quot;) end . . ."},{"ref":"errors.html","title":"Custom Errors","type":"extras","doc":"Custom Errors Phoenix provides an ErrorView, lib/hello_web/views/error_view.ex, to render errors in our applications. The full module name will include the name of our application, as in Hello.ErrorView. Phoenix will detect any 400 or 500 status level errors in our application and use the render/2 function in our ErrorView to render an appropriate error template. Any errors which don&#39;t match an existing clause of render/2 will be caught by template_not_found/2. We can also customize the implementation of any of these functions however we like. Here&#39;s what the ErrorView looks like. defmodule Hello.ErrorView do use Hello.Web, :view # If you want to customize a particular status code # for a certain format, you may uncomment below. # def render(&quot;500.html&quot;, _assigns) do # &quot;Internal Server Error&quot; # end # By default, Phoenix returns the status message from # the template name. For example, &quot;404.html&quot; becomes # &quot;Not Found&quot;. def template_not_found(template, _assigns) do Phoenix.Controller.status_message_from_template(template) end end NOTE: In the development environment, this behavior will be overridden. Instead, we will get a really great debugging page. In order to see the ErrorView in action, we&#39;ll need to set debug_errors: to false in config/dev.exs. The server must be restarted for the changes to become effective. config :hello, HelloWeb.Endpoint, http: [port: 4000], debug_errors: false, code_reloader: true, cache_static_lookup: false, watchers: [node: [&quot;node_modules/webpack/bin/webpack.js&quot;, &quot;--mode&quot;, &quot;development&quot;, &quot;--watch-stdin&quot;, cd: Path.expand(&quot;../assets&quot;, __DIR__)]] To learn more about custom error pages, please see The Error View section of the View Guide. Custom Errors Elixir provides a macro called defexception for defining custom exceptions. Exceptions are represented as structs, and structs need to be defined inside of modules. In order to create a custom error, we need to define a new module. Conventionally this will have &quot;Error&quot; in the name. Inside of that module, we need to define a new exception with defexception. We can also define a module within a module to provide a namespace for the inner module. Here&#39;s an example from the Phoenix.Router which demonstrates all of these ideas. defmodule Phoenix.Router do defmodule NoRouteError do @moduledoc &quot;&quot;&quot; Exception raised when no route is found. &quot;&quot;&quot; defexception plug_status: 404, message: &quot;no route found&quot;, conn: nil, router: nil def exception(opts) do conn = Keyword.fetch!(opts, :conn) router = Keyword.fetch!(opts, :router) path = &quot;/&quot; &lt;&gt; Enum.join(conn.path_info, &quot;/&quot;) %NoRouteError{message: &quot;no route found for \#{conn.method} \#{path} (\#{inspect router})&quot;, conn: conn, router: router} end end . . . end Plug provides a protocol called Plug.Exception specifically for adding a status to exception structs. If we wanted to supply a status of 404 for an Ecto.NoResultsError, we could do it by defining an implementation for the Plug.Exception protocol like this: defimpl Plug.Exception, for: Ecto.NoResultsError do def status(_exception), do: 404 end Note that this is just an example: Phoenix already does this for Ecto.NoResultsError, so you don&#39;t have to."},{"ref":"testing.html","title":"Introduction to Testing","type":"extras","doc":"Introduction to Testing Note: the Testing guides have not been fully updated to Phoenix 1.3; they&#39;re a work in progress and more content is coming. Testing has become integral to the software development process, and the ability to easily write meaningful tests is an indispensable feature for any modern web framework. Phoenix takes this seriously, providing support files to make all the major components of the framework easy to test. It also generates test modules with real-world examples alongside any generated modules to help get us going. Elixir ships with a built-in testing framework called ExUnit. ExUnit strives to be clear and explicit, keeping magic to a minimum. Phoenix uses ExUnit for all of its testing, and we will use it here as well. ExUnit refers to a test module as a &quot;test case&quot;, and we will do the same. Let&#39;s see this in action. Note: Before we proceed, we&#39;ll need to have PostgreSQL installed and running on our system. We&#39;ll also need to configure our repo with the correct login credentials. The section on ecto.create in the Mix Tasks guide has more information on this, and the Ecto Guide dives into the details on how it all works. In a freshly generated application (we use a project named &quot;hello&quot; in the examples), let&#39;s run mix test at the root of the project. (Please see the Up and Running Guide for instructions on generating a new application.) $ mix test .... Finished in 0.09 seconds 3 tests, 0 failures Randomized with seed 652656 We already have three tests! In fact, we already have a directory structure completely set up for testing, including a test helper and support files. Note: We didn&#39;t need to create or migrate our test database because the test helper took care of all that for us. test ├── hello_web │   ├── channels │   ├── controllers │   │   └── page_controller_test.exs │   └── views │   ├── error_view_test.exs │   ├── layout_view_test.exs │   └── page_view_test.exs ├── support │   ├── channel_case.ex │   ├── conn_case.ex │   └── data_case.ex └── test_helper.exs The test cases we get for free include test/hello_web/controllers/page_controller_test.exs, test/hello_web/views/error_view_test.exs, and test/hello_web/views/page_view_test.exs. Nice. We&#39;re going to look at test cases in detail throughout the testing guides, but let&#39;s take a quick look at these three, just to get our feet wet. The first test case we&#39;ll look at is test/hello_web/controllers/page_controller_test.exs. defmodule HelloWeb.PageControllerTest do use HelloWeb.ConnCase test &quot;GET /&quot;, %{conn: conn} do conn = get(conn, &quot;/&quot;) assert html_response(conn, 200) =~ &quot;Welcome to Phoenix!&quot; end end There are a couple of interesting things happening here. The get/2 function gives us a connection struct set up as if it had been used for a get request to &quot;/&quot;. This saves us a considerable amount of tedious setup. The assertion actually tests three things - that we got an HTML response (by checking for a content-type of &quot;text/html&quot;), that our response code was 200, and that the body of our response contains the string &quot;Welcome to Phoenix!&quot; The error view test case, test/hello_web/views/error_view_test.exs, illustrates a few interesting things of its own. defmodule HelloWeb.ErrorViewTest do use HelloWeb.ConnCase, async: true # Bring render/3 and render_to_string/3 for testing custom views import Phoenix.View test &quot;renders 404.html&quot; do assert render_to_string(HelloWeb.ErrorView, &quot;404.html&quot;, []) == &quot;Not Found&quot; end test &quot;renders 500.html&quot; do assert render_to_string(HelloWeb.ErrorView, &quot;500.html&quot;, []) == &quot;Internal Server Error&quot; end end HelloWeb.ErrorViewTest sets async: true which means that this test case will be run in parallel with other test cases. While individual tests within the case still run serially, this can greatly increase overall test speeds. It is possible to encounter strange behavior with asynchronous tests, but thanks to the Ecto.Adapters.SQL.Sandbox, async tests involving a database can be done without worry. This means that the vast majority of tests in your Phoenix application will be able to be run asynchronously. It also imports Phoenix.View in order to use the render_to_string/3 function. With that, all the assertions can be simple string equality tests. The page view case, test/hello_web/views/page_view_test.exs, does not contain any tests by default, but it is here for us when we need to add functions to our HelloWeb.PageView module. defmodule HelloWeb.PageViewTest do use HelloWeb.ConnCase, async: true end Let&#39;s also take a look at the support and helper files Phoenix provides us. The default test helper file, test/test_helper.exs, creates and migrates our test database for us. It also starts a transaction for each test to run in. This will &quot;clean&quot; the database by rolling back the transaction as each test completes. The test helper can also hold any testing-specific configuration our application might need. ExUnit.start Ecto.Adapters.SQL.Sandbox.mode(Hello.Repo, :manual) The files in test/support are there to help us get our modules into a testable state. They provide convenience functions for tasks like setting up a connection struct and finding errors on an Ecto changeset. We&#39;ll take a closer look at them in action throughout the rest of the testing guides. Running Tests Now that we have an idea what our tests are doing, let&#39;s look at different ways to run them. As we saw near the beginning of this guide, we can run our entire suite of tests with mix test. $ mix test .... Finished in 0.2 seconds 3 tests, 0 failures Randomized with seed 540755 If we would like to run all the tests in a given directory, test/hello_web/controllers for instance, we can pass the path to that directory to mix test. $ mix test test/hello_web/controllers/ . Finished in 0.2 seconds 1 tests, 0 failures Randomized with seed 652376 In order to run all the tests in a specific file, we can pass the path to that file into mix test. $ mix test test/hello_web/views/error_view_test.exs ... Finished in 0.2 seconds 2 tests, 0 failures Randomized with seed 220535 And we can run a single test in a file by appending a colon and a line number to the filename. Let&#39;s say we only wanted to run the test for the way HelloWeb.ErrorView renders 500.html. The test begins on line 12 of the file, so this is how we would do it. $ mix test test/hello_web/views/error_view_test.exs:11 Including tags: [line: &quot;11&quot;] Excluding tags: [:test] . Finished in 0.1 seconds 2 tests, 0 failures, 1 excluded Randomized with seed 288117 We chose to run this specifying the first line of the test, but actually, any line of that test will do. These line numbers would all work - :11, :12, or :13. Running Tests Using Tags ExUnit allows us to tag our tests at the case level or on the individual test level. We can then choose to run only the tests with a specific tag, or we can exclude tests with that tag and run everything else. Let&#39;s experiment with how this works. First, we&#39;ll add a @moduletag to test/hello_web/views/error_view_test.exs. defmodule HelloWeb.ErrorViewTest do use HelloWeb.ConnCase, async: true @moduletag :error_view_case ... end If we use only an atom for our module tag, ExUnit assumes that it has a value of true. We could also specify a different value if we wanted. defmodule HelloWeb.ErrorViewTest do use HelloWeb.ConnCase, async: true @moduletag error_view_case: &quot;some_interesting_value&quot; ... end For now, let&#39;s leave it as a simple atom @moduletag :error_view_case. We can run only the tests from the error view case by passing --only error_view_case into mix test. $ mix test --only error_view_case Including tags: [:error_view_case] Excluding tags: [:test] ... Finished in 0.1 seconds 3 tests, 0 failures, 1 excluded Randomized with seed 125659 Note: ExUnit tells us exactly which tags it is including and excluding for each test run. If we look back to the previous section on running tests, we&#39;ll see that line numbers specified for individual tests are actually treated as tags. $ mix test test/hello_web/views/error_view_test.exs:11 Including tags: [line: &quot;11&quot;] Excluding tags: [:test] . Finished in 0.2 seconds 2 tests, 0 failures, 1 excluded Randomized with seed 364723 Specifying a value of true for error_view_case yields the same results. $ mix test --only error_view_case:true Including tags: [error_view_case: &quot;true&quot;] Excluding tags: [:test] ... Finished in 0.1 seconds 3 tests, 0 failures, 1 excluded Randomized with seed 833356 Specifying false as the value for error_view_case, however, will not run any tests because no tags in our system match error_view_case: false. $ mix test --only error_view_case:false Including tags: [error_view_case: &quot;false&quot;] Excluding tags: [:test] Finished in 0.1 seconds 3 tests, 0 failures, 3 excluded Randomized with seed 622422 The --only option was given to &quot;mix test&quot; but no test executed We can use the --exclude flag in a similar way. This will run all of the tests except those in the error view case. $ mix test --exclude error_view_case Excluding tags: [:error_view_case] . Finished in 0.2 seconds 3 tests, 0 failures, 2 excluded Randomized with seed 682868 Specifying values for a tag works the same way for --exclude as it does for --only. We can tag individual tests as well as full test cases. Let&#39;s tag a few tests in the error view case to see how this works. defmodule HelloWeb.ErrorViewTest do use HelloWeb.ConnCase, async: true @moduletag :error_view_case # Bring render/3 and render_to_string/3 for testing custom views import Phoenix.View @tag individual_test: &quot;yup&quot; test &quot;renders 404.html&quot; do assert render_to_string(HelloWeb.ErrorView, &quot;404.html&quot;, []) == &quot;Not Found&quot; end @tag individual_test: &quot;nope&quot; test &quot;renders 500.html&quot; do assert render_to_string(HelloWeb.ErrorView, &quot;500.html&quot;, []) == &quot;Internal Server Error&quot; end end If we would like to run only tests tagged as individual_test, regardless of their value, this will work. $ mix test --only individual_test Including tags: [:individual_test] Excluding tags: [:test] .. Finished in 0.1 seconds 3 tests, 0 failures, 1 excluded Randomized with seed 813729 We can also specify a value and run only tests with that. $ mix test --only individual_test:yup Including tags: [individual_test: &quot;yup&quot;] Excluding tags: [:test] . Finished in 0.1 seconds 3 tests, 0 failures, 2 excluded Randomized with seed 770938 Similarly, we can run all tests except for those tagged with a given value. $ mix test --exclude individual_test:nope Excluding tags: [individual_test: &quot;nope&quot;] ... Finished in 0.2 seconds 3 tests, 0 failures, 1 excluded Randomized with seed 539324 We can be more specific and exclude all the tests from the error view case except the one tagged with individual_test that has the value &quot;yup&quot;. $ mix test --exclude error_view_case --include individual_test:yup Including tags: [individual_test: &quot;yup&quot;] Excluding tags: [:error_view_case] .. Finished in 0.2 seconds 3 tests, 0 failures, 1 excluded Randomized with seed 61472 Finally, we can configure ExUnit to exclude tags by default. Let&#39;s configure it to always exclude tests with the error_view_case tag in test/test_helper.exs. ExUnit.start Ecto.Adapters.SQL.Sandbox.mode(Hello.Repo, :manual) ExUnit.configure(exclude: [error_view_case: true]) Now when we run mix test, it only runs one spec from our page_controller_test.exs. $ mix test Excluding tags: [error_view_case: true] . Finished in 0.2 seconds 3 tests, 0 failures, 2 excluded Randomized with seed 186055 We can override this behavior with the --include flag, telling mix test to include tests tagged with error_view_case. $ mix test --include error_view_case Including tags: [:error_view_case] Excluding tags: [error_view_case: true] .... Finished in 0.2 seconds 3 tests, 0 failures Randomized with seed 748424 Randomization Running tests in random order is a good way to ensure that our tests are truly isolated. If we notice that we get sporadic failures for a given test, it may be because a previous test changes the state of the system in ways that aren&#39;t cleaned up afterward, thereby affecting the tests which follow. Those failures might only present themselves if the tests are run in a specific order. ExUnit will randomize the order tests run in by default, using an integer to seed the randomization. If we notice that a specific random seed triggers our intermittent failure, we can re-run the tests with that same seed to reliably recreate that test sequence in order to help us figure out what the problem is. $ mix test --seed 401472 .... Finished in 0.2 seconds 3 tests, 0 failures Randomized with seed 401472 Generating More Files We&#39;ve seen what Phoenix gives us with a newly generated app. Now let&#39;s see what happens when we generate a new HTML resource. Let&#39;s borrow the users resource we created in the Ecto Guide. At the root of our new application, let&#39;s run the mix phx.gen.html task with the following options. $ mix phx.gen.html Users User users name:string email:string bio:string number_of_pets:integer * creating lib/hello_web/controllers/user_controller.ex * creating lib/hello_web/templates/user/edit.html.eex * creating lib/hello_web/templates/user/form.html.eex * creating lib/hello_web/templates/user/index.html.eex * creating lib/hello_web/templates/user/new.html.eex * creating lib/hello_web/templates/user/show.html.eex * creating lib/hello_web/views/user_view.ex * creating test/hello_web/controllers/user_controller_test.exs * creating lib/hello/users/user.ex * creating priv/repo/migrations/20180904210841_create_users.exs * creating lib/hello/users.ex * injecting lib/hello/users.ex * creating test/hello/users/users_test.exs * injecting test/hello/users/users_test.exs Add the resource to your browser scope in lib/hello_web/router.ex: resources &quot;/users&quot;, UserController Remember to update your repository by running migrations: $ mix ecto.migrate Now let&#39;s follow the directions and add the new resources route to our lib/hello_web/router.ex file. defmodule HelloWeb.Router do use HelloWeb, :router ... scope &quot;/&quot;, Hello do pipe_through :browser get &quot;/&quot;, PageController, :index resources &quot;/users&quot;, UserController end # Other scopes may use custom stacks. # scope &quot;/api&quot;, Hello do # pipe_through :api # end end When we run mix test again, we see that we already have twenty tests! $ mix test ................ Finished in 0.1 seconds 19 tests, 0 failures Randomized with seed 537537 At this point, we are at a great place to transition to the rest of the testing guides, in which we&#39;ll examine these tests in much more detail, and add some of our own."},{"ref":"testing_schemas.html","title":"Testing Schemas","type":"extras","doc":"Testing Schemas In the Ecto Guide we generated an HTML resource for users. This gave us a number of modules for free, including a user schema and a user schema test case. In this guide, we&#39;ll use the schema and test case to work through the changes we made in the Ecto Guide in a test-driven way. For those of us who haven&#39;t worked through the Ecto Guide, it&#39;s easy to catch up. Please see the &quot;Generating an HTML Resource&quot; section below. Before we do anything else, let&#39;s run mix test to make sure our test suite runs cleanly. $ mix test ................ Finished in 0.6 seconds 19 tests, 0 failures Randomized with seed 638414 Great. We&#39;ve got nineteen tests and they are all passing!"},{"ref":"testing_schemas.html#test-driving-a-changeset","title":"Testing Schemas - Test Driving a Changeset","type":"extras","doc":"We&#39;ll be adding additional validations to the schema module, so let&#39;s open the generated test/hello/accounts/accounts_test.exs and take a look: defmodule Hello.AccountsTest do use Hello.DataCase alias Hello.Accounts describe &quot;users&quot; do alias Hello.Accounts.User @valid_attrs %{bio: &quot;some bio&quot;, email: &quot;some email&quot;, name: &quot;some name&quot;, number_of_pets: 42} @update_attrs %{bio: &quot;some updated bio&quot;, email: &quot;some updated email&quot;, name: &quot;some updated name&quot;, number_of_pets: 43} @invalid_attrs %{bio: nil, email: nil, name: nil, number_of_pets: nil} # ... test &quot;create_user/1 with valid data creates a user&quot; do assert {:ok, %User{} = user} = Accounts.create_user(@valid_attrs) assert user.bio == &quot;some bio&quot; assert user.email == &quot;some email&quot; assert user.name == &quot;some name&quot; assert user.number_of_pets == 42 end test &quot;create_user/1 with invalid data returns error changeset&quot; do assert {:error, %Ecto.Changeset{}} = Accounts.create_user(@invalid_attrs) end # ... end end In the first line, we use Hello.DataCase, which is defined in test/support/data_case.ex. Hello.DataCase is responsible for importing and aliasing all the necessary modules for all of our schema cases. Hello.DataCase will also run all of our schema tests within the SQL sandbox, which will revert any changes to the database at the end of the test. If you are using PostgreSQL, you can even run database tests asynchronously by setting use Hello.DataCase, async: true, although this option is not recommended for other databases. Hello.DataCase is also a place to define any helper functions we might need to test our schemas. We get an example function errors_on/1 for free, and we&#39;ll see how that works shortly. We alias our Hello.Accounts.User module so that we can refer to its structs as %User{} instead of %Hello.Accounts.User{}. We also define module attributes for @valid_attrs and @invalid_attrs so they will be available to all our tests. Number of Pets While Phoenix generated our model with all of the fields required, the number of pets a user has is optional in our domain. Let&#39;s write a new test to verify that. To test this, we can delete the :number_of_pets key and value from the @valid_attrs map and make a User changeset from those new attributes. Then we can assert that the changeset is still valid. defmodule Hello.AccountsTest do ... test &quot;number_of_pets is not required&quot; do changeset = User.changeset(%User{}, Map.delete(@valid_attrs, :number_of_pets)) assert changeset.valid? end end Now, let&#39;s run the tests again. $ mix test .................... 1) test number_of_pets is not required (Hello.AccountsTest) test/hello/accounts/accounts_test.exs:19 Expected truthy, got false code: assert changeset.valid?() stacktrace: test/hello/accounts/accounts_test.exs:21: (test) .. Finished in 0.4 seconds 20 tests, 1 failure Randomized with seed 780208 It fails - which is exactly what it should do! We haven&#39;t written the code to make it pass yet. To do that, we need to remove the :number_of_pets attribute from our validate_required/3 function in lib/hello_web/accounts/user.ex. defmodule Hello.Accounts.User do ... def changeset(%User{} = user, attrs) do user |&gt; cast(attrs, [:name, :email, :bio, :number_of_pets]) |&gt; validate_required([:name, :email, :bio]) end end Now our tests are all passing again. $ mix test ....................... Finished in 0.3 seconds 20 tests, 0 failures Randomized with seed 963040 The Bio Attribute In the Ecto Guide, we learned that the user&#39;s :bio attribute has two business requirements. The first is that it must be at least two characters long. Let&#39;s write a test for that using the same pattern we&#39;ve just used. First, we change the :bio attribute to have a value of a single character. Then we create a changeset with the new attributes and test its validity. defmodule Hello.AccountsTest do ... test &quot;bio must be at least two characters long&quot; do attrs = %{@valid_attrs | bio: &quot;I&quot;} changeset = User.changeset(%User{}, attrs) refute changeset.valid? end end When we run the test, it fails, as we would expect. $ mix test ................... 1) test bio must be at least two characters long (Hello.AccountsTest) test/hello/accounts/accounts_test.exs:24 Expected false or nil, got true code: refute changeset.valid?() stacktrace: test/hello/accounts/accounts_test.exs:27: (test) .... Finished in 0.3 seconds 21 tests, 1 failure Randomized with seed 327779 Hmmm. Yes, this test behaved as we expected, but the error message doesn&#39;t seem to reflect our test. We&#39;re validating the length of the :bio attribute, and the message we get is &quot;Expected false or nil, got true&quot;. There&#39;s no mention of our :bio attribute at all. We can do better. Let&#39;s change our test to get a better message while still testing the same behavior. We can leave the code to set the new :bio value in place. In the assert, however, we&#39;ll use the errors_on/1 function we get from DataCase to generate a map of errors, and check that the :bio attribute error is in that map. defmodule Hello.AccountsTest do ... test &quot;bio must be at least two characters long&quot; do attrs = %{@valid_attrs | bio: &quot;I&quot;} changeset = User.changeset(%User{}, attrs) assert %{bio: [&quot;should be at least 2 character(s)&quot;]} = errors_on(changeset) end end When we run the tests again, we get a different message entirely. $ mix test ................... 1) test bio must be at least two characters long (Hello.AccountsTest) test/hello/accounts/accounts_test.exs:24 match (=) failed code: assert %{bio: [&quot;should be at least 2 character(s)&quot;]} = errors_on(changeset) right: %{} stacktrace: test/hello/accounts/accounts_test.exs:27: (test) .... Finished in 0.4 seconds 21 tests, 1 failure Randomized with seed 435902 This shows us the assertion we are testing - that our error is in the map of errors from the model&#39;s changeset. code: assert %{bio: [&quot;should be at least 2 character(s)&quot;]} = errors_on(changeset) And we see that the right hand side of the expression evaluates to an empty map. rhs: %{} That map is empty because we don&#39;t yet validate the minimum length of the :bio attribute. Our test has pointed the way. Now let&#39;s make it pass by adding that validation. defmodule Hello.Accounts.User do ... def changeset(%User{} = user, attrs) do user |&gt; cast(attrs, [:name, :email, :bio, :number_of_pets]) |&gt; validate_required([:name, :email, :bio]) |&gt; validate_length(:bio, min: 2) end end When we run the tests again, they all pass. $ mix test ........................ Finished in 0.2 seconds 21 tests, 0 failures Randomized with seed 305958 The other business requirement for the :bio field is that it be a maximum of one hundred and forty characters. Let&#39;s write a test for that using the errors_on/1 function again. We&#39;ll use String.duplicate/2 to produce n-long &quot;a&quot; string here. defmodule Hello.AccountsTest do ... test &quot;bio must be at most 140 characters long&quot; do attrs = %{@valid_attrs | bio: String.duplicate(&quot;a&quot;, 141)} changeset = User.changeset(%User{}, attrs) assert %{bio: [&quot;should be at most 140 character(s)&quot;]} = errors_on(changeset) end end When we run the test, it fails as we want it to. $ mix test ....................... 1) test bio must be at most 140 characters long (Hello.AccountsTest) test/hello/accounts/accounts_test.exs:30 match (=) failed code: assert %{bio: [&quot;should be at most 140 character(s)&quot;]} = errors_on(changeset) right: %{} stacktrace: test/hello/accounts/accounts_test.exs:33: (test) . Finished in 0.3 seconds 22 tests, 1 failure Randomized with seed 593838 To make this test pass, we need to add a maximum to the length validation of the :bio attribute. defmodule Hello.Accounts.User do ... def changeset(%User{} = user, attrs) do user |&gt; cast(attrs, [:name, :email, :bio, :number_of_pets]) |&gt; validate_required([:name, :email, :bio]) |&gt; validate_length(:bio, min: 2, max: 140) end end When we run the tests, they all pass. $ mix test ......................... Finished in 0.4 seconds 22 tests, 0 failures Randomized with seed 468975 The Email Attribute We have one last attribute to validate. Currently, :email is just a string like any other. We&#39;d like to make sure that it at least matches an &quot;@&quot;. This is no substitute for an email confirmation, but it will weed out some invalid addresses before we even try. This process will feel familiar by now. First, we change the value of the :email attribute to omit the &quot;@&quot;. Then we write an assertion which uses errors_on/1 to check for the correct validation error on the :email attribute. defmodule Hello.AccountsTest do ... test &quot;email must contain at least an @&quot; do attrs = %{@valid_attrs | email: &quot;fooexample.com&quot;} changeset = User.changeset(%User{}, attrs) assert %{email: [&quot;has invalid format&quot;]} = errors_on(changeset) end end When we run the tests, it fails. We see that we&#39;re getting an empty map of errors back from errors_on/1. $ mix test ....................... 1) test email must contain at least an @ (Hello.AccountsTest) test/hello/accounts/accounts_test.exs:36 match (=) failed code: assert %{email: [&quot;has invalid format&quot;]} = errors_on(changeset) right: %{} stacktrace: test/hello/accounts/accounts_test.exs:39: (test) .. Finished in 0.4 seconds 23 tests, 1 failure Randomized with seed 962127 Then we add the new validation to generate the error our test is looking for. defmodule Hello.Accounts.User do ... def changeset(%User{} = user, attrs) do user |&gt; cast(attrs, [:name, :email, :bio, :number_of_pets]) |&gt; validate_required([:name, :email, :bio]) |&gt; validate_length(:bio, min: 2, max: 140) |&gt; validate_format(:email, ~r/@/) end end Now the schema tests are passing again, but other tests are now failing, if you haven&#39;t touched the generated context &amp; controller tests. Here&#39;s one failure (but because tests are run in random order, you might see a different failure first): $ mix test .... 1) test update user renders errors when data is invalid (HelloWeb.UserControllerTest) test/hello_web/controllers/user_controller_test.exs:66 ** (MatchError) no match of right hand side value: {:error, #Ecto.Changeset&lt;action: :insert, changes: %{bio: &quot;some bio&quot;, email: &quot;some email&quot;, name: &quot;some name&quot;, number_of_pets: 42}, errors: [email: {&quot;has invalid format&quot;, [validation: :format]}], data: #Hello.Accounts.User&lt;&gt;, valid?: false&gt;} stacktrace: test/hello_web/controllers/user_controller_test.exs:11: HelloWeb.UserControllerTest.fixture/1 test/hello_web/controllers/user_controller_test.exs:85: HelloWeb.UserControllerTest.create_user/1 test/hello_web/controllers/user_controller_test.exs:1: HelloWeb.UserControllerTest.__ex_unit__/2 ... Finished in 0.1 seconds 26 tests, 12 failures Randomized with seed 825065 We can fix these tests by editing the module attributes in the failing test files - first, in test/hello_web/controllers/user_controller_test.exs, add an &quot;@&quot; to the :email values in @valid_attrs and @update_attrs: defmodule HelloWeb.UserControllerTest do ... @create_attrs %{bio: &quot;some bio&quot;, email: &quot;some@email&quot;, name: &quot;some name&quot;, number_of_pets: 42} @update_attrs %{bio: &quot;some updated bio&quot;, email: &quot;some updated@email&quot;, name: &quot;some updated name&quot;, number_of_pets: 43} @invalid_attrs %{bio: nil, email: nil, name: nil, number_of_pets: nil} ... This will fix all of the HelloWeb.UserControllerTest failures. Make the same changes to the module attributes in test/hello/accounts/accounts_test.exs: defmodule Hello.AccountsTest do ... @valid_attrs %{bio: &quot;some bio&quot;, email: &quot;some@email&quot;, name: &quot;some name&quot;, number_of_pets: 42} @update_attrs %{bio: &quot;some updated bio&quot;, email: &quot;updated@email&quot;, name: &quot;some updated name&quot;, number_of_pets: 43} @invalid_attrs %{bio: nil, email: nil, name: nil, number_of_pets: nil} ... This will fix all but two of the failures - to fix those last two, we&#39;ll need to fix the values those tests are comparing: defmodule Hello.AccountsTest do ... test &quot;create_user/1 with valid data creates a user&quot; do assert {:ok, %User{} = user} = Accounts.create_user(@valid_attrs) assert user.bio == &quot;some bio&quot; assert user.email == &quot;some@email&quot; assert user.name == &quot;some name&quot; assert user.number_of_pets == 42 end ... test &quot;update_user/2 with valid data updates the user&quot; do user = user_fixture() assert {:ok, user} = Accounts.update_user(user, @update_attrs) assert %User{} = user assert user.bio == &quot;some updated bio&quot; assert user.email == &quot;some updated@email&quot; assert user.name == &quot;some updated name&quot; assert user.number_of_pets == 43 end end Now all the tests pass again: $ mix test .......................... Finished in 0.2 seconds 23 tests, 0 failures Randomized with seed 330955 Generating an HTML Resource For this section, we&#39;re going to assume that we all have a PostgreSQL database installed on our system, and that we generated a default application - one in which Ecto and Postgrex are installed and configured automatically. If this is not the case, please see the section on adding Ecto and Postgrex of the Ecto Guide and join us when that&#39;s done. Ok, once we&#39;re all configured properly, we need to run the phx.gen.html task with the list of attributes we have here. $ mix phx.gen.html Accounts User users name:string email:string \\ bio:string number_of_pets:integer * creating lib/hello_web/controllers/user_controller.ex * creating lib/hello_web/templates/user/edit.html.eex * creating lib/hello_web/templates/user/form.html.eex * creating lib/hello_web/templates/user/index.html.eex * creating lib/hello_web/templates/user/new.html.eex * creating lib/hello_web/templates/user/show.html.eex * creating lib/hello_web/views/user_view.ex * creating test/hello_web/controllers/user_controller_test.exs * creating lib/hello/accounts/user.ex * creating priv/repo/migrations/20180906212909_create_users.exs * creating lib/hello/accounts.ex * injecting lib/hello/accounts.ex * creating test/hello/accounts/accounts_test.exs * injecting test/hello/accounts/accounts_test.exs Add the resource to your browser scope in web/router.ex: resources &quot;/users&quot;, UserController Remember to update your repository by running migrations: $ mix ecto.migrate Then we need to follow the instructions the task gives us and insert the resources &quot;/users&quot;, UserController line in the router lib/hello_web/router.ex. defmodule HelloWeb.Router do ... scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index resources &quot;/users&quot;, UserController end # Other scopes may use custom stacks. # scope &quot;/api&quot;, HelloWeb do # pipe_through :api # end end With that done, we can create our database with ecto.create. $ mix ecto.create The database for Hello.Repo has been created. Then we can migrate our database to create our users table with ecto.migrate. $ mix ecto.migrate [info] == Running Hello.Repo.Migrations.CreateUser.change/0 forward [info] create table users [info] == Migrated in 0.0s With that, we are ready to continue with the testing guide."},{"ref":"testing_controllers.html","title":"Testing Controllers","type":"extras","doc":"Testing Controllers We&#39;re going to take a look at how we might test drive a controller which has endpoints for a JSON api. Phoenix has a generator for creating a JSON resource which looks like this: $ mix phx.gen.json AllTheThings Thing things some_attr:string another_attr:string In this command, AllTheThings is the context; Thing is the schema; things is the plural name of the schema (which is used as the table name). Then some_attr and another_attr are the database columns on table things of type string. However, don&#39;t actually run this command. Instead, we&#39;re going to explore test driving out a similar result to what a generator would give us. Set up If you haven&#39;t already done so, first create a blank project by running: $ mix phx.new hello Change into the newly-created hello directory, configure your database in config/dev.exs and then run: $ mix ecto.create If you have any questions about this process, now is a good time to jump over to the Up and Running Guide. Let&#39;s create an Accounts context for this example. Since context creation is not in scope of this guide, we will use the generator. If you aren&#39;t familiar, read this section of the Mix guide and the Contexts Guide. $ mix phx.gen.context Accounts User users name:string email:string:unique password:string * creating lib/hello/accounts/user.ex * creating priv/repo/migrations/20170913155721_create_users.exs * creating lib/hello/accounts.ex * injecting lib/hello/accounts.ex * creating test/hello/accounts/accounts_test.exs * injecting test/hello/accounts/accounts_test.exs Remember to update your repository by running migrations: $ mix ecto.migrate Ordinarily we would spend time tweaking the generated migration file (priv/repo/migrations/&lt;datetime&gt;_create_users.exs) to add things like non-null constraints and so on, but we don&#39;t need to make any changes for this example, so we can just run the migration: $ mix ecto.migrate Compiling 2 files (.ex) Generated hello app [info] == Running Hello.Repo.Migrations.CreateUsers.change/0 forward [info] create table users [info] create index users_email_index [info] == Migrated in 0.0s As a final check before we start developing, we can run mix test and make sure that all is well. $ mix test All of the tests should pass, but sometimes the database isn&#39;t configured properly in config/test.exs, or some other issue crops up. It is best to correct these issues now, before we complicate things with deliberately breaking tests! Test driving What we are going for is a controller with the standard CRUD actions. We&#39;ll start with our test since we&#39;re TDDing this. Create a user_controller_test.exs file in test/hello_web/controllers defmodule HelloWeb.UserControllerTest do use HelloWeb.ConnCase end There are many ways to approach TDD. Here, we will think about each action we want to perform, and handle the &quot;happy path&quot; where things go as planned, and the error case where something goes wrong, if applicable. defmodule HelloWeb.UserControllerTest do use HelloWeb.ConnCase test &quot;index/2 responds with all Users&quot; describe &quot;create/2&quot; do test &quot;Creates, and responds with a newly created user if attributes are valid&quot; test &quot;Returns an error and does not create a user if attributes are invalid&quot; end describe &quot;show/2&quot; do test &quot;Responds with user info if the user is found&quot; test &quot;Responds with a message indicating user not found&quot; end describe &quot;update/2&quot; do test &quot;Edits, and responds with the user if attributes are valid&quot; test &quot;Returns an error and does not edit the user if attributes are invalid&quot; end test &quot;delete/2 and responds with :ok if the user was deleted&quot; end Here we have tests around the 5 controller CRUD actions we need to implement for a typical JSON API. At the top of the module we are using the module HelloWeb.ConnCase, which provides connections to our test repository. Then we define the 8 tests. In 2 cases, index and delete, we are only testing the happy path, because in our case they generally won&#39;t fail because of domain rules (or lack thereof). In practical application, our delete could fail easily once we have associated resources that cannot leave orphaned resources behind, or number of other situations. On index, we could have filtering and searching to test. Also, both could require authorization. Create, show and update have more typical ways to fail because they need a way to find the resource, which could be non existent, or invalid data was supplied in the params. Since we have multiple tests for each of these endpoints, putting them in a describe block is good way to organize our tests. Let&#39;s run the test: $ mix test test/hello_web/controllers/user_controller_test.exs We get 8 failures that say &quot;Not implemented&quot; which is good. Our tests don&#39;t have blocks yet. The first test Let&#39;s add our first test. We&#39;ll start with index/2. defmodule HelloWeb.UserControllerTest do use HelloWeb.ConnCase alias Hello.Accounts test &quot;index/2 responds with all Users&quot;, %{conn: conn} do users = [%{name: &quot;John&quot;, email: &quot;john@example.com&quot;, password: &quot;john pass&quot;}, %{name: &quot;Jane&quot;, email: &quot;jane@example.com&quot;, password: &quot;jane pass&quot;}] # create users local to this database connection and test [{:ok, user1},{:ok, user2}] = Enum.map(users, &amp;Accounts.create_user(&amp;1)) response = conn |&gt; get(Routes.user_path(conn, :index)) |&gt; json_response(200) expected = %{ &quot;data&quot; =&gt; [ %{ &quot;name&quot; =&gt; user1.name, &quot;email&quot; =&gt; user1.email }, %{ &quot;name&quot; =&gt; user2.name, &quot;email&quot; =&gt; user2.email } ] } assert response == expected end Let&#39;s take a look at what&#39;s going on here. First we alias Hello.Accounts, the context module that provides us with our repository manipulation functions. When we use the HelloWeb.ConnCase module, it sets things up such that each connection is wrapped in a transaction, and all of the database interactions inside of the test use the same database connection and transaction. This module also sets up a conn attribute in our ExUnit context, using Phoenix.ConnCase.build_conn/0. We then pattern match this to use it in each test case. For details, take a look at the file test/support/conn_case.ex, as well as the Ecto documentation for SQL.Sandbox. We could put a build_conn/0 call inside of each test, but it is cleaner to use a setup block to do it. The index test then hooks into the context to extract the contents of the :conn key. We then create two users using the Hello.Accounts.create_user/1 function. Again, note that this function accesses the test repo, but even though we don&#39;t pass the conn variable to the call, it still uses the same connection and puts these new users inside the same database transaction. Next the conn is piped to a get function to make a GET request to our UserController index action, which is in turn piped into json_response/2 along with the expected HTTP status code. This will return the JSON from the response body, when everything is wired up properly. We represent the JSON we want the controller action to return with the variable expected, and assert that the response and expected are the same. Our expected data is a JSON response with a top level key of &quot;data&quot; containing an array of users that have &quot;name&quot; and &quot;email&quot; properties that should match the users created before making the request. Also, we do not want the users&#39; &quot;password&quot; properties to show up in our JSON response. When we run the test we get an error that we have no user_path function. In our router, we&#39;ll uncomment the api scope at the bottom of the auto-generated file, and then use the resources macro to generate the routes for the &quot;/users&quot; path. Because we aren&#39;t going to be generating forms to create and update users, we add the except: [:new, :edit] to skip those endpoints. defmodule HelloWeb.Router do use HelloWeb, :router pipeline :browser do plug :accepts, [&quot;html&quot;] plug :fetch_session plug :fetch_flash plug :protect_from_forgery plug :put_secure_browser_headers end pipeline :api do plug :accepts, [&quot;json&quot;] end scope &quot;/&quot;, HelloWeb do pipe_through :browser get &quot;/&quot;, PageController, :index end # Other scopes may use custom stacks. scope &quot;/api&quot;, HelloWeb do pipe_through :api resources &quot;/users&quot;, UserController, except: [:new, :edit] end end Before running the test again, check out our new paths by running mix phx.routes. You should see six new &quot;/api&quot; routes in addition to the default page controller route: $ mix phx.routes Compiling 6 files (.ex) page_path GET / HelloWeb.PageController :index user_path GET /api/users HelloWeb.UserController :index user_path GET /api/users/:id HelloWeb.UserController :show user_path POST /api/users HelloWeb.UserController :create user_path PATCH /api/users/:id HelloWeb.UserController :update PUT /api/users/:id HelloWeb.UserController :update user_path DELETE /api/users/:id HelloWeb.UserController :delete We should get a new error now. Running the test informs us we don&#39;t have a HelloWeb.UserController. Let&#39;s create that controller by opening the file lib/hello_web/controllers/user_controller.ex and adding the index/2 action we&#39;re testing. Our test description has us returning all users: defmodule HelloWeb.UserController do use HelloWeb, :controller alias Hello.Accounts def index(conn, _params) do users = Accounts.list_users() render(conn, &quot;index.json&quot;, users: users) end end When we run the test again, our failing test tells us the module HelloWeb.UserView is not available. Let&#39;s add it by creating the file lib/hello_web/views/user_view.ex. Our test specifies a JSON format with a top key of &quot;data&quot;, containing an array of users with attributes &quot;name&quot; and &quot;email&quot;. defmodule HelloWeb.UserView do use HelloWeb, :view def render(&quot;index.json&quot;, %{users: users}) do %{data: render_many(users, HelloWeb.UserView, &quot;user.json&quot;)} end def render(&quot;user.json&quot;, %{user: user}) do %{name: user.name, email: user.email} end end The view module for the index uses the render_many/4 function. According to the documentation, using render_many/4 is &quot;roughly equivalent&quot; to using Enum.map/2, and in fact Enum.map is called under the hood. The main difference between render_many/4 and directly calling Enum.map/2 is that the former benefits from library-quality error checking, properly handling missing values, and so on. render_many/4 also has an :as option that can used so that the key in the assigns map can be renamed. By default, this is inferred from the module name (:user in this case), but it can be changed if necessary to fit the render function being used. And with that, our test passes when we run it. Testing the show action We&#39;ll also cover the show/2 action here so we can see how to handle an error case. Our show tests currently look like this: describe &quot;show/2&quot; do test &quot;Responds with user info if the user is found&quot; test &quot;Responds with a message indicating user not found&quot; end Run this test only by running the following command: (if your show tests don&#39;t start on line 34, change the line number accordingly) $ mix test test/hello_web/controllers/user_controller_test.exs:34 Our first show/2 test result is, as expected, not implemented. Let&#39;s build a test around what we think a successful show/2 should look like. test &quot;Responds with user info if the user is found&quot;, %{conn: conn} do {:ok, user} = Accounts.create_user(%{name: &quot;John&quot;, email: &quot;john@example.com&quot;, password: &quot;john pass&quot;}) response = conn |&gt; get(Routes.user_path(conn, :show, user.id)) |&gt; json_response(200) expected = %{&quot;data&quot; =&gt; %{&quot;email&quot; =&gt; user.email, &quot;name&quot; =&gt; user.name}} assert response == expected end This is fine, but it can be refactored slightly. Notice that both this test and the index test need users in the database. Instead of creating these users over and over again, we can instead call another setup/1 function to populate the database with users on an as-needed basis. To do this, first create a private function at the bottom of the test module as follows: defp create_user(_) do {:ok, user} = Accounts.create_user(@create_attrs) {:ok, user: user} end Next define @create_attrs as a custom attribute for the module at the top, as follows. alias Hello.Accounts @create_attrs %{name: &quot;John&quot;, email: &quot;john@example.com&quot;, password: &quot;john pass&quot;} Finally, invoke the function using a second setup/1 call inside of the describe block: describe &quot;show/2&quot; do setup [:create_user] test &quot;Responds with user info if the user is found&quot;, %{conn: conn, user: user} do response = conn |&gt; get(Routes.user_path(conn, :show, user.id)) |&gt; json_response(200) expected = %{&quot;data&quot; =&gt; %{&quot;email&quot; =&gt; user.email, &quot;name&quot; =&gt; user.name}} assert response == expected end test &quot;Responds with a message indicating user not found&quot; end The functions called by setup take an ExUnit context (not to be confused with the contexts we are describing throughout this guide) and allow us to add additional fields when we return. In this case, create_user doesn&#39;t care about the existing context (hence the underscore parameter), and adds a new user to the ExUnit context under the key user: by returning {:ok, user: user}. The test can then access both the database connection and this new user from the ExUnit context. Finally, let&#39;s change our index/2 test to also use the new create_user function. The index test doesn&#39;t really need two users, after all. The revised index/2 test should look like this: describe &quot;index/2&quot; do setup [:create_user] test &quot;index/2 responds with all Users&quot;, %{conn: conn, user: user} do response = conn |&gt; get(Routes.user_path(conn, :index)) |&gt; json_response(200) expected = %{&quot;data&quot; =&gt; [%{&quot;name&quot; =&gt; user.name, &quot;email&quot; =&gt; user.email}]} assert response == expected end end The biggest change here is that we now wrapped the old test inside of another describe block so that we have somewhere to put the setup/2 call for the index test. We are now accessing the user from the ExUnit context, and expecting just a single user from the index/2 test results, not two. The index/2 test should still pass, but the show/2 test will error with a message that we need a HelloWeb.UserController.show/2 action. Let&#39;s add that to the UserController module next. defmodule HelloWeb.UserController do use HelloWeb, :controller alias Hello.Accounts def index(conn, _params) do users = Accounts.list_users() render(conn, &quot;index.json&quot;, users: users) end def show(conn, %{&quot;id&quot; =&gt; id}) do user = Accounts.get_user!(id) render(conn, &quot;show.json&quot;, user: user) end end You might notice the exclamation point in the get_user!/1 function. This convention means that this function will throw an error if the requested user is not found. You&#39;ll also notice that we aren&#39;t properly handling the possibility of a thrown error here. When we TDD we only want to write enough code to make the test pass. We&#39;ll add more code when we get to the error handling test for show/2. Running the test tells us we need a render/2 function that can pattern match on &quot;show.json&quot;: defmodule HelloWeb.UserView do use HelloWeb, :view def render(&quot;index.json&quot;, %{users: users}) do %{data: render_many(users, HelloWeb.UserView, &quot;user.json&quot;)} end def render(&quot;show.json&quot;, %{user: user}) do %{data: render_one(user, HelloWeb.UserView, &quot;user.json&quot;)} end def render(&quot;user.json&quot;, %{user: user}) do %{name: user.name, email: user.email} end end Notice the &quot;show.json&quot; rendering path uses render_one/4 instead of render_many/4 because it is only rendering a single user, not a list. When we run the test again, it passes. Show when the user is not found The last item we&#39;ll cover is the case where we don&#39;t find a user in show/2. Try this one on your own and see what you come up with. One possible solution will be given below. Walking through our TDD steps, we add a test that supplies a non-existent user id to user_path which returns a 404 status and an error message. One interesting problem here is how we might define a &quot;non-existent&quot; id. We could just pick a large integer, but who&#39;s to say some future test won&#39;t generate thousands of test users and break our test? Instead of going bigger, we can also go the other way. Database ids tend to start at 1 and increase forever. Negative numbers are perfectly valid integers, and yet never used for database ids. So we&#39;ll pick -1 as our &quot;unobtainable&quot; user id, which should always fail. test &quot;Responds with a message indicating user not found&quot;, %{conn: conn} do conn = get(conn, Routes.user_path(conn, :show, -1)) assert text_response(conn, 404) =~ &quot;User not found&quot; end We want a HTTP status code of 404 to notify the requester that this resource was not found, as well as an accompanying error message. Notice that we use text_response/2 instead of json_response/2 to assert that the status code is 404 and the response body matches the accompanying error message. You can run this test now to see what happens. You should see that an Ecto.NoResultsError is thrown, because there is no such user in the database. Our controller action needs to handle the error thrown by Ecto. We have two choices here. By default, this will be handled by the phoenix_ecto library, returning a 404. However if we want to show a custom error message, we can create a new get_user/1 function that does not throw an Ecto error. For this example, we&#39;ll take the second path and implement a new get_user/1 function in the file lib/hello/accounts.ex, just before the get_user!/1 function: @doc &quot;&quot;&quot; Gets a single `%User{}` from the data store where the primary key matches the given id. Returns `nil` if no result was found. ## Examples iex&gt; get_user(123) %User{} iex&gt; get_user(456) nil &quot;&quot;&quot; def get_user(id), do: Repo.get(User, id) This function is just a thin wrapper around Ecto.Repo.get/3, and like that function will return either a %User{} if the user is found, or nil if not. Next change the show/2 function to use the non-throwing version, and handle the two possible result cases. def show(conn, %{&quot;id&quot; =&gt; id}) do case Accounts.get_user(id) do nil -&gt; conn |&gt; put_status(:not_found) |&gt; text(&quot;User not found&quot;) user -&gt; render(conn, &quot;show.json&quot;, user: user) end end The first branch of the case statement handles the nil result case. First, we use the put_status/2 function from Plug.Conn to set the desired error status. The complete list of allowed codes can be found in the Plug.Conn.Status documentation, where we can see that :not_found corresponds to our desired &quot;404&quot; status. We then return a text response using text/2. The second branch of the case statement handles the &quot;happy path&quot; we&#39;ve already covered. Phoenix also allows us to only implement the &quot;happy path&quot; in our action and use Phoenix.Controller.action_fallback/1. This is useful for centralizing your error handling code. You may wish to refactor the show action to use action_fallback as covered in the &quot;Action Fallback&quot; section of the controllers guide. With those implemented, our tests pass. The rest of the controller is left for you to implement as practice. If you are not sure where to begin, it is worth using the Phoenix JSON generator and seeing what tests are automatically generated for you. Happy testing!"},{"ref":"testing_channels.html","title":"Testing Channels","type":"extras","doc":"Testing Channels As developers we typically value tests since they help to &#39;future-proof&#39; our applications by minimizing regression and provide updated documentation. Phoenix recognizes this and helps make it easier to write tests by providing conveniences for testing its different parts, including Channels. In the Channels Guide, we saw that a &quot;Channel&quot; is a layered system with different components. Given this, there would be cases when writing unit tests for our Channel functions may not be enough. We may want to verify that its different moving parts are working together as we expect. This integration testing would assure us that we correctly defined our channel route, the channel module, and its callbacks; and that the lower-level layers such as the PubSub and Transport are configured correctly and are working as intended. The Channel Generator As we progress through this guide, it would help to have a concrete example we could work off of. Phoenix comes with a Mix task for generating a basic channel and tests. These generated files serve as a good reference for writing channels and their corresponding tests. Let&#39;s go ahead and generate our Channel: $ mix phx.gen.channel Room * creating lib/hello_web/channels/room_channel.ex * creating test/hello_web/channels/room_channel_test.exs Add the channel to your `lib/hello_web/channels/user_socket.ex` handler, for example: channel &quot;room:lobby&quot;, HelloWeb.RoomChannel This creates a channel, its test and instructs us to add a channel route in lib/hello_web/channels/user_socket.ex. It is important to add the channel route or our channel won&#39;t function at all! The Channel Test Helpers Module Upon inspecting the file test/hello_web/channels/room_channel_test.exs, we see a line that looks like use MyAppWeb.ChannelCase. Note - we assume that our app is named MyApp throughout this guide. Where does this come from? When we generate a new Phoenix application, a test/support/channel_case.ex file is also generated for us. This file houses the MyAppWeb.ChannelCase module which we will use for all our integration tests for our channels. It automatically imports conveniences for testing channels. Some of the helper functions provided there are for triggering callback functions in our channel. The others are there to provide us with special assertions that apply only to channels. If we need to add our own helper function that we would only use in channel tests, we would add it to MyAppWeb.ChannelCase by defining it there and ensuring MyAppWeb.ChannelCase is imported every time it is used. For example: defmodule MyAppWeb.ChannelCase do ... using do quote do ... import MyAppWeb.ChannelCase end end def a_channel_test_helper() do # code here end end The Setup Block Now that we know that Phoenix provides with a custom Test Case just for channels and what it provides, we can move on to understanding the rest of test/hello_web/channels/room_channel_test.exs. First off, is the setup block: setup do {:ok, _, socket} = socket(&quot;user_id&quot;, %{some: :assign}) |&gt; subscribe_and_join(RoomChannel, &quot;room:lobby&quot;) {:ok, socket: socket} end The setup/2 macro comes with ExUnitwhich comes out of the box with Elixir. The do block passed to setup/2 will get run for each of our tests. Note the line {:ok, socket: socket}. That line ensures that the socket from subscribe_and_join/3 will be accessible to all our tests. In this way, we won&#39;t need to call subscribe_and_join/3 for every test block we create. subscribe_and_join/3 emulates the client joining a channel and subscribes the test process to the given topic. This is a necessary step since clients need to join a channel before they can send and receive events on that channel. Testing a Synchronous Reply The first test block in our generated channel test looks like: test &quot;ping replies with status ok&quot;, %{socket: socket} do ref = push(socket, &quot;ping&quot;, %{&quot;hello&quot; =&gt; &quot;there&quot;}) assert_reply ref, :ok, %{&quot;hello&quot; =&gt; &quot;there&quot;} end This tests the following code in our MyAppWeb.RoomChannel: # Channels can be used in a request/response fashion # by sending replies to requests from the client def handle_in(&quot;ping&quot;, payload, socket) do {:reply, {:ok, payload}, socket} end As is stated in the comment above, we see that a reply is synchronous since it mimics the request/ response pattern we are familiar with in HTTP. This synchronous reply is best used when we only want to send an event back to the client when we are done processing the message on the server. For example, when we save something to the database and then send a message to the client only once that&#39;s done. In the test &quot;ping replies with status ok&quot;, %{socket: socket} do line, we see that we have the map %{socket: socket}. This gives us access to the socket in the setup block. We emulate the client pushing a message to the channel with push/3. In the line ref = push(socket, &quot;ping&quot;, %{&quot;hello&quot; =&gt; &quot;there&quot;}), we push the event &quot;ping&quot; with the payload %{&quot;hello&quot; =&gt; &quot;there&quot;} to the channel. This triggers the handle_in/3 callback we have for the &quot;ping&quot; event in our channel. Note that we store the ref since we need that on the next line for asserting the reply. With assert_reply ref, :ok, %{&quot;hello&quot; =&gt; &quot;there&quot;}, we assert that the server sends a synchronous reply :ok, %{&quot;hello&quot; =&gt; &quot;there&quot;}. This is how we check that the handle_in/3 callback for the &quot;ping&quot; was triggered. Testing a Broadcast It is common to receive messages from the client and broadcast to everyone subscribed to a current topic. This common pattern is simple to express in Phoenix and is one of the generated handle_in/3 callbacks in our MyAppWeb.RoomChannel. def handle_in(&quot;shout&quot;, payload, socket) do broadcast(socket, &quot;shout&quot;, payload) {:noreply, socket} end Its corresponding test looks like: test &quot;shout broadcasts to room:lobby&quot;, %{socket: socket} do push(socket, &quot;shout&quot;, %{&quot;hello&quot; =&gt; &quot;all&quot;}) assert_broadcast &quot;shout&quot;, %{&quot;hello&quot; =&gt; &quot;all&quot;} end We notice that we access the same socket that is from the setup block. How handy! We also do the same push/3 as we did in the synchronous reply test. So we push the &quot;shout&quot; event with the payload %{&quot;hello&quot; =&gt; &quot;all&quot;}. Since the handle_in/3 callback for the &quot;shout&quot; event just broadcasts the same event and payload, all subscribers in the &quot;room:lobby&quot; should receive the message. To check that, we do assert_broadcast &quot;shout&quot;, %{&quot;hello&quot; =&gt; &quot;all&quot;}. NOTE: assert_broadcast/3 tests that the message was broadcast in the PubSub system. For testing if a client receives a message, use assert_push/3 Testing an Asynchronous Push from the Server The last test in our MyAppWeb.RoomChannelTest verifies that broadcasts from the server are pushed to the client. Unlike the previous tests discussed, we are indirectly testing that our channel&#39;s handle_out/3 callback is triggered. This handle_out/3 is defined in our MyApp.RoomChannel as: def handle_out(event, payload, socket) do push(socket, event, payload) {:noreply, socket} end Since the handle_out/3 event is only triggered when we call broadcast/3 from our channel, we will need to emulate that in our test. We do that by calling broadcast_from or broadcast_from!. Both serve the same purpose with the only difference of broadcast_from! raising an error when broadcast fails. The line broadcast_from!(socket, &quot;broadcast&quot;, %{&quot;some&quot; =&gt; &quot;data&quot;}) will trigger our handle_out/3 callback above which pushes the same event and payload back to the client. To test this, we do assert_push &quot;broadcast&quot;, %{&quot;some&quot; =&gt; &quot;data&quot;}. Wrap-up In this guide we tackled all the special assertions that comes with MyAppWeb.ConnCase and some of the functions provided that help you test channels by triggering its callbacks. We found the API for testing channels is largely consistent with the API for Phoenix Channels which makes it easy to work with. If interested in learning more about the helpers provided by MyAppWeb.ChannelCase, check out the documentation for Phoenix.ChannelTest which is the module that defines those functions."},{"ref":"deployment.html","title":"Introduction to Deployment","type":"extras","doc":"Introduction to Deployment Once we have a working application, we&#39;re ready to deploy it. If you&#39;re not quite finished with your own application, don&#39;t worry. Just follow the Up and Running Guide to create a basic application to work with. When preparing an application for deployment, there are three main steps: Handling of your application secrets Compiling your application assets Starting your server in production In this guide, we will learn how to get the production environment running locally. You can use the same techniques in this guide to run your application in production, but depending on your deployment infrastructure, extra steps will be necessary. As an example of deploying to other infrastructures, we also discuss two different approaches in our guides: using Elixir&#39;s releases with mix release and by using Heroku. The release guide also has a sample Docker file you can use if you prefer to deploy with container technologies. Let&#39;s explore those steps above one by one."},{"ref":"deployment.html#handling-of-your-application-secrets","title":"Introduction to Deployment - Handling of your application secrets","type":"extras","doc":"All Phoenix applications have data that must be kept secure, for example, the username and password for your production database, and the secret Phoenix uses to sign and encrypt important information. The general recommendation is to keep those in environment variables and load them into your application. This is done in config/prod.secret.exs, which is responsible for loading secrets and configuration from environment variables. Therefore, you need to make sure the proper relevant variables are set in production: $ mix phx.gen.secret REALLY_LONG_SECRET $ export SECRET_KEY_BASE=REALLY_LONG_SECRET $ export DATABASE_URL=ecto://USER:PASS@HOST/database Do not copy those values directly, set SECRET_KEY_BASE according to the result of mix phx.gen.secret and DATABASE_URL according to your database address. If for some reason you do not want to rely on environment variables, you can hard code the secrets in your config/prod.secret.exs, but make sure not to check the file into your version control system. With your secret information properly secured, it is time to configure assets! Before taking this step, we need to do one bit of preparation. Since we will be readying everything for production, we need to do some setup in that environment by getting our dependencies and compiling. $ mix deps.get --only prod $ MIX_ENV=prod mix compile"},{"ref":"deployment.html#compiling-your-application-assets","title":"Introduction to Deployment - Compiling your application assets","type":"extras","doc":"This step is required only if you have static assets like images, JavaScript, stylesheets and more in your Phoenix applications. By default, Phoenix uses webpack, and that&#39;s what we are going to explore. Compilation of static assets happens in two steps: $ npm run deploy --prefix ./assets $ mix phx.digest Check your digested files at &quot;priv/static&quot;. And that is it! The first command builds the assets and the second generates digests as well as a cache manifest file so Phoenix can quickly serve assets in production. Keep in mind that, if you by any chance forget to run the steps above, Phoenix will show an error message: $ PORT=4001 MIX_ENV=prod mix phx.server 10:50:18.732 [info] Running MyApp.Endpoint with Cowboy on http://example.com 10:50:18.735 [error] Could not find static manifest at &quot;my_app/_build/prod/lib/foo/priv/static/cache_manifest.json&quot;. Run &quot;mix phx.digest&quot; after building your static files or remove the configuration from &quot;config/prod.exs&quot;. The error message is quite clear: it says Phoenix could not find a static manifest. Just run the commands above to fix it or, if you are not serving or don&#39;t care about assets at all, you can just remove the cache_static_manifest configuration from config/prod.exs."},{"ref":"deployment.html#starting-your-server-in-production","title":"Introduction to Deployment - Starting your server in production","type":"extras","doc":"To run Phoenix in production, we need to set the PORT and MIX_ENV environment variables when invoking mix phx.server: $ PORT=4001 MIX_ENV=prod mix phx.server 10:59:19.136 [info] Running MyApp.Endpoint with Cowboy on http://example.com To run in detached mode so that the Phoenix server does not stop and continues to run even if you close the terminal: $ PORT=4001 MIX_ENV=prod elixir --erl &quot;-detached&quot; -S mix phx.server In case you get an error message, please read it carefully, and open up a bug report if it is still not clear how to address it. You can also run your application inside an interactive shell: $ PORT=4001 MIX_ENV=prod iex -S mix phx.server 10:59:19.136 [info] Running MyApp.Endpoint with Cowboy on http://example.com"},{"ref":"deployment.html#putting-it-all-together","title":"Introduction to Deployment - Putting it all together","type":"extras","doc":"The previous sections give an overview about the main steps required to deploy your Phoenix application. In practice, you will end-up adding steps of your own as well. For example, if you are using a database, you will also want to run mix ecto.migrate before starting the server to ensure your database is up to date. Overall, here is a script you can use as a starting point: # Initial setup $ mix deps.get --only prod $ MIX_ENV=prod mix compile # Compile assets $ npm run deploy --prefix ./assets $ mix phx.digest # Custom tasks (like DB migrations) $ MIX_ENV=prod mix ecto.migrate # Finally run the server $ PORT=4001 MIX_ENV=prod mix phx.server And that&#39;s it. Next you can learn how to deploy Phoenix with Elixir&#39;s releases and how to deploy to Heroku."},{"ref":"releases.html","title":"Deploying with Releases","type":"extras","doc":"Deploying with Releases"},{"ref":"releases.html#what-well-need","title":"Deploying with Releases - What we&#39;ll need","type":"extras","doc":"The only thing we&#39;ll need for this guide is a working Phoenix application. For those of us who need a simple application to deploy, please follow the Up and Running guide."},{"ref":"releases.html#goals","title":"Deploying with Releases - Goals","type":"extras","doc":"Our main goal for this guide is to package your Phoenix application into a self-contained directory that includes the Erlang VM, Elixir, all of your code and dependencies. This package can then be dropped into a production machine."},{"ref":"releases.html#releases-assemble","title":"Deploying with Releases - Releases, assemble!","type":"extras","doc":"To assemble a release, you will need Elixir v1.9 or later: $ elixir -v 1.9.0 If you are not familiar with Elixir releases yet, we recommend you to read Elixir&#39;s excellent docs before continuing. Once that is done, you can assemble a release by going through all of the steps in our general deployment guide with mix release at the end. Let&#39;s recap. First set the environment variables: $ mix phx.gen.secret REALLY_LONG_SECRET $ export SECRET_KEY_BASE=REALLY_LONG_SECRET $ export DATABASE_URL=ecto://USER:PASS@HOST/database Then load dependencies to compile code and assets: # Initial setup $ mix deps.get --only prod $ MIX_ENV=prod mix compile # Compile assets $ npm run deploy --prefix ./assets $ mix phx.digest And now run mix release: $ MIX_ENV=prod mix release Generated my_app app * assembling my_app-0.1.0 on MIX_ENV=prod * skipping runtime configuration (config/releases.exs not found) Release created at _build/prod/rel/my_app! # To start your system _build/prod/rel/my_app/bin/my_app start ... You can start the release by calling _build/prod/rel/my_app/bin/my_app start, where you have to replace my_app by your current application name. If you do so, your application should start but you will notice your web server does not actually run! That&#39;s because we need to tell Phoenix to start the web servers. When using mix phx.server, the phx.server command does that for us, but in a release we don&#39;t have Mix (which is a build tool), so we have to do it ourselves. Open up config/prod.secret.exs and you should find a section about &quot;Using releases&quot; with a configuration to set. Go ahead and uncomment that line or manually add the line below, adapted to your application names: config :my_app, MyApp.Endpoint, server: true Now assemble the release once again: $ MIX_ENV=prod mix release Generated my_app app * assembling my_app-0.1.0 on MIX_ENV=prod * skipping runtime configuration (config/releases.exs not found) Release created at _build/prod/rel/my_app! # To start your system _build/prod/rel/my_app/bin/my_app start And starting the release now should also successfully start the web server! Now you can get all of the files under the _build/prod/rel/my_app directory, package it, and run it in any production machine with the same OS and archictecture as the one that assembled the release. For more details, check the docs for mix release. But before we finish this guide, there are two features from releases most Phoenix applications will use, so let&#39;s talk about those."},{"ref":"releases.html#runtime-configuration","title":"Deploying with Releases - Runtime configuration","type":"extras","doc":"You may have noticed that, in order to assemble our release, we had to set both SECRET_KEY_BASE and DATABASE_URL. That&#39;s because config/config.exs, config/prod.exs, and friends are executed when the release is assembled (or more generally speaking, whenever you run a mix command). However, in many cases, we don&#39;t want to set the values for SECRET_KEY_BASE and DATABASE_URL when assembling the release but only when starting the system in production. In particular, you may not even have those values easily accessible, and you may have to reach out to another system to retrieve those. Luckily, for such use cases, mix release provides runtime configuration, which we can enable in three steps: Rename config/prod.secret.exs to config/releases.exs Change use Mix.Config inside the new config/releases.exs file to import Config (if you want, you can replace all uses of use Mix.Config by import Config, as the latter replaces the former) Change config/prod.exs to no longer call import_config &quot;prod.secret.exs&quot; at the bottom Now if you assemble another release, you should see this: $ MIX_ENV=prod mix release Generated my_app app * assembling my_app-0.1.0 on MIX_ENV=prod * using config/releases.exs to configure the release at runtime Notice how it says you are using runtime configuration. Now you no longer need to set those environment variables when assembling the release, only when you run _build/prod/rel/my_app/bin/my_app start and friends."},{"ref":"releases.html#ecto-migrations-and-custom-commands","title":"Deploying with Releases - Ecto migrations and custom commands","type":"extras","doc":"Another common need in production systems is to execute custom commands required to set up the production environment. One of such commands is precisely migrating the database. Since we don&#39;t have Mix, a build tool, inside releases, which are a production artifact, we need to bring said commands directly into the release. Our recommendation is to create a new file in your application, such as lib/my_app/release.ex, with the following: defmodule MyApp.Release do @app :my_app def migrate do for repo &lt;- repos() do {:ok, _, _} = Ecto.Migrator.with_repo(repo, &amp;Ecto.Migrator.run(&amp;1, :up, all: true)) end end def rollback(repo, version) do {:ok, _, _} = Ecto.Migrator.with_repo(repo, &amp;Ecto.Migrator.run(&amp;1, :down, to: version)) end defp repos do Application.load(@app) Application.fetch_env!(@app, :ecto_repos) end end Where you replace the first two lines by your application names. Now you can assemble a new release with MIX_ENV=prod mix release and you can invoke any code, including the functions in the module above, by calling the eval command: $ _build/prod/rel/my_app/bin/my_app eval &quot;MyApp.Release.migrate&quot; And that&#39;s it!"},{"ref":"releases.html#containers","title":"Deploying with Releases - Containers","type":"extras","doc":"Elixir releases work well with container technologies, such as Docker. The idea is that you assemble the release inside the Docker container and then build an image based on the release artifacts. Here is an example Docker file to run at the root of your application covering all of the steps above: # FROM elixir:1.9.0-alpine as build # install build dependencies RUN apk add --update git build-base nodejs yarn python # prepare build dir RUN mkdir /app WORKDIR /app # install hex + rebar RUN mix local.hex --force &amp;&amp; \\ mix local.rebar --force # set build ENV ENV MIX_ENV=prod # install mix dependencies COPY mix.exs mix.lock ./ COPY config config RUN mix deps.get RUN mix deps.compile # build assets COPY assets assets COPY priv priv RUN cd assets &amp;&amp; npm install &amp;&amp; npm run deploy RUN mix phx.digest # build project COPY lib lib RUN mix compile # build release (uncomment COPY if rel/ exists) # COPY rel rel RUN mix release # prepare release image FROM alpine:3.9 AS app RUN apk add --update bash openssl RUN mkdir /app WORKDIR /app COPY --from=build /app/_build/prod/rel/my_app ./ RUN chown -R nobody: /app USER nobody ENV HOME=/app At the end, you will have an application in /app ready to run as bin/my_app start."},{"ref":"heroku.html","title":"Deploying on Heroku","type":"extras","doc":"Deploying on Heroku"},{"ref":"heroku.html#what-well-need","title":"Deploying on Heroku - What we&#39;ll need","type":"extras","doc":"The only thing we&#39;ll need for this guide is a working Phoenix application. For those of us who need a simple application to deploy, please follow the Up and Running guide."},{"ref":"heroku.html#goals","title":"Deploying on Heroku - Goals","type":"extras","doc":"Our main goal for this guide is to get a Phoenix application running on Heroku."},{"ref":"heroku.html#limitations","title":"Deploying on Heroku - Limitations","type":"extras","doc":"Heroku is a great platform and Elixir performs well on it. However, you may run into limitations if you plan to leverage advanced features provided by Elixir and Phoenix, such as: Connections are limited. Heroku limits the number of simultaneous connections as well as the duration of each connection. It is common to use Elixir for real-time apps which need lots of concurrent, persistent connections, and Phoenix is capable of handling over 2 million connections on a single server. Distributed clustering is not possible. Heroku firewalls dynos off from one another. This means things like distributed Phoenix channels and distributed tasks will need to rely on something like Redis instead of Elixir&#39;s built-in distribution. In-memory state such as those in Agents, GenServers, and ETS will be lost every 24 hours. Heroku restarts dynos every 24 hours regardless of whether the node is healthy. The built-in Observer can&#39;t be used with Heroku. Heroku does allow for connection into your dyno, but you won&#39;t be able to use the observer to watch the state of your dyno. If you are just getting started or you don&#39;t expect to use the features above, Heroku should be enough for your needs. For instance, if you are migrating an existing application running on Heroku to Phoenix, keeping a similar set of features, Elixir will perform just as well or even better than your current stack. If you want a platform-as-a-service without these limitations, try Gigalixir. If you would rather deploy to a cloud platform, such as EC2, Google Cloud, etc, consider Distillery."},{"ref":"heroku.html#steps","title":"Deploying on Heroku - Steps","type":"extras","doc":"Let&#39;s separate this process into a few steps so we can keep track of where we are. Initialize Git repository Sign up for Heroku Install the Heroku Toolbelt Create and setup Heroku application Make our project ready for Heroku Deploy time! Useful Heroku commands"},{"ref":"heroku.html#initializing-git-repository","title":"Deploying on Heroku - Initializing Git repository","type":"extras","doc":"Git is a popular decentralized revision control system and is also used to deploy apps to Heroku. Before we can push to Heroku we&#39;ll need to initialize a local Git repository and commit our files to it. We can do so by running the following commands in our project directory: $ git init $ git add . $ git commit -m &quot;Initial commit&quot; Heroku offers some great information on how it is using Git here."},{"ref":"heroku.html#signing-up-for-heroku","title":"Deploying on Heroku - Signing up for Heroku","type":"extras","doc":"Signing up to Heroku is very simple, just head over to https://signup.heroku.com/ and fill in the form. The Free plan will give us one web dyno and one worker dyno, as well as a PostgreSQL and Redis instance for free. These are meant to be used for testing and development, and come with some limitations. In order to run a production application, please consider upgrading to a paid plan."},{"ref":"heroku.html#installing-the-heroku-toolbelt","title":"Deploying on Heroku - Installing the Heroku Toolbelt","type":"extras","doc":"Once we have signed up, we can download the correct version of the Heroku Toolbelt for our system here. The Heroku CLI, part of the Toolbelt, is useful to create Heroku applications, list currently running dynos for an existing application, tail logs or run one-off commands (mix tasks for instance)."},{"ref":"heroku.html#create-and-setup-heroku-application","title":"Deploying on Heroku - Create and Setup Heroku Application","type":"extras","doc":"There are two different ways to deploy a Phoenix app on Heroku. We could use Heroku buildpacks or their container stack. The difference between these two approaches is in how we tell Heroku to treat our build. In buildpack case, we need to update our apps configuration on Heroku to use Phoenix/Elixir specific buildpacks. On container approach, we have more control on how we want to setup our app and we can define our container image using Dockerfile and heroku.yml. This section will explore the buildpack approach. In order to use Dockerfile, it is often recommended to convert our app to use releases, which we will describe later on. Create Application A buildpack is a convenient way of packaging framework and/or runtime support. Phoenix requires 2 buildpacks to run on Heroku, the first adds basic Elixir support and the second adds Phoenix specific commands. With the Toolbelt installed, let&#39;s create the Heroku application. We will do so using the latest available version of the Elixir buildpack: $ heroku create --buildpack hashnuke/elixir Creating app... done, ⬢ mysterious-meadow-6277 Setting buildpack to hashnuke/elixir... done https://mysterious-meadow-6277.herokuapp.com/ | https://git.heroku.com/mysterious-meadow-6277.git Note: the first time we use a Heroku command, it may prompt us to log in. If this happens, just enter the email and password you specified during signup. Note: the name of the Heroku application is the random string after &quot;Creating&quot; in the output above (mysterious-meadow-6277). This will be unique, so expect to see a different name from &quot;mysterious-meadow-6277&quot;. Note: the URL in the output is the URL to our application. If we open it in our browser now, we will get the default Heroku welcome page. Note: if we hadn&#39;t initialized our Git repository before we ran the heroku create command, we wouldn&#39;t have our Heroku remote repository properly set up at this point. We can set that up manually by running: heroku git:remote -a [our-app-name]. The buildpack uses a predefined Elixir and Erlang version but to avoid surprises when deploying, it is best to explicitly list the Elixir and Erlang version we want in production to be the same we are using during development or in your continuous integration servers. This is done by creating a config file named elixir_buildpack.config in the root directory of your project with your target version of Elixir and Erlang: # Elixir version elixir_version=1.8.1 # Erlang version # available versions https://github.com/HashNuke/heroku-buildpack-elixir-otp-builds/blob/master/otp-versions erlang_version=21.2.5 Adding the Phoenix Server and Assets Buildpack To successfully run Phoenix in production, we need to compile assets and start the Phoenix server. The Phoenix Static buildpack can take care of that for us, so let&#39;s add it now. $ heroku buildpacks:add https://github.com/gjaldon/heroku-buildpack-phoenix-static.git Buildpack added. Next release on mysterious-meadow-6277 will use: 1. https://github.com/HashNuke/heroku-buildpack-elixir.git 2. https://github.com/gjaldon/heroku-buildpack-phoenix-static.git This Phoenix Static buildpack pack can be configured to change the node version and the options for asset compilation. Please refer to the configuration section for full details. You can make your own custom build script, but for now we will use the default one provided. The Phoenix Static buildpack also configures Heroku to use the proper command to start your application. The Elixir Buildpack runs by default mix run --no-halt, which will not start your Phoenix server. The Phoenix Static buildpack changes it to the proper mix phx.server. If you don&#39;t want to use the Phoenix Static buildpack, then you must manually define a Procfile at the root of your application with the proper command: web: mix phx.server Heroku will recognize this file and use the command to start your application, ensuring that it also starts the Phoenix server. Finally, note that since we are using multiple buildpacks, you might run into an issue where the sequence is out of order (the Elixir buildpack needs to run before the Phoenix Static buildpack). Heroku&#39;s docs explain this better, but you will need to make sure the Phoenix Static buildpack comes last."},{"ref":"heroku.html#making-our-project-ready-for-heroku","title":"Deploying on Heroku - Making our Project ready for Heroku","type":"extras","doc":"Every new Phoenix project ships with a config file config/prod.secret.exs which loads configuration and secrets from environment variables. This aligns well with Heroku best practices, so most the only work left for us to do is to configure URLs and SSL. First let&#39;s tell Phoenix to use our Heroku URL and enforce we only use the SSL version of the website. Also, bind to the port requested by Heroku in the $PORT environment variable. Find the url line in your config/prod.exs: url: [host: &quot;example.com&quot;, port: 80], ... and replace it with this (don&#39;t forget to replace mysterious-meadow-6277 with your application name): http: [port: {:system, &quot;PORT&quot;}], url: [scheme: &quot;https&quot;, host: &quot;mysterious-meadow-6277.herokuapp.com&quot;, port: 443], force_ssl: [rewrite_on: [:x_forwarded_proto]], Then open up your config/prod.secret.exs and uncomment the # ssl: true, line in your repository configuration. It will look like this: config :hello, Hello.Repo, ssl: true, url: database_url, pool_size: String.to_integer(System.get_env(&quot;POOL_SIZE&quot;) || &quot;10&quot;) Finally, if you plan on using websockets, then we will need to decrease the timeout for the websocket transport in lib/hello_web/endpoint.ex. If you do not plan on using websockets, then leaving it set to false is fine. You can find further explanation of the options available at the documentation. defmodule HelloWeb.Endpoint do use Phoenix.Endpoint, otp_app: :hello socket &quot;/socket&quot;, HelloWeb.UserSocket, websocket: [timeout: 45_000], longpoll: false ... end This ensures that any idle connections are closed by Phoenix before they reach Heroku&#39;s 55-second timeout window."},{"ref":"heroku.html#creating-environment-variables-in-heroku","title":"Deploying on Heroku - Creating Environment Variables in Heroku","type":"extras","doc":"The DATABASE_URL config var is automatically created by Heroku when we add the Heroku Postgres add-on. We can create the database via the heroku toolbelt: $ heroku addons:create heroku-postgresql:hobby-dev Now we set the POOL_SIZE config var: $ heroku config:set POOL_SIZE=18 This value should be just under the number of available connections, leaving a couple open for migrations and mix tasks. The hobby-dev database allows 20 connections, so we set this number to 18. If additional dynos will share the database, reduce the POOL_SIZE to give each dyno an equal share. When running a mix task later (after we have pushed the project to Heroku) you will also want to limit its pool size like so: $ heroku run &quot;POOL_SIZE=2 mix hello.task&quot; So that Ecto does not attempt to open more than the available connections. We still have to create the SECRET_KEY_BASE config based on a random string. First, use mix phx.gen.secret to get a new secret: $ mix phx.gen.secret xvafzY4y01jYuzLm3ecJqo008dVnU3CN4f+MamNd1Zue4pXvfvUjbiXT8akaIF53 Your random string will be different; don&#39;t use this example value. Now set it in Heroku: $ heroku config:set SECRET_KEY_BASE=&quot;xvafzY4y01jYuzLm3ecJqo008dVnU3CN4f+MamNd1Zue4pXvfvUjbiXT8akaIF53&quot; Setting config vars and restarting mysterious-meadow-6277... done, v3 SECRET_KEY_BASE: xvafzY4y01jYuzLm3ecJqo008dVnU3CN4f+MamNd1Zue4pXvfvUjbiXT8akaIF53"},{"ref":"heroku.html#deploy-time","title":"Deploying on Heroku - Deploy Time!","type":"extras","doc":"Our project is now ready to be deployed on Heroku. Let&#39;s commit all our changes: $ git add config/prod.exs $ git add elixir_buildpack.config $ git add phoenix_static_buildpack.config $ git add lib/hello_web/endpoint.ex $ git commit -m &quot;Use production config from Heroku ENV variables and decrease socket timeout&quot; And deploy: $ git push heroku master Counting objects: 55, done. Delta compression using up to 8 threads. Compressing objects: 100% (49/49), done. Writing objects: 100% (55/55), 48.48 KiB | 0 bytes/s, done. Total 55 (delta 1), reused 0 (delta 0) remote: Compressing source files... done. remote: Building source: remote: remote: -----&gt; Multipack app detected remote: -----&gt; Fetching custom git buildpack... done remote: -----&gt; elixir app detected remote: -----&gt; Checking Erlang and Elixir versions remote: WARNING: elixir_buildpack.config wasn&#39;t found in the app remote: Using default config from Elixir buildpack remote: Will use the following versions: remote: * Stack cedar-14 remote: * Erlang 17.5 remote: * Elixir 1.0.4 remote: Will export the following config vars: remote: * Config vars DATABASE_URL remote: * MIX_ENV=prod remote: -----&gt; Stack changed, will rebuild remote: -----&gt; Fetching Erlang 17.5 remote: -----&gt; Installing Erlang 17.5 (changed) remote: remote: -----&gt; Fetching Elixir v1.0.4 remote: -----&gt; Installing Elixir v1.0.4 (changed) remote: -----&gt; Installing Hex remote: 2015-07-07 00:04:00 URL:https://s3.amazonaws.com/s3.hex.pm/installs/1.0.0/hex.ez [262010/262010] -&gt; &quot;/app/.mix/archives/hex.ez&quot; [1] remote: * creating /app/.mix/archives/hex.ez remote: -----&gt; Installing rebar remote: * creating /app/.mix/rebar remote: -----&gt; Fetching app dependencies with mix remote: Running dependency resolution remote: Dependency resolution completed successfully remote: [...] remote: -----&gt; Compiling remote: [...] remote: Generated phoenix_heroku app remote: [...] remote: Consolidated protocols written to _build/prod/consolidated remote: -----&gt; Creating .profile.d with env vars remote: -----&gt; Fetching custom git buildpack... done remote: -----&gt; Phoenix app detected remote: remote: -----&gt; Loading configuration and environment remote: Loading config... remote: [...] remote: Will export the following config vars: remote: * Config vars DATABASE_URL remote: * MIX_ENV=prod remote: remote: -----&gt; Installing binaries remote: Downloading node 0.12.4... remote: Installing node 0.12.4... remote: Using default npm version remote: remote: -----&gt; Building dependencies remote: [...] remote: Building Phoenix static assets remote: 07 Jul 00:06:22 - info: compiled 3 files into 2 files, copied 3 in 3616ms remote: Check your digested files at &#39;priv/static&#39;. remote: remote: -----&gt; Finalizing build remote: Creating runtime environment remote: remote: -----&gt; Discovering process types remote: Procfile declares types -&gt; (web) remote: Default types for Multipack -&gt; web remote: remote: -----&gt; Compressing... done, 82.1MB remote: -----&gt; Launching... done, v5 remote: https://mysterious-meadow-6277.herokuapp.com/ deployed to Heroku remote: remote: Verifying deploy... done. To https://git.heroku.com/mysterious-meadow-6277.git * [new branch] master -&gt; master Typing heroku open in the terminal should launch a browser with the Phoenix welcome page opened. In the event that you are using Ecto to access a database, you will also need to run migrations after the first deploy: $ heroku run &quot;POOL_SIZE=2 mix ecto.migrate&quot; And that&#39;s it!"},{"ref":"heroku.html#deploying-to-heroku-using-the-container-stack","title":"Deploying on Heroku - Deploying to Heroku using the container stack","type":"extras","doc":"Create Heroku application Set the stack of your app to container, this allows us to use Dockerfile to define our app setup. $ heroku create Creating app... done, ⬢ mysterious-meadow-6277 $ heroku stack:set container Add a new heroku.yml file to your root folder. In this file you can define addons used by your app, how to build the image and what configs are passed to the image. You can learn more about Heroku&#39;s heroku.yml options here. Here is a sample: setup: addons: - plan: heroku-postgresql as: DATABASE build: docker: web: Dockerfile config: MIX_ENV: prod SECRET_KEY_BASE: $SECRET_KEY_BASE DATABASE_URL: $DATABASE_URL Setup releases and Dockerfile Now we need to define a Dockerfile at the root folder of your project that contains your application. We recommend to use releases when doing so, as the release will allow us to build a container with only the parts of Erlang and Elixir we actually use. Follow the releases docs. At the end of the guide, there is a sample Dockerfile file you can use. Once you have the image definition setup, you can push your app to heroku and you can see it starts building the image and deploy it."},{"ref":"heroku.html#useful-heroku-commands","title":"Deploying on Heroku - Useful Heroku Commands","type":"extras","doc":"We can look at the logs of our application by running the following command in our project directory: $ heroku logs # use --tail if you want to tail them We can also start an IEx session attached to our terminal for experimenting in our app&#39;s environment: $ heroku run &quot;POOL_SIZE=2 iex -S mix&quot; In fact, we can run anything using the heroku run command, like the Ecto migration task from above: $ heroku run &quot;POOL_SIZE=2 mix ecto.migrate&quot;"},{"ref":"heroku.html#connecting-to-your-dyno","title":"Deploying on Heroku - Connecting to your dyno","type":"extras","doc":"Heroku gives you the ability to connect to your dyno with an IEx shell which allows running Elixir code such as database queries. Modify the web process in your Procfile to run a named node: web: elixir --sname server -S mix phx.server Redeploy to Heroku Connect to the dyno with heroku ps:exec (if you have several applications on the same repository you will need to specify the app name or the remote name with --app APP_NAME or --remote REMOTE_NAME) Launch an iex session with iex --sname console --remsh server You have an iex session into your dyno!"},{"ref":"heroku.html#troubleshooting","title":"Deploying on Heroku - Troubleshooting","type":"extras","doc":"Compilation Error Occasionally, an application will compile locally, but not on Heroku. The compilation error on Heroku will look something like this: remote: == Compilation error on file lib/postgrex/connection.ex == remote: could not compile dependency :postgrex, &quot;mix compile&quot; failed. You can recompile this dependency with &quot;mix deps.compile postgrex&quot;, update it with &quot;mix deps.update postgrex&quot; or clean it with &quot;mix deps.clean postgrex&quot; remote: ** (CompileError) lib/postgrex/connection.ex:207: Postgrex.Connection.__struct__/0 is undefined, cannot expand struct Postgrex.Connection remote: (elixir) src/elixir_map.erl:58: :elixir_map.translate_struct/4 remote: (stdlib) lists.erl:1353: :lists.mapfoldl/3 remote: (stdlib) lists.erl:1354: :lists.mapfoldl/3 remote: remote: remote: ! Push rejected, failed to compile elixir app remote: remote: Verifying deploy... remote: remote: ! Push rejected to mysterious-meadow-6277. remote: To https://git.heroku.com/mysterious-meadow-6277.git This has to do with stale dependencies which are not getting recompiled properly. It&#39;s possible to force Heroku to recompile all dependencies on each deploy, which should fix this problem. The way to do it is to add a new file called elixir_buildpack.config at the root of the application. The file should contain this line: always_rebuild=true Commit this file to the repository and try to push again to Heroku. Connection Timeout Error If you are constantly getting connection timeouts while running heroku run this could mean that your internet provider has blocked port number 5000: heroku run &quot;POOL_SIZE=2 mix myapp.task&quot; Running POOL_SIZE=2 mix myapp.task on mysterious-meadow-6277... ! ETIMEDOUT: connect ETIMEDOUT 50.19.103.36:5000 You can overcome this by adding detached option to run command: heroku run:detached &quot;POOL_SIZE=2 mix ecto.migrate&quot; Running POOL_SIZE=2 mix ecto.migrate on mysterious-meadow-6277... done, run.8089 (Free)"}]